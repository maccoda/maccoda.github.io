<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
	<title>Maccoda Mail</title>
	<subtitle>Sending out some thoughts and learnings</subtitle>
	<link href="https://maccoda.github.io/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="https://maccoda.github.io"/>
	<generator uri="https://www.getzola.org/">Zola</generator>
	<updated>2022-06-13T00:00:00+00:00</updated>
	<id>https://maccoda.github.io/atom.xml</id>
	<entry xml:lang="en">
		<title>Domain Mono Repos</title>
		<published>2022-06-13T00:00:00+00:00</published>
		<updated>2022-06-13T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/domain-repo/" type="text/html"/>
		<id>https://maccoda.github.io/domain-repo/</id>
		<content type="html">&lt;p&gt;We use repositories every day as a software engineer. They are a simple
organisational tool to group together code for a certain project. Primarily
however they are driven by the fact they are a single repository in accordance with our
source control (git). However, as the list of tools and processes that hook into
these repositories grow, so too does the value of the repository. Slowly, it is
becoming coupled with many other elements of our work. For example, we have
plenty of tools to track history over a single repository using source control
management. We have deployment pipelines that are typically attached to a single
repository, which are responsible for getting our code out to production. We
also have issue tracking and project management that is attached to a single
repository. As we can see, the boundary at which we draw the repository is
actually having more and more of an effect on how we work than simply a basic
organisational tool.&lt;&#x2F;p&gt;
&lt;p&gt;My most common approach for repository structure has been to have a single
repository for a single deployable unit. Take a basic client server example.
Typically there would be a UI repository to manage the client side code, and an
API repository to manage the server side code. Along with that, if we are using
infrastructure as code (which we probably should be) there would even be a third
repository managing all the infrastructure. This model made a lot of sense
initially. Each of these elements are a different deployable unit and typically
there would only be a single language for each repository.&lt;&#x2F;p&gt;
&lt;p&gt;However, as projects grew, and we lean more into automation and tooling this
model started to show some cracks. To add value for the customer, it is uncommon
we can achieve this solely through the UI or the API. It is more common to need
to make changes across both these deployable units to add value. Therefore for a
single task we need to make changes to multiple repositories, which means
multiple code reviews. Not to mention needing to maintain more repositories
moving at different rates. This was obviously such as issue as the popular
editor VSCode even supports a notion of &lt;em&gt;workspaces&lt;&#x2F;em&gt; to work across multiple
repositories&#x2F;directories. Once all parts were reviewed and integrated into the
pipeline then came the issue of ensuring the correct deployment order. It is
fairly common that the UI should depend on the API. Thus, we always require the
API to be deployed before the UI. This is not codified in our repositories as
most CI tools create a separate pipeline per repository, hence it becomes
difficult to ensure that the UI is never deployed without first having the API
with the relevant changes deployed.&lt;&#x2F;p&gt;
&lt;p&gt;These draw backs are what have led to the idea of a new repository style,
drawing on Domain Driven Design (DDD) and hence the name &lt;em&gt;Domain Mono Repos&lt;&#x2F;em&gt;.
The idea is that the same boundary that is created for a domain when designing
is the same boundary to define what sits within the domain mono repo. How this
looks in practice is that a single repository will contain all deployable units
and their infrastructure. For example, a single domain might consist of a NodeJS
API deployed on AWS ECS, a single page application UI and some AWS Lambda
Functions and AWS SQS queues. For this there would be a single repository that
separates these all into different directories, each having their respective
project structure.&lt;&#x2F;p&gt;
&lt;p&gt;Structuring a repository in this way addresses the issues mentioned earlier:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;a single feature can be implemented and raised in a single code review across
all deployable units&lt;&#x2F;li&gt;
&lt;li&gt;a pipeline can be created to ensure the correct deployment order for each
deployable unit&lt;&#x2F;li&gt;
&lt;li&gt;easier tracking of change history with commits being able to span the whole
domain&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Some other benefits that have been observed:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;logistically easier to find code and projects as there are fewer repositories
and are named using the same language as the domain, hence easier to search
for&lt;&#x2F;li&gt;
&lt;li&gt;less template repositories to manage as they all essentially are created from
the same start point&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Some good things to remember when using HTTP statuses</title>
		<published>2022-01-11T00:00:00+00:00</published>
		<updated>2022-01-11T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/http-status-good-usage/" type="text/html"/>
		<id>https://maccoda.github.io/http-status-good-usage/</id>
		<content type="html">&lt;p&gt;If you have worked on a client&#x2F;server project of any sort then you have no doubt
encountered HTTP statuses. They are part of the HTTP standard and there are a
lot of them. I wanted to go through some useful elements to consider regarding
their usage as both the producer and consumer of a HTTP response.&lt;&#x2F;p&gt;
&lt;p&gt;First off, what are they exactly and what do they all mean? Thankfully we have
&lt;a href=&quot;https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;HTTP&#x2F;Status&quot;&gt;MDN&lt;&#x2F;a&gt; which has the entire list of them. As you can see they are
represented as a 3 digit number with ranging from 100-599 (currently at least).
The most important thing to note and the inspiration for writing this post is
that the statuses are grouped based on the first digit. This grouping is both
incredibly useful and incredibly important to recognise. It is useful because
you are able to easily categorise return types if you are not concerned with
specifics, such as for all errors show an error message. It is important because
I have seen many people write code that checks for a status of exactly 200 when
in fact the response could be any from the 2XX group.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;authoring-a-server&quot;&gt;Authoring a server&lt;&#x2F;h2&gt;
&lt;p&gt;When authoring a server which provides these statuses it is good to extend
beyond just the 200 and 500 options. In doing so it provides the client with
more information than simply success or failure, and therefore allowing the
client to make more informed decisions as to how to handle the response. The
following are two small examples where success and failure can be represented
with a different status code and thus would result in the client performing
different actions.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;200-vs-204&quot;&gt;200 vs 204&lt;&#x2F;h3&gt;
&lt;p&gt;Both the status of 200 and 204 represent a successful result but have slightly
separate meanings. 200 is &lt;strong&gt;OK&lt;&#x2F;strong&gt; and 204 is &lt;strong&gt;No Content&lt;&#x2F;strong&gt;. The commonplace 200
response will typically be accompanied by some body text and hence if this
response is received the client will likely attempt to parse the body element.
However if no such body element exists sending through a 204 will make the
client aware that no such body is present and can avoid attempting to parse it.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;4xx-vs-5xx&quot;&gt;4XX vs 5XX&lt;&#x2F;h3&gt;
&lt;p&gt;In terms of a failure scenario there are several ways in which this can be
categorised. Two ranges of errors are within the 4XX and 5XX range. When
constructing a server response it is important to consider which range is most
appropriate to assist the client in determining the next course of action. When
the server returns a 4XX response it means that the error is on the client side,
such as incorrect data or invalid credentials. In these cases there is no point
in the client retrying with the same input. Whereas if the failure was due to an
internal error (unrelated to client provided input) such as downstream
dependencies failures or unexpected exceptions, a 5XX code should be returned.
Depending on the exact response code the client can know whether a retry should
be performed or not.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;authoring-a-client&quot;&gt;Authoring a client&lt;&#x2F;h2&gt;
&lt;p&gt;Authoring a client using HTTP statuses is almost the opposite of authoring a
server. When authoring a client it is vital to not just assume there is the
success or failure case. Beyond that, the status alone can be used to obtain all
the information required.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;do-not-assume-a-200-for-success&quot;&gt;Do not assume a 200 for success&lt;&#x2F;h3&gt;
&lt;p&gt;As mentioned in the server section, 200 is not the only status code for a
successful call. Therefore writing client code that explicitly checks to see if
the status is 200 will result in errors. For example, the status 201 is returned
if an entity has been created, such as a typical POST in a REST API. Therefore a
still successful scenario has now suddenly caused issues on the client side.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;know-the-groupings&quot;&gt;Know the groupings&lt;&#x2F;h3&gt;
&lt;p&gt;As mentioned previously, the HTTP statuses are grouped into 5 classes, 1XX to
5XX. Treating each of these individually allows for client code to be written to
respond differently depending on the class. One of the clearest examples is
provided above, knowing the difference between client errors (4xx) and server
errors (5xx). Using this information it is possible to write correct utility
methods around these to define common actions to be taken depending on the class
of HTTP status received.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;utilise-the-status&quot;&gt;Utilise the status&lt;&#x2F;h3&gt;
&lt;p&gt;Finally, an issue that I have observed is writing client code that just skips
the status check. The status classifies the type of response that has been
received and in some use cases this is sufficient so all other information can
be disregarded. A good example of this is a health check. A health check is a
simple HTTP call to ensure that a service is up and running, a client calling
this can determine the status of the service simply by looking at the status.
There may well be some body content here but there is no need to couple the code
to the contents of this response to determine the status of the service.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Valuable functional programming basics every developer should know</title>
		<published>2021-06-05T00:00:00+00:00</published>
		<updated>2021-06-05T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/fp-oo-must-know/" type="text/html"/>
		<id>https://maccoda.github.io/fp-oo-must-know/</id>
		<content type="html">&lt;p&gt;For a long time there was an idealistic divide between functional and object
oriented programming and this was manifested in the languages that came through.
In the current landscape however you are spoilt for choice with languages and
this divide is closing with a lot of the most popular languages available taking
the best aspects of both paradigms. Kotlin is a great example of this where it
is initially based on the JVM and follows OO principles with classes, etc but
also introduces a lot of functional principles such as first class functions and
the scary monad (I am no expert in this but there are a lot of easy to
understand properties that you can make use of). Another example is Rust where
it cannot easily be classified as either paradigm but uses functional elements
such as using the &lt;code&gt;Result&lt;&#x2F;code&gt; type to promote functions always return a result, as
well as object oriented notions such as the dot notation of functions on a type.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;monad-concepts&quot;&gt;Monad Concepts&lt;&#x2F;h2&gt;
&lt;p&gt;Monad is a term used a lot in functional programming and especially in the vast
theory behind it. I did not wish to delve into such theory here but rather the
useful functions that become available because we can treat some objects as a
monad. Of particular interest is working with collections or streams of
elements. The main reason I personally find these incredibly powerful is that
they provide a common language for which we can describe the intention of common
functions that can be combined together to achieve our end result. A lot of
these functions you can use in place of a &lt;code&gt;for&lt;&#x2F;code&gt; loop so next time you are
looking at iterating over a collection with a &lt;code&gt;for&lt;&#x2F;code&gt; loop consider if one of the
following constructs are what you need.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;map&quot;&gt;&lt;code&gt;map&lt;&#x2F;code&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;The &lt;code&gt;map&lt;&#x2F;code&gt; function is a transformation of each element from type X to type Y.
Depending on the language you are using this may modify the elements in place or
create a new collection of the mapped values (in true functional style).&lt;&#x2F;p&gt;
&lt;p&gt;An easy example is say I have a collection of blog posts and I want to obtain
the titles of all these, we can achieve this by:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;val blogPosts: Collection&amp;lt;BlogPost&amp;gt; = listOf(BlogPost(title = &amp;quot;post 1&amp;quot;),
                                             BlogPost(title = &amp;quot;post 2&amp;quot;))
val blogPostTitles: Collection&amp;lt;String&amp;gt; = blogPosts.map { it.title } &amp;#x2F;&amp;#x2F; [&amp;quot;post 1&amp;quot;, &amp;quot;post 2&amp;quot;]
&amp;#x2F;&amp;#x2F; Without the syntactic sugar
&amp;#x2F;&amp;#x2F; val blogPostTitles: Collection&amp;lt;String&amp;gt; = blogPosts.map { post -&amp;gt; post.title }
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Let&#x27;s break this example down a bit to what is happening here. The &lt;code&gt;map&lt;&#x2F;code&gt;
function takes a function as a parameter which we will call our &lt;strong&gt;transform
function&lt;&#x2F;strong&gt;. This function maps the input type to some other type (this can the
same as the input type). The &lt;code&gt;map&lt;&#x2F;code&gt; function then iterates through the input list
and creates a new list applying this function to each element.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;flatmap&quot;&gt;&lt;code&gt;flatMap&lt;&#x2F;code&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;The &lt;code&gt;flatMap&lt;&#x2F;code&gt; function is actually a combination of the above &lt;code&gt;map&lt;&#x2F;code&gt; function and
the &lt;code&gt;flatten&lt;&#x2F;code&gt; function (not covered in this post). The &lt;code&gt;flatten&lt;&#x2F;code&gt; function takes
a container of containers type and &lt;strong&gt;flattens&lt;&#x2F;strong&gt; it to just a container type.
This is quite abstract so lets take a simple example. Say you have a
&lt;code&gt;List&amp;lt;List&amp;lt;String&amp;gt;&amp;gt;&lt;&#x2F;code&gt; and you want a &lt;code&gt;List&amp;lt;String&amp;gt;&lt;&#x2F;code&gt;, this in the broad sense what
the &lt;code&gt;flatten&lt;&#x2F;code&gt; function does. In this example the container is the &lt;code&gt;List&lt;&#x2F;code&gt; type.&lt;&#x2F;p&gt;
&lt;p&gt;Knowing this it is quite simple to describe the &lt;code&gt;flatMap&lt;&#x2F;code&gt; function although it
may still be difficult to wrap your head around in actual applications. The
&lt;code&gt;flatMap&lt;&#x2F;code&gt; function will apply the transformation specified to the element in the
container and then flatten it. This is typically required when the
transformation function returns the same type as the initial type.&lt;&#x2F;p&gt;
&lt;p&gt;As an example say we have a type that represents the books a customer has read
and we want to print all of the books a group of customers have read (we are not
concerned about duplicates). Such data may be present as:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;data class BookCustomer(val booksRead: List&amp;lt;String&amp;gt;)

val bookCustomers: List&amp;lt;BookCustomer&amp;gt; = ...
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The end type we are wanting is a &lt;code&gt;List&amp;lt;String&amp;gt;&lt;&#x2F;code&gt; containing all the book titles.
Let us first try this without &lt;code&gt;flatMap&lt;&#x2F;code&gt;  to aide in seeing when to consider
using it.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;val bookCustomers: List&amp;lt;BookCustomer&amp;gt; = ...

val booksRead: MutableList&amp;lt;String&amp;gt; = mutableListOf()

for (customer: BookCustomer in bookCustomers) {
  val booksTitles: List&amp;lt;String&amp;gt; = customer.booksRead
  booksRead.addAll(booksTitles)
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The key thing that using these functional paradigms provides is built in
immutability. In the above example we are needing to create a mutable list to
get the result. We will see in the below version this is not required.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;val bookCustomers: List&amp;lt;BookCustomer&amp;gt; = ...

val bookRead: List&amp;lt;String&amp;gt; = bookCustomers.flatMap { it.booksRead }
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The transformation we are performing is mapping the &lt;code&gt;BookCustomer&lt;&#x2F;code&gt; to the list
of book titles they have read, then the flatten part of &lt;code&gt;flatMap&lt;&#x2F;code&gt; handles to
reduction of the list of lists into a single list. This leads us into the next
section on &lt;code&gt;reduce&lt;&#x2F;code&gt; which is the general pattern of &lt;code&gt;flatten&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;reduce-or-fold&quot;&gt;&lt;code&gt;reduce&lt;&#x2F;code&gt; or &lt;code&gt;fold&lt;&#x2F;code&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;The &lt;code&gt;reduce&lt;&#x2F;code&gt; and &lt;code&gt;fold&lt;&#x2F;code&gt; functions are more general functions to reduce a container,
typically a collection, to a singular value. A simple example we can explore is
reducing a collection of integers to their sum.&lt;&#x2F;p&gt;
&lt;p&gt;Firstly, the difference between the two functions is primarily in the arguments
that the functions take. The function signatures are below to make it simple to
reference.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;fun &amp;lt;T, R&amp;gt; Iterable&amp;lt;T&amp;gt;.fold(
    initial: R,
    operation: (acc: R, T) -&amp;gt; R
): R

fun &amp;lt;T, R&amp;gt; Iterable&amp;lt;T&amp;gt;.reduce(
    operation: (acc: R, T) -&amp;gt; R
): R
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The primary difference between the two functions is that one takes the &lt;code&gt;initial&lt;&#x2F;code&gt;
value of the resulting type and one does not. It instead uses the first value as
the initial value. This subtle difference results in the &lt;code&gt;reduce&lt;&#x2F;code&gt; function
requiring a non-empty collection to work on whereas &lt;code&gt;fold&lt;&#x2F;code&gt; can work on an empty
list and just return the &lt;code&gt;initial&lt;&#x2F;code&gt; value.&lt;&#x2F;p&gt;
&lt;p&gt;A simple example to show how these functions work is by implementing a summation
function that operates on a collection of integers.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;fun sumReduce(input: Iterable&amp;lt;Int&amp;gt;): Int {
  input.reduce { acc, cur -&amp;gt; acc + cur }
}


fun sumFold(input: Iterable&amp;lt;Int&amp;gt;): Int {
  input.fold(0) { acc, cur -&amp;gt; acc + cur }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;!-- Explain the arguments provided here --&gt;
&lt;p&gt;The interesting element of these is the closure passed of the form &lt;code&gt;(acc: R, cur: T) -&amp;gt; R&lt;&#x2F;code&gt;. This function is essentially and accumulation function that
combines the elements of the collection to the final result. It takes two
arguments:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;acc&lt;&#x2F;code&gt; which is the current accumulated result up to the current element&lt;&#x2F;li&gt;
&lt;li&gt;&lt;code&gt;cur&lt;&#x2F;code&gt; which is the current element&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Putting this in action:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;val numbers = listOf(1, 2, 3, 4, 5)

val sum: Int = sumFold(numbers)
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The accumulation function is applied to each element and then the accumulated
value is updated and passed along. Stepping through the above example would look
like this:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Note this is for fold, if using reduce the first row would be omitted as there
is no initial value&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;&lt;code&gt;acc&lt;&#x2F;code&gt;&lt;&#x2F;th&gt;&lt;th&gt;&lt;code&gt;cur&lt;&#x2F;code&gt;&lt;&#x2F;th&gt;&lt;th&gt;Accumulation function result&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;0&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;1&lt;&#x2F;td&gt;&lt;td&gt;2&lt;&#x2F;td&gt;&lt;td&gt;3&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;&#x2F;td&gt;&lt;td&gt;3&lt;&#x2F;td&gt;&lt;td&gt;6&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;6&lt;&#x2F;td&gt;&lt;td&gt;4&lt;&#x2F;td&gt;&lt;td&gt;10&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;10&lt;&#x2F;td&gt;&lt;td&gt;5&lt;&#x2F;td&gt;&lt;td&gt;15&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;!-- Give a good real life example of reducing validations perhaps --&gt;
&lt;h4 id=&quot;more-use-cases&quot;&gt;More use cases&lt;&#x2F;h4&gt;
&lt;p&gt;The power of these functions is how flexible they are, any accumulator function
can be provided allowing you to work with any type. If you were inclined you
could spend more time studying functional programming and see how this is the
basis of a lot of incredibly power combinator functions. For example we can
create &lt;code&gt;flatMap&lt;&#x2F;code&gt; using &lt;code&gt;reduce&lt;&#x2F;code&gt; and &lt;code&gt;map&lt;&#x2F;code&gt;. Since this is typically handled in
the standard library we will look at a more likely scenario to find in a&lt;&#x2F;p&gt;
&lt;p&gt;project.&lt;&#x2F;p&gt;
&lt;p&gt;The example we will go through is that of some validation framework which
leverages the following:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;interface Validation {
  fun validate(input: Input): ValidationResult
}

enum class ValidationResult {
  VALID, INVALID
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Imagine we have a collection of validators and we wish to implement some
functionality that requires that all validators to run on the &lt;code&gt;Input&lt;&#x2F;code&gt; object and
it returns &lt;code&gt;VALID&lt;&#x2F;code&gt; if &lt;strong&gt;all&lt;&#x2F;strong&gt; validators return &lt;code&gt;VALID&lt;&#x2F;code&gt; otherwise if even one
returns &lt;code&gt;INVALID&lt;&#x2F;code&gt; it returns &lt;code&gt;INVALID&lt;&#x2F;code&gt;. The &lt;code&gt;reduce&lt;&#x2F;code&gt; function can do exactly
this as we can evaluate all the validators and then &lt;em&gt;reduce&lt;&#x2F;em&gt; them to a single
result.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;val validators: List&amp;lt;Validation&amp;gt; = ...
val input: Input = ...

val result: ValidationResult = validators
                                  .reduce { acc, cur -&amp;gt; if(acc == ValidationResult.VALID) it.validate(input) else ValidationResult.INVALID }
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;filter&quot;&gt;&lt;code&gt;filter&lt;&#x2F;code&gt;&lt;&#x2F;h3&gt;
&lt;p&gt;The &lt;code&gt;filter&lt;&#x2F;code&gt; function is another helpful function to work with collections which
filters the collection based on a provided predicate. If the term predicate is
new, it is simply a function that takes an input object and returns a boolean.&lt;&#x2F;p&gt;
&lt;p&gt;Using another book example let&#x27;s assume we have the below data type for a book
and we want to obtain the list of all books we read, this can be done as below:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;data class Book(val title: String, val read: Boolean)

val books: List&amp;lt;Book&amp;gt; = ...

val booksRead: List&amp;lt;Book&amp;gt; = books.filter { it.read }
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;not-quite-must-knows&quot;&gt;Not quite must knows&lt;&#x2F;h2&gt;
&lt;p&gt;The above functions and types are extremely valuable in most modern languages.
The below types are useful to know but depending on your language choice you may
not actually use it but understanding the concept is valuable regardless as it
can still have a positive impact on the way you write your code.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;option-maybe-type&quot;&gt;Option&#x2F;Maybe Type&lt;&#x2F;h3&gt;
&lt;p&gt;It is common to have to represent the possibility of some data not being
present. Commonly in languages this is represented by some null value but in
pure functional programming this is actually represented by a type possibly
called &lt;code&gt;Option&lt;&#x2F;code&gt; (such as in Rust) or &lt;code&gt;Maybe&lt;&#x2F;code&gt; (such as in Haskell). The core of
this type is to be able to reflect the absence of a value in the type system.
This can also be achieved with languages still supporting null such as Kotlin as
it surfaces the nullability to the type level.&lt;&#x2F;p&gt;
&lt;p&gt;Having a container type to represent the absence of a value allows the client of
the data to act on it safely without needing to check whether the data is
present or not, which is something unable to be achieved with a basic null value
alone.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;let data = Some(2)
let no_data = None
let result_some = data.map(|x| x + 3) &amp;#x2F;&amp;#x2F; Some(5)
let result_none = no_data.map(|x| + 3) &amp;#x2F;&amp;#x2F; None
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;result-either-type&quot;&gt;Result&#x2F;Either Type&lt;&#x2F;h3&gt;
&lt;p&gt;In an OO landscape it is typical to handle errors through exception handling.
Pure functional languages require this to be represented in the type system,
which is quite a powerful model. This is again named differently depending on
the language but it is a container type that has two possible representations.
If it is called &lt;code&gt;Either&lt;&#x2F;code&gt; then this will have a &lt;code&gt;Left&lt;&#x2F;code&gt; and &lt;code&gt;Right&lt;&#x2F;code&gt; type, this is
more generic than the &lt;code&gt;Result&lt;&#x2F;code&gt; type as you are able to represent any arbitrary
type that is a union of two possible types. A more focused point is the &lt;code&gt;Result&lt;&#x2F;code&gt;
type used in Rust to represent explicitly an error as it does not have
exceptions. The two types of this union are &lt;code&gt;Ok&lt;&#x2F;code&gt; and &lt;code&gt;Err&lt;&#x2F;code&gt; (for error).&lt;&#x2F;p&gt;
&lt;p&gt;Again this notion of a type may not be largely applicable in the OO domain but
it does promote you to think of handling errors and state in a different manner
and representing this in the type system. This concept can easily be implemented
in Kotlin using sealed classes and does not need to just be used for error
handling but can be used to create any container class that a client can act on.
Again the goal here is having the container class allows the client to work with
the data irrespective of the underlying state.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Migrating your project from Java to Kotlin</title>
		<published>2021-03-07T00:00:00+00:00</published>
		<updated>2021-03-07T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/migrating-to-kotlin/" type="text/html"/>
		<id>https://maccoda.github.io/migrating-to-kotlin/</id>
		<content type="html">&lt;p&gt;I have been part of a few migrations of projects from Java to Kotlin in
particular as I have convinced more teams of its value over Java. However I did
not want to write another comparison article but rather assuming that you are
undertaking this migration how you can tackle it. One of the great benefits here
is that Kotlin is entirely interoperable with Java allowing you to not make the
changes in a single grand rewrite effort. Instead you can address the changes
piecemeal.&lt;&#x2F;p&gt;
&lt;p&gt;This post has been split into two sections of &lt;strong&gt;traps&lt;&#x2F;strong&gt; to avoid when migrating
and &lt;strong&gt;tricks&lt;&#x2F;strong&gt; to try. Not all sections may be relevant to your particular use
case as some sections are focused on the tooling&#x2F;frameworks that has been used,
so please find the ones most applicable and hopefully it assists.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;traps&quot;&gt;Traps&lt;&#x2F;h2&gt;
&lt;p&gt;First we shall cover the areas of migrations that teams have tripped up on
unexpectedly and how they were overcome.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;compilation-order&quot;&gt;Compilation order&lt;&#x2F;h3&gt;
&lt;p&gt;When working with a polyglot project it becomes important to understand the
compilation order as this defines the allowed dependencies. When using tools
such as Gradle I believe it is configurable using the &lt;code&gt;dependsOn&lt;&#x2F;code&gt; argument of
the task. In my experience the standardised tooling has chosen the order to be
Kotlin =&amp;gt; Java and thus I shall cover the elements that this direction of
dependency introduces.&lt;&#x2F;p&gt;
&lt;p&gt;The output class files should be co-located and hence full interaction should be
capable however there are many fancy tools in the JVM world that generate code
or hook into the compilation cycle to alter the byte code (such as Lombok in the
next section). It is important to know how these tools works in principle but
also as it can lead to unexpected issues. Therefore comprehensively understand
the tooling of the project prior to the migration to determine any of these such
tools used in the Java toolchain as these will not be able to be used by the
Kotlin classes as they are compiled prior to the tool being invoked.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;lombok&quot;&gt;Lombok&lt;&#x2F;h3&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;projectlombok.org&#x2F;&quot;&gt;Lombok&lt;&#x2F;a&gt; is such a tool that hooks into the
compilation cycle to generate boilerplate code within Java. Commonly used to
generate getters, setters, and constructors. These files are generated as part
of the Java compilation step, therefore all the Lombok generated code becomes
inaccessible by Kotlin code in a polyglot project. This has led to several
compilation errors of the nature of &amp;quot;symbol not found&amp;quot;. Now that you are aware
of this trap in the migration these cryptic messages should ideally have a
clearer cause.&lt;&#x2F;p&gt;
&lt;p&gt;The best way to avoid this issue is to &amp;quot;delombok&amp;quot; your code as you migrate. It
is not necessary to &amp;quot;delombok&amp;quot; the entire code base or even the entire file. The
issue can simply be rectified by writing the required function explicitly as
Lombok skips over the generation of functions that already exist.&lt;&#x2F;p&gt;
&lt;p&gt;The following shows an object of performing just that, assume that our Kotlin
code only needs access to the &lt;code&gt;getName()&lt;&#x2F;code&gt; function.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@Value
public class Person {
  private final int id;
  private final String name;
  private final int age;
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Will be changed to the following to allow Kotlin access:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@Value
public class Person {
  private final int id;
  private final String name;
  private final int age;

  public String getName() {
    return name;
  }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;builder-pattern&quot;&gt;Builder pattern&lt;&#x2F;h4&gt;
&lt;p&gt;Another commonly generated pattern via Lombok is the builder pattern. This is
very useful in Java in particular to aide in readability when there are several
parameters to construct an object. In Kotlin such a pattern is not required as
the language itself supports this with &lt;a href=&quot;https:&#x2F;&#x2F;kotlinlang.org&#x2F;docs&#x2F;functions.html#named-arguments&quot;&gt;named arguments&lt;&#x2F;a&gt;. What this does mean
however is when migrating such a class from Java to Kotlin you must implement
the builder pattern within Kotlin as the Java classes cannot make use of the
named arguments and further it also reduces the amount that is changed in each
migration step.&lt;&#x2F;p&gt;
&lt;p&gt;The following is an example of how to implement the builder pattern for a basic
data class.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;data class Name(val first: String, val last: String) {

  companion object {
    fun builder() = Builder()

      data class Builder(
        var first: String? = null,
        var second: String? = null
        ) {

        fun first(first: String) = apply { this.first = first }
        fun second(second: String) = apply { this.second = second }
        &amp;#x2F;&amp;#x2F; You can do better handling of null than this but I have found this
        &amp;#x2F;&amp;#x2F; sufficient until the I get to migrate the calling class to Kotlin
        fun build() = Name(first!!, second!!)
      }
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;tricks&quot;&gt;Tricks&lt;&#x2F;h2&gt;
&lt;p&gt;Next up we will cover some tricks discovered to make the migration easier, in
particular focusing on tooling that Kotlin already provides to make this
simpler.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;order-to-migrate&quot;&gt;Order to migrate&lt;&#x2F;h3&gt;
&lt;p&gt;Migrating a project can be a monumental task depending on the size of the code
base, therefore it is important just as any other large changes that it be done
in small, manageable chunks. The following is some general advice on how to
tackle this migration.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Convert the value&#x2F;data objects first&lt;&#x2F;strong&gt;. The principle here is that they have
the fewest dependencies (ideally none), therefore moving these across should be
simple. Also, typically to migrate a class it is greatly beneficial that the
dependent (or imported) classes are already in Kotlin so none of the above traps
occur.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Work your way outwards&lt;&#x2F;strong&gt;. Once all value&#x2F;data classes have been converted
choose classes that are closely related to it, ideally having only a few
dependencies, moving gradually out to the entry point of the program.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Either convert or add functionality, never both.&lt;&#x2F;strong&gt; This is strongly aligned
with the recommendation when refactoring (which converting a class is), that
adding new functionality whilst also performing a refactoring creates two
possible sources of error. In regards to migrating to Kotlin in particular this
leads to a bloat in code reviews making it very difficult to see the
functionality changes. Thus always perform the migration, then add the new
functionality.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;kotlin-compiler-plugins&quot;&gt;Kotlin compiler plugins&lt;&#x2F;h3&gt;
&lt;p&gt;Kotlin chose a few differing paradigms from Java which results in certain
tooling being unable to work due to their leveraging of particular Java
paradigms. The most obvious example is mocking frameworks in Java make use of
the fact that they can create a subclass of the class to mock This cannot be
done in Kotlin as easily as for Java as Kotlin has closed classes by default. To
assist in this the Kotlin team have provided compiler plugins such as &lt;a href=&quot;https:&#x2F;&#x2F;kotlinlang.org&#x2F;docs&#x2F;all-open-plugin.html&quot;&gt;all-open&lt;&#x2F;a&gt;
and &lt;a href=&quot;https:&#x2F;&#x2F;kotlinlang.org&#x2F;docs&#x2F;no-arg-plugin.html&quot;&gt;no-arg&lt;&#x2F;a&gt; to address these limitations when migrating. It also allows you to
continue to make use of the more mature tooling in Java if you wish to.&lt;&#x2F;p&gt;
&lt;p&gt;In saying this however I do recommend exploring Kotlin native
libraries&#x2F;frameworks where possible as these do provide a much better
experience.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;kotlin-jvm-annotations&quot;&gt;Kotlin JVM annotations&lt;&#x2F;h3&gt;
&lt;p&gt;Another major difference in the languages is that Kotlin does not have a notion
of &lt;code&gt;static&lt;&#x2F;code&gt;, its &lt;code&gt;companion object&lt;&#x2F;code&gt; is similar but not the same. Therefore when
interoperating with Java one may still wish to use static functions or static
constants. Typically these will be placed in the companion object and need to be
accessed through &lt;code&gt;MyClass.Companion.MY_CONSTANT&lt;&#x2F;code&gt;. There are annotations provided
with the Kotlin standard library to make this look more like a Java class such
as &lt;code&gt;MyClass.MY_CONSTANT&lt;&#x2F;code&gt; which then means that you do not need to change all
call sites of constants and functions.&lt;&#x2F;p&gt;
&lt;p&gt;For constants&#x2F;static fields the &lt;a href=&quot;https:&#x2F;&#x2F;kotlinlang.org&#x2F;docs&#x2F;java-to-kotlin-interop.html#static-fields&quot;&gt;&lt;code&gt;@JvmField&lt;&#x2F;code&gt;&lt;&#x2F;a&gt; annotation can be used and for
static methods the &lt;a href=&quot;https:&#x2F;&#x2F;kotlinlang.org&#x2F;docs&#x2F;java-to-kotlin-interop.html#static-methods&quot;&gt;&lt;code&gt;@JvmStatic&lt;&#x2F;code&gt;&lt;&#x2F;a&gt; annotation can be used.&lt;&#x2F;p&gt;
&lt;p&gt;These annotations are not only there to provide aesthetics but also can improve
your code. For example using &lt;a href=&quot;https:&#x2F;&#x2F;kotlinlang.org&#x2F;docs&#x2F;java-to-kotlin-interop.html#overloads-generation&quot;&gt;&lt;code&gt;@JvmOverloads&lt;&#x2F;code&gt;&lt;&#x2F;a&gt; one can get all variations of a
function generated for a Java class to consume. This is incredibly powerful for
creating test data for example.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Wrapping primitives in domain objects</title>
		<published>2020-11-28T00:00:00+00:00</published>
		<updated>2020-11-28T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/wrapper-classes/" type="text/html"/>
		<id>https://maccoda.github.io/wrapper-classes/</id>
		<content type="html">&lt;p&gt;An interesting pattern I have seen with many developers is that they shy away from creating classes
to represent domain objects, especially basic ones. This is pretty common for identifiers that are
numbers, UUIDs, or just strings. Another similar pattern I see is for booleans, there is plenty of
code out there that uses a boolean value to represent some binary notion that does not really map to
a true or false. A tell tale is if there is a variable or function starting with &lt;code&gt;isXXX&lt;&#x2F;code&gt;. This is by
no means a rule but should trigger a line of questioning whether a boolean is the correct data type.
That is exactly what I wanted to explore in this post, rich data types and being able to add a whole
new level of comprehension to your code and how it fits into your application architecture. This is
so common it has been given a name of &lt;a href=&quot;https:&#x2F;&#x2F;refactoring.guru&#x2F;smells&#x2F;primitive-obsession&quot;&gt;primitive
obsession&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;wrapper-classes&quot;&gt;Wrapper classes&lt;&#x2F;h2&gt;
&lt;p&gt;Using a customer ID as an example I wanted to show some ways in which we could represent this
instead of its primitive type and what values we get from it. The way I manage these domain objects
is what I call wrapper types or classes but there are several names I am sure, essentially I am making a class
that wraps the primitive type that represents the value.&lt;&#x2F;p&gt;
&lt;p&gt;To start off this example lets assume we represent the customer ID as an integer, which is pretty
common if we use the auto incrementing field of a SQL database. The use case we will use is a
service that stores the customer movie recommendations and has an API to read the recommendations
for a given customer ID, it may look something like this (depending on the framework you use):&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;@Controller
class RecommendationController(private val repo: RecommendationRepository) {
    @Get
    fun getCustomerRecommendations(@Path customerId: Int): Preferences {
        return repo.findWithId(customerId)
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The first and most common opposition I hear is what value does it add? Of course in the trivial
example I have provided above it is hard to see the value, but as your application grows it becomes
more valuable and it is much easier to be using it from the outset. Rather than explain all the
benefits of it over the costs of an extra class I would like to show it through a set of examples
similar to what I have seen&#x2F;dealt with myself.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;clearer-function-signatures&quot;&gt;Clearer function signatures&lt;&#x2F;h3&gt;
&lt;p&gt;Let us now consider a little more complicated example, because we could be giving a customer
thousands of recommendations we allow the client to provide a limit to the number of recommendations
we return since they likely do not require all at once. This will again be another &lt;code&gt;Int&lt;&#x2F;code&gt; given to
the controller as a query parameter. Another common feature here is that when you have an account
with your movie streaming company you can actually set up some profiles so lets also add that since
we will likely want to be getting the recommendation for that profile only, so now our controller
function looks a little more like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;@Get
fun getCustomerRecommendations(@Path customerId: Int, @Path profileId: Int, @Query limit: Int) {
    &amp;#x2F;&amp;#x2F; ....
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Hopefully you can already see that we now have several different domain elements that are all
represented as an &lt;code&gt;Int&lt;&#x2F;code&gt;. In the controller layer (the outer layer) this makes perfect sense as we
want to keep these simple types to work nicely with the framework for deserialization however our
internal API of the repository now will have 3 input parameters that are all of the same type. &lt;strong&gt;If
you do not use wrapper types you have to rely on the parameter names of the API to know which goes
into which place&lt;&#x2F;strong&gt;, if we were to represent these with their own classes instead the compiler will
tell us when we have put the profile ID in the place of the customer ID.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;how-to-represent-the-wrapper-class&quot;&gt;How to represent the wrapper class&lt;&#x2F;h3&gt;
&lt;p&gt;Now that we have our first good example why it would be worthwhile adding these classes lets see
what it will look like. This will greatly vary between languages and the way I am representing it
here is by no means the best or only way it will all depend on what actions you need to perform on
the type. In Kotlin there are few options and I will go through them all and why I choose some over
others.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;inline-classes&quot;&gt;Inline classes&lt;&#x2F;h4&gt;
&lt;p&gt;The absolute best option in Kotlin is &lt;a href=&quot;https:&#x2F;&#x2F;kotlinlang.org&#x2F;docs&#x2F;reference&#x2F;inline-classes.html&quot;&gt;inline
classes&lt;&#x2F;a&gt; as this use case is exactly what
the feature was built for, however as of the writing of this post it is still in experimental stages
so I have not used it a lot on production code bases but definitely is fine to have a play with if
you love to be on the bleeding edge.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;inline class CustomerId(val value: Int)
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;data-classes&quot;&gt;Data classes&lt;&#x2F;h4&gt;
&lt;p&gt;Typically I lean on &lt;a href=&quot;https:&#x2F;&#x2F;kotlinlang.org&#x2F;docs&#x2F;reference&#x2F;data-classes.html&quot;&gt;data classes&lt;&#x2F;a&gt; as these
objects contain some piece of data as the name suggests. The benefit here is mainly that the
&lt;code&gt;equals&lt;&#x2F;code&gt; function is generated for us which is something I commonly find that I need to make use of.
The only element of this implementation to be cognisant of is that you will want a consistent naming
convention and expect direct access to the inner field as data classes require there to be a public
accessor. Personally I opt for &lt;code&gt;value&lt;&#x2F;code&gt; (and the generated Java of &lt;code&gt;getValue&lt;&#x2F;code&gt;).&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;data class CustomerId(val value: Int)
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;When the domain object is represented as a &lt;code&gt;String&lt;&#x2F;code&gt; I also adjust the &lt;code&gt;toString&lt;&#x2F;code&gt; function to just
provide the value rather than the generated form which may be unexpected, such as below. This of
course entirely depends on your use case and may not always add value for you.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;data class CustomerName(val value: String) {
	override fun toString(): String = value
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;normal-classes&quot;&gt;Normal classes&lt;&#x2F;h4&gt;
&lt;p&gt;If there is not the use case for &lt;code&gt;equals&lt;&#x2F;code&gt; &lt;strong&gt;and&lt;&#x2F;strong&gt; you do not want to allow for direct access to the
inner field I tend to just write a typical wrapper object very similar to the data class but with a
slightly different API. Honestly I have not seen a lot of use for this case in a Kotlin only project
but in Java and Java&#x2F;Kotlin projects I have found it valuable to represent absence of a field, for
example for a certain request the customer age may not be required:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;class CustomerAge(private val innerValue: Int?) {
	val value: Optional&amp;lt;Int&amp;gt; = Optional.ofNullable(innerValue)
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;In an entire Kotlin project the above does not make a whole lot of sense as nullability is built
into the language however I wanted to show it for completeness as you may be working in a language
that does not or you may have a use case where you do not want to allow for direct access to the
value for some reason.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;benefits-of-wrapper-classes&quot;&gt;Benefits of wrapper classes&lt;&#x2F;h2&gt;
&lt;p&gt;To finish up I wanted to go over some of the benefits I have seen for wrapper classes.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;clearer-intent&quot;&gt;Clearer intent&lt;&#x2F;h3&gt;
&lt;p&gt;Wrapper classes make it crystal clear what type of data you are working with, you will never have to
trace the call stack or hope that someone wrote the currently correct variable name for the
arguments for the string you are working with. The class now tells you exactly what it represents
and the intent on how it should be used. The most significant impact for me has been when reading
older code, it makes it much easier to read function signatures and the logic as I can lean on the
types to inform me whereas when things are all primitive types I rely on the developers variable
naming which has many times become outdated or simply confusing.&lt;&#x2F;p&gt;
&lt;p&gt;This is most apparent when dealing with booleans. Consider the case where content that a customer
can see is restricted based on their subscription plan. A pretty common thing to see is:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;val isAllowed: Boolean = doesCustomerHaveSubscription(customer) &amp;amp;&amp;amp; subscrptionCanAccess(customer, content)

if (isAllowed) {
	&amp;#x2F;&amp;#x2F; Do something...
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;There are several other variations of this where we misrepresent a binary state as a boolean,
allowed&#x2F;restricted, valid&#x2F;invalid are a couple. By representing this as a boolean, certainly we do
get a lot of benefit because we can leverage the language construct for combining these evaluations
but it is very easy to start evaluating either side of the binary choice. For example recently I
have reviewed code where in one spot we are checking to see if it is allowed and at another location
not far away we are checking to see if it is restricted. I can speak from experience that this is
very difficult to understand and keep in a mental model.&lt;&#x2F;p&gt;
&lt;p&gt;Further, there is always some intrinsic element of the domain that dictates how these values can be
combined that do not always map to the same combination as boolean logic, or you have forced it to
match. For example, we typically have it that to be valid when combining evaluations, all must be
valid, if one is invalid then the whole combination is invalid. Certainly this does map to having
valid as true and invalid in boolean logic with the AND operator by why represent it like this when
we can represent it with much clearer intent:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;sealed class Evaluation {
	abstract fun combine(other: Evaluation): Evaluation
}

class Allowed: Evaluation {
	override fun combine(other: Evaluation): Evaluation {
		return when(other) {
			is Allowed -&amp;gt; Allowed
			is Restricted -&amp;gt; Restricted
		}
	}
}

class Restricted: Evaluation {
	override fun combine(other: Evalution): Evaluation {
		return Restricted
	}
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;em&gt;Above I have used &lt;a href=&quot;https:&#x2F;&#x2F;kotlinlang.org&#x2F;docs&#x2F;reference&#x2F;sealed-classes.html&quot;&gt;sealed classes&lt;&#x2F;a&gt; which are extremely helpful for representing a known finite number of states of a value.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Then we can achieve the exact same as above but getting the intent much clearer, certainly there is more code but that is a small price to pay for ease of reading:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;val contentEvaluation: Evaluation = evaluateCustomerSubscription(customer)
							.combine(evaluateSubscriptionAccess(customer, content))

if (contentEvaluation == Allowed) {
	&amp;#x2F;&amp;#x2F; Do something...
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;easier-refactoring&quot;&gt;Easier refactoring&lt;&#x2F;h3&gt;
&lt;p&gt;As with a lot justifications, adding a wrapper class makes the code base easier to adapt to change,
change in design or requirements. There are several examples for this but I wanted to share one that
has stuck with me, let&#x27;s imagine we have an application that stores a customer&#x27;s address and one of
the fields of the address is the zip code and since we are an American company we know that zip
codes in USA are just numbers so we decide to model this as an integer. Then we may have some
elements as follows around the code base:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;data class Address(val streetName: String, val zipCode: Int)

&amp;#x2F;&amp;#x2F; ...

fun getShippingCostForZipCode(zipCode: Int): Cost

&amp;#x2F;&amp;#x2F; ...

fun generatePostalSlip(name: String, zipCode: Int): String
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now consider the case where the company wants to expand to somewhere like the UK which has letters
in their zip code, suddenly we now need to represent the zip code as a &lt;code&gt;String&lt;&#x2F;code&gt;, so we need to go
into all these locations and change them up. If however we had chosen to represent this with its own
wrapper class then it would be pretty simple, we can just change the internal value of the class and
adjust the functionality as required. I know that we have great IDE tooling that can manage this but
that still does not eliminate the large diff that is typically created which will be reviewed or
examined at some later point in time. Having a smaller diff makes it much easier for your colleagues
to understand the actual purpose of the change. In the above example you will be conflating the
adding of the UK marketplace with changing the zip code to a string.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;richer-api&quot;&gt;Richer API&lt;&#x2F;h3&gt;
&lt;p&gt;It is obvious that we have no good reason to add 2 to a customer ID, yet when we simply represent a
customer ID as an integer this is in fact part of the API we provide. Further how many times have
you seen private methods acting on a string to slice it a certain way or format it just so, and then
when you have used it enough times you get the idea to add this to some distant ambiguous &amp;quot;util&amp;quot;
class? This to me is a smell begging us to make some sort of class around this data to expose an API
that matches the domain context and this is precisely what a wrapper class will provide for our
data. One very common one is a name, we see it everywhere represented as a string and then have
utility functions capitalizing the names, getting the first and second name, etc.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;fun printNameForLetter(name: String) {
	println(&amp;quot;${firstNameInitial(name)}. ${capitalizeLastName(name)}&amp;quot;)
}

private fun firstNameInitial(name: String): String {
	&amp;#x2F;&amp;#x2F; ...
}

private fun capitalizeLastName(name: String): String{
	&amp;#x2F;&amp;#x2F; ...
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Such functions are far better suited to its own class where all of this common functionality can be
localized and benefited across all use cases.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;class Name(value: String) {
	val fistNameInitial: String = ...
	&amp;#x2F;&amp;#x2F; ...
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The latter allows for far more reuse due to the proximity and easier to manage any changing
requirements. One great feature of Kotlin it would be naive of me to skip is that it provides
&lt;a href=&quot;https:&#x2F;&#x2F;kotlinlang.org&#x2F;docs&#x2F;reference&#x2F;extensions.html&quot;&gt;extension functions&lt;&#x2F;a&gt; which bridge this gap
and make for a very different design pattern. I am personally still working out the best conventions
as to when add a function to the class or as an extension function. Currently my rule of thumb is if
it will be used elsewhere add it to the class, simply because then when looking for the definition
it is all in one place rather than across several files as extension functions.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Common traps to avoid when using feature toggles</title>
		<published>2020-11-26T00:00:00+00:00</published>
		<updated>2020-11-26T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/feature-toggle-mistakes/" type="text/html"/>
		<id>https://maccoda.github.io/feature-toggle-mistakes/</id>
		<content type="html">&lt;p&gt;In a &lt;a href=&quot;&#x2F;software_concepts&#x2F;feature_toggles_intro&quot;&gt;previous blog&lt;&#x2F;a&gt; post I discussed the benefits of feature toggles and how they unlock the ability to have true continuous delivery. As with everything there are certainly ways in which you should not use these or traps to avoid that I wanted to share also.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;aim-for-short-lived-toggles&quot;&gt;Aim for short lived toggles&lt;&#x2F;h2&gt;
&lt;p&gt;Creating a feature toggle does not come for free, it adds extra branching within the code base and
is extra maintenance for all involved. To mitigate this excess cost you should strive to keep
feature toggles as short lived as possible. Once the feature has been launched a task should be queued
up to remove the touch points of this feature toggle.&lt;&#x2F;p&gt;
&lt;p&gt;A key benefit to keeping them short lived is that we do not allow the code complexity to creep up.
It is not that difficult to imagine having several features being developed in parallel that could
have some overlap of location within the code base. In this case the developer adding in the second feature needs
to implement it on both sides of the feature toggle since they cannot be certain that the previous
feature is fully launched as that is the nature of the feature toggles, it could be turned off at
any moment.&lt;&#x2F;p&gt;
&lt;p&gt;Another reason for early removal is that keeping code around that is using the feature toggle well after it has been launched is dead code but dead code that your compiler cannot let you know about. This just bloats your code base and will likely confuse developers not privy to the currently launched state.&lt;&#x2F;p&gt;
&lt;p&gt;A rarer issue is that people may become dependant on the feature toggles to set up the system into a
certain state because it exists for so long. Most feature toggle services allow for overrides for
specific identifiers which means these can easily be misused and hiding a shortcoming in the system.
This is particularly problematic for testing as one can build guidance for getting the system to a
certain state based on these feature toggles.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;do-not-use-them-as-online-configuration&quot;&gt;Do not use them as online configuration&lt;&#x2F;h2&gt;
&lt;p&gt;Do not do this, please! Whilst these are a very cheap way to manage online configuration they are certainly a very bad way to do it. This is not the purpose of feature toggles as this promotes long lived feature toggles which is discussed above. If you wish to have online configuration with a graphical interface there are many alternatives to do this that are built with this purpose, it is just never good to conflate the purpose of a tool as you don&#x27;t always know the implications particularly since certain design decisions may have been made based on assumed use cases.&lt;&#x2F;p&gt;
&lt;p&gt;Even more importantly though is now throughout the code base a feature toggle could now be two things, either launching a feature or a configuration manager. As with all things if it is not clear people will misinterpret and make mistakes.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;keep-the-checks-on-the-feature-toggle-to-as-few-as-possible&quot;&gt;Keep the checks on the feature toggle to as few as possible&lt;&#x2F;h2&gt;
&lt;p&gt;This is similar to just diving into writing code before giving it any thought. You should not just
add a feature toggle check on a whim but instead should spend some time thinking about the best
location for it. The criteria to optimize for the &lt;em&gt;best location&lt;&#x2F;em&gt; would be the following:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Reduce the number of systems that need to perform the check&lt;&#x2F;li&gt;
&lt;li&gt;Reduce the number of touch points in each system for the feature toggle&lt;&#x2F;li&gt;
&lt;li&gt;Ensure it gates the entire feature&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The third point I will explain further later, so I will elaborate on the first two. For both of these there is a common theme of reducing the scope of influence the feature toggle has.&lt;&#x2F;p&gt;
&lt;p&gt;We want as few systems&#x2F;services as possible to have to know about a single feature, similarly to how
we want the domain to be scoped to the correct context. I am not saying here that you should force
it to be in as fewer systems as possible but you should always assess before you add a dependency of
a feature toggle to a system. A simple check is to ask &amp;quot;Does this system care or need to know about
feature X?&amp;quot;, if it does not need to know about the feature it certainly does not need to know about
the feature toggle.&lt;&#x2F;p&gt;
&lt;p&gt;Once we have determined which systems&#x2F;services should house the feature, we then want to also limit
the number of places we need to perform a check of the feature toggle within them. The less
conditional forking we add to the code the simpler it is and in particular the simpler it is to
remove the checks once the feature is launched. I once had to remove a dispersed feature toggle with tens of places across
multiple systems which was a very slow process not only because of the amount of changes required
but because when a feature is spread that thin it is very easy for it to become coupled to other
elements. When this occurs it can tend not to be just the removal of the if branch but can sometimes
require an entire refactor. To avoid this scenario I do recommend that once you know which system&#x2F;service is
responsible for the feature really consider the design for how you can enable the feature and
consider the cost of clean up. If required perform a refactoring prior to make it easier to have
fewer touch points. Personally I always strive to have a single touch point where possible.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;avoid-needing-more-than-one-toggle-per-feature&quot;&gt;Avoid needing more than one toggle per feature&lt;&#x2F;h2&gt;
&lt;p&gt;The benefit of feature toggles is that they allow for a controlled launch with percentage based launches. This benefit can easily be forfeited if we are not careful about how you choose to gate your features. What you should strive for is one toggle for one feature to be launched. Let&#x27;s go through a counter example to explain why.&lt;&#x2F;p&gt;
&lt;p&gt;Imagine we needed to implement a new feature where we needed some changes in system A and system B.
We decide in this case that we should use one feature toggle in each service because we do not want
to share across services (this is our mistake). We then get on and complete the tasks for each of
the services. When it comes time to launch we realise that we actually cannot dial them up
independently! This is because feature toggles typically use some identifier to ensure that they
show the same treatment for the same customer, since we now have two toggles we have no guarantee
that the same customer sees the feature in both services. So what happens if we need this to be on
across both services (as if it is not we will either provide a poor customer experience or
get them into a unexpected state)? The only way to ensure we do not place any customers in such a state
is we turn them both on fully at the same time! This may not seem bad and in plenty of cases it
isn&#x27;t but when your customer base is large enough you can be going from 0 to thousands of customers
instantly.&lt;&#x2F;p&gt;
&lt;p&gt;What exactly does this mean now? Well we have lost the ability to slowly test our feature out as we
slowly crank up the feature. We have lost the ability to experiment on the feature and see if it is
valuable or not. Mainly we have lost the most significant safety net we had.&lt;&#x2F;p&gt;
&lt;p&gt;The moral of this point is that just because you have service boundaries does not equate to feature boundaries. Always consider the launch strategy when choosing the number of toggles and the touch points.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Introduction to Layered Architecture</title>
		<published>2020-10-11T00:00:00+00:00</published>
		<updated>2020-10-11T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/software_concepts/basic-layered-architecture/" type="text/html"/>
		<id>https://maccoda.github.io/software_concepts/basic-layered-architecture/</id>
		<content type="html">&lt;p&gt;The inspiration of this post is I have worked with a few interns lately and the biggest sticking
point they have is from going from the problem solving in a single function as typical of most
computer science work to creating an application across multiple files and focusing on reusability
and adaptability to change. It is a big jump going from the mindset of pure computer science degree
and solving problems with the goal of correctness and optimization whereas once in the industry the
priorities shift to being able to change with changing requirements. With this article I intend to
show a simple first step by using the layered architecture.&lt;&#x2F;p&gt;
&lt;p&gt;When starting out on a new project the hardest thing to do is organise the architecture. What
packages&#x2F;modules should I make? Where should I put this class? Should this piece of work be its own
class? A really safe place to start with is the layered architecture, there are plenty of articles
and books on this regarding if it is the best approach and in more depth. My goal from this article
is solely to help those working on one of their first projects be able to structure their code.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;What exactly is the layered architecture?&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The layered architecture as the name suggests splits your code into layers. Typically there are 3
for a web service, 4 if you have a UI. There is the controller layer which handles requests to your
service, the service or domain layer which has the business logic of your application, and finally
the repository or persistence layer. If you have a UI you will also want to have a presentation
layer.&lt;&#x2F;p&gt;
&lt;p&gt;Typically the rule of thumb here is that each layer can only have dependencies on the same level
layer or below. Again I want to stress though that there are different ways of doing this and
arguably better when mixed with this design approach but I have found this to be a great starting
design to make the initial progress. I can hopefully go over other architecture patterns in future
articles.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;controller-layer&quot;&gt;Controller layer&lt;&#x2F;h2&gt;
&lt;p&gt;In a typical web application this layer will be the one responsible for accepting the web requests.
This is where you want to do your input validation and then pass across the sanitized inputs to the
service&#x2F;domain layer.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;@Controller(&amp;quot;&amp;#x2F;users&amp;quot;)
class UserController(private val userService: UserService) {
  @Get(&amp;quot;&amp;#x2F;{id}&amp;quot;)
  fun getUser(id: Int): User {
    return userService.getUser(id) ?: build404Error()
  }

  @Post
  fun addUser(userDetails: UserDetails) {
    &amp;#x2F;&amp;#x2F; Validation logic
    if (userDetails.name.isNullOrBlank() || userDetails.password.isNullOrBlank()) {
      return build400Error()
    }
    userService.addNewUser(userDetails)
  }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;service-domain-layer&quot;&gt;Service&#x2F;Domain layer&lt;&#x2F;h2&gt;
&lt;p&gt;Depending on which crowds you chat with or which framework this layer may get a different name
however the purpose is the same. This layer contains the logic for the business logic of your
application. This is the more important part of your application as this is the section that makes
it do what it does. If you are making a bank application this is where you handle transactions and
checking balances, if it is a retail application you work with the shopping cart, etc.&lt;&#x2F;p&gt;
&lt;p&gt;The domain layer should not have any dependencies on any other layer. The main reason for this is
the other layers should ideally be able to be changed easily (although you would not want to do this
often) and have no impact on how the business logic works. I realize this is a little contradicting
to the first point I made about only knowing about layers on the same level and below but this is
where you realize that there are elements of software that are more of a craft than a hard science.
For this layer specifically what you want to avoid is it knowing anything about the infrastructure,
that is it should not know that it receives requests as a HTTP call, or it persists data in a
particular format using a certain SQL database. This should be abstracted away so the controller
should convert it to a domain object this layer can use and the persistance layer should have a high
enough abstraction in its API so this does not need to know of the logistics of how the data is
stored.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;class UserService(private val userRepository: UserRepository) {
  fun addNewUser(userDetails: UserDetails) {
    val maybeExistingUser = userRepository.findWithName(userDetails.name)
    if (maybeExistingUser != null) throw UserAlreadyExists(userDetails.name)

    userRepository.save(userDetails)
  }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;persistence-layer&quot;&gt;Persistence layer&lt;&#x2F;h2&gt;
&lt;p&gt;This is where you implement the logic for persisting the entities to the format used by your
application. This can be to a database, a flat file or in memory. As stated above you want this API
to be abstracted away from the actual implementation details. Doing this will allow you to quickly
get started and then allow you to change the persistence mechanism as the project grows, for example
I typically start with a flat file to get started and move to a database once (or if) it is needed.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;class UserRepository(private val dataStore: DataStore) {
  fun save(userDetails: UserDetails) {
    val user = User(name = userDetails.name, password = Encryptor.encrypt(userDetails.password))
    dataStore.insert(user)
  }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;presentation-layer&quot;&gt;Presentation layer&lt;&#x2F;h2&gt;
&lt;p&gt;This layer can take on many forms, it could be your sparkly new React frontend or could simply be a
HTML page served from your server. Regardless this layer needs to be separate and only have the
responsibility of taking the returned data and displaying it.&lt;&#x2F;p&gt;
&lt;p&gt;For this example I will not provide an example as there are many things it could be, it could be the
entire single page application that is making JSON API calls to the server and building the user
interface. Another alternative if it is server side rendered or simply a desktop application, is it
could be a template that receives the output of the controller layer and knows how to format and
arrange the data on the page.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;faq&quot;&gt;FAQ&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;what-should-i-do-if-i-have-to-call-another-service-or-api&quot;&gt;What should I do if I have to call another service or API?&lt;&#x2F;h3&gt;
&lt;p&gt;When considering these classes it is the hexagonal architecture that starts to have a better fit
however I like to think of these at a similar location as the persistence layer as you typically
interact with a database in a similar fashion to another web service. A lot of databases nowadays
are just web APIs. The key part here is this should be separate from your domain logic.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;how-should-i-split-my-domain-layer&quot;&gt;How should I split my domain layer?&lt;&#x2F;h3&gt;
&lt;p&gt;There are many ways to slice your domain layer and the package, directory, or module structure has
so many varieties. One that I have begun to enjoy working with is feature&#x2F;functionality based
splits. An example being for a banking application you can create a separate module for interacting
with bank accounts and a separate one for interacting with customers. There of course may be overlap
and I guarantee you that the functionally will not be as clear as the obvious examples I or others
may provide, so allow flexibility as you may not get it right the first time. The concept to
consider is that you should strive to be able to define a clear API into your module that defines a
use case of your application. The goal is that the module should only change for one business
reason.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;If I have missed a common question or one you would like answered please raise an issue on this
repository and I will gladly answer and update this post.&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Why you no longer need feature branches</title>
		<published>2020-07-11T00:00:00+00:00</published>
		<updated>2020-07-11T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/software_concepts/feature-toggles-intro/" type="text/html"/>
		<id>https://maccoda.github.io/software_concepts/feature-toggles-intro/</id>
		<content type="html">&lt;p&gt;The core of what software engineers do is add new and improved features to a service or application. We add a feature the customer requested or address some technical debt. Some of these features can take hours to complete whilst others weeks. All the while you are part of a whole team working on numerous features at once, so the question comes how do merge all these features together once they are ready?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;feature-branches&quot;&gt;Feature Branches&lt;&#x2F;h2&gt;
&lt;p&gt;One such option is to use feature branches, of the popular workflow &lt;a href=&quot;https:&#x2F;&#x2F;www.atlassian.com&#x2F;git&#x2F;tutorials&#x2F;comparing-workflows&#x2F;gitflow-workflow&quot;&gt;Gitflow&lt;&#x2F;a&gt;, where a new branch is forked off the main branch and all feature development completed on this branch. The branch is then merged back on when the feature is completed. The benefit here is the isolation from the main branch so it is not disturbed with a half complete feature. It also means that as each feature is completed the merge request only needs to focus on the feature being merged and is independent from any other features that are being worked on in parallel.&lt;&#x2F;p&gt;
&lt;p&gt;There are some points of concern here. If you are the lucky or unlucky one, your choice, working on the larger feature then you are constantly needing to merge changes from the main branch as each new smaller feature, bug fix, or any work is committed. This adds a fair bit of churn to this workflow as the developer on this larger feature will be going back and forth between solving merge conflicts and implementing the feature.&lt;&#x2F;p&gt;
&lt;p&gt;This then extends the time it takes for the feature to be completed, leading to the second concern that we end up having long lived feature branches and we start to lose continuous integration. The longer a feature branch lives the more it diverges and the greater the risk of the merge. One way we can definitely improve this is the feature definition process to make these as small as possible but that is separate from the point of this article.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;enter-feature-toggles&quot;&gt;Enter Feature Toggles&lt;&#x2F;h2&gt;
&lt;p&gt;As continuous delivery has become a more prevalnt concept other solutions have developed working on getting these features out as quickly as possible. What this has resulted in is the notion of feature toggles.&lt;&#x2F;p&gt;
&lt;p&gt;Feature toggles at its simplest can be thought of as a switch. It is either off or on. This switch controls whether or not the feature is off or on in our application. Feature toggles have greater functionality than this but let&#x27;s explore the benefits before we delve into those.&lt;&#x2F;p&gt;
&lt;p&gt;A major benefit with feature toggles is its enabling of main branch development, continuous integration just got a whole lot easier. How do we do this? When we start work on our new feature first thing we do is create a feature toggle and wrap our changes in a conditional on the state of the toggle.&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;if (featureToggleService.isLaunched(&amp;quot;NEW_HEADER&amp;quot;) {
	addHeader(document)
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;By doing this it means that we can implement the feature over several commits but since the feature toggle is off in production our new feature code isn&#x27;t activate in production. This also means that the changes become smaller meaning those merge conflicts should be less and less.&lt;&#x2F;p&gt;
&lt;p&gt;The biggest benefit is the separation of feature work completion and feature launch. With the feature branch model it wouldn&#x27;t be unheard of to block the deployment to production or block the merge to the main branch until business, product, or testing team are ready for the launch. This can lead to several problematic circumstances, we have a big bang deployment to production containing a lot of changes so if something does go wrong it is harder to pinpoint the exact issue, or in the case the branch isn&#x27;t merged the developers have to keep this feature branch up to date well after the feature work has been completed. Feature toggles on the other hand allow us to push our code out to production even when it is incomplete. Once the work is completed we can then hand control over to the interested team who is able to be responsible for launching that feature by simply flicking the switch. Decoupling the code completion to the feature launch entirely.&lt;&#x2F;p&gt;
&lt;p&gt;Another element is the safety lever feature toggles provide. In the feature branch model we need to revert all commits and push it through the pipeline if an issues was found. For the feature toggle it is yet again a simple flick of the switch. Not only is there less time and risk in this &amp;quot;roll back&amp;quot; but it can also be controlled by anyone responsible for the feature and not just the engineering team.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;other-functionalities-of-feature-toggles&quot;&gt;Other functionalities of feature toggles&lt;&#x2F;h2&gt;
&lt;p&gt;Hopefully I have been able to show the benefit of feature toggles however the above is not the only benefits we get.&lt;&#x2F;p&gt;
&lt;p&gt;Feature toggles can typically be dialed up progressively, meaning we are able to test it on a smaller audience to see if all goes well prior to everyone getting the change. An example being we could give the new feature to 10% of the customer base, then after an hour move to 50%, etc. Giving even more confidence when launching these features.&lt;&#x2F;p&gt;
&lt;p&gt;We can also usually override the controls for a feature toggle. That is if the testing team want to test the change for a certain test customer or the UX team want to test how actual customers interact with the change this can be done without affecting all customers.&lt;&#x2F;p&gt;
&lt;p&gt;Depending on which feature toggle service you use there may be even more options available, or you might find your company already has one you can improve.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;some-feature-toggle-services&quot;&gt;Some Feature Toggle Services&lt;&#x2F;h2&gt;
&lt;p&gt;Below are a few of the feature toggle services I have heard of:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.split.io&#x2F;&quot;&gt;Split.io&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;launchdarkly.com&#x2F;&quot;&gt;Launch Darkly&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;There are plenty more just have a search for &amp;quot;feature toggle service&amp;quot;, it is also sometimes called &amp;quot;feature flag&amp;quot;&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Speed up your Gitlab pipelines to Heroku</title>
		<published>2020-05-09T00:00:00+00:00</published>
		<updated>2020-05-09T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/speed-up-cd-heroku/" type="text/html"/>
		<id>https://maccoda.github.io/speed-up-cd-heroku/</id>
		<content type="html">&lt;p&gt;Arguably one of the best things one can have for their project is a robust continuous delivery
pipeline. Being able to know that once you commit and push your code there is infrastructure in
place to ensure your change is correct and subsequently deployed is one the things I personally
truly enjoy in software. So when I had some spare time I started tinkering with one of my side
projects in getting it set up and deployed to Heroku. My project is hosted at &lt;a href=&quot;www.gitlab.com&quot;&gt;Gitlab&lt;&#x2F;a&gt; which have
their own integrated CI service and is deployed to &lt;a href=&quot;www.heroku.com&quot;&gt;Heroku&lt;&#x2F;a&gt; a platform as a service (PaaS) provider
which manages a lot of the deployment infrastructure for me, perfect for a side project.&lt;&#x2F;p&gt;
&lt;p&gt;For this project I had set up the following stages:&lt;&#x2F;p&gt;
&lt;div class=&quot;mermaid&quot;&gt;
graph LR
  t[Test]
  pp[Deploy Pre-Prod]
  it[Integration Tests]
  p[Deploy Prod]
  t --&gt; pp
  pp --&gt; it
  it --&gt; p
&lt;&#x2F;div&gt;
&lt;p&gt;Definitely a little more involved than most of my side projects but hopefully it actually closer
represents would you would typically encounter for production services in the industry.&lt;&#x2F;p&gt;
&lt;p&gt;The application I had was a &lt;a href=&quot;www.kotlinlang.org&quot;&gt;Kotlin&lt;&#x2F;a&gt; web server application built with &lt;a href=&quot;www.gradle.org&quot;&gt;Gradle&lt;&#x2F;a&gt; and deployed to
Heroku using a very versatile deployment tool &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;travis-ci&#x2F;dpl&quot;&gt;dpl&lt;&#x2F;a&gt;. All of this definitely worked and did what it
needed to however it took around 17 minutes and there are always things we can improve!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;using-a-cache&quot;&gt;Using a cache&lt;&#x2F;h2&gt;
&lt;p&gt;Gitlab CI runners are declaratively defined and based on &lt;a href=&quot;https:&#x2F;&#x2F;www.docker.com&#x2F;&quot;&gt;Docker&lt;&#x2F;a&gt; containers. Each job executed in
the pipeline you will get an entirely fresh environment which is great to provide a reproducible
environment but this does require the environment to be recreated every time. In the case of Gradle
and the Gradle wrapper this means that on each stage of the pipeline that was using a Gradle task it
would need to download the distribution.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;&#x2F;images&#x2F;gradle-download.png&quot; alt=&quot;gradle download&quot; &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;To avoid needing to download this at each job we can simply add in a &lt;a href=&quot;https:&#x2F;&#x2F;docs.gitlab.com&#x2F;ee&#x2F;ci&#x2F;caching&#x2F;&quot;&gt;cache&lt;&#x2F;a&gt; in our pipeline. This
cache is saved at the end of each job and restored at the start, so it does come with its own cost
but compared to downloading Gradle and all project dependencies it is minor. To achieve this for my
Gradle project I simply changed the directory for where Gradle saved the dependencies and told
Gitlab CI to cache it, with a lot of help from &lt;a href=&quot;https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;34162120&#x2F;gitlab-ci-gradle-dependency-cache&quot;&gt;this StackOverflow question&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;yaml&quot; class=&quot;language-yaml &quot;&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;before_script:
  - export GRADLE_USER_HOME=`pwd`&amp;#x2F;.gradle

cache:
  paths:
    - .gradle&amp;#x2F;wrapper
    - .gradle&amp;#x2F;caches
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Do note that with this configuration your cache will be persisted and restored across all jobs
(assuming you have not placed this in a single job already) so if not all stages require this cache
we could adjust this to shave off some extra time but for now it will do just fine.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;deploying-with-docker-to-heroku-directly&quot;&gt;Deploying with Docker to Heroku directly&lt;&#x2F;h2&gt;
&lt;p&gt;The change that gave me the biggest improvement was by converting my deployment from using the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;travis-ci&#x2F;dpl&quot;&gt;dpl&lt;&#x2F;a&gt;
tool to using the &lt;a href=&quot;https:&#x2F;&#x2F;devcenter.heroku.com&#x2F;articles&#x2F;container-registry-and-runtime&quot;&gt;container registry&lt;&#x2F;a&gt; Heroku provides.&lt;&#x2F;p&gt;
&lt;p&gt;The speed of deployment is less attributed to the dpl tool and more towards how Heroku defaults its
deployments. If you look across all of the Heroku website it shows how simple it is to perform
deployments with git. This is definitely a positive for simplicity of deployment but in doing so it
means that each deployment needs to be built from source each time. Using the registry we are able
to create an immutable, deployable Docker image that we can reuse at each stage of deployment.&lt;&#x2F;p&gt;
&lt;p&gt;First thing you will require is that your application builds to a Docker image, which I will not
delve into here (maybe another post). My application was actually already being deployed through
Docker with dpl by using the &lt;a href=&quot;https:&#x2F;&#x2F;devcenter.heroku.com&#x2F;articles&#x2F;build-docker-images-heroku-yml&quot;&gt;heroku.yml&lt;&#x2F;a&gt; file, so my Docker image was ready to go.&lt;&#x2F;p&gt;
&lt;p&gt;With a deployable Docker image ready the next step is to add a build and publish step to our
pipeline. For those not familiar with publishing Docker images, you can consider Docker images akin
to a release of a library&#x2F;dependency. These are published to some central registry with a specific
identifier and version, the same is done for Docker images. We can publish a specific application
and version to a registry, here it is hosted by Heroku others include &lt;a href=&quot;https:&#x2F;&#x2F;aws.amazon.com&#x2F;ecr&#x2F;&quot;&gt;ECR (AWS)&lt;&#x2F;a&gt; or of course
&lt;a href=&quot;https:&#x2F;&#x2F;hub.docker.com&#x2F;&quot;&gt;DockerHub&lt;&#x2F;a&gt;, which is then fetched and deployed. Coming back now let&#x27;s add this build and publish
step to our pipeline, firstly lets define some variables:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;yaml&quot; class=&quot;language-yaml &quot;&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;variables:
  CONTAINER_IMAGE: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG
  PREPROD_APP_NAME: my-pre-prod-app
  PROD_APP_NAME: my-prod-app
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;These variables will simply make it easy to reference the identifier given to our container image
using some &lt;a href=&quot;https:&#x2F;&#x2F;docs.gitlab.com&#x2F;ee&#x2F;ci&#x2F;variables&#x2F;predefined_variables.html&quot;&gt;variables&lt;&#x2F;a&gt; that Gitlab will populate for us as well as the names of
our Heroku applications. With these in place we can now create a build step, I have added this to my
test stage so the tests and build can run in parallel.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;yaml&quot; class=&quot;language-yaml &quot;&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;build:
  image: docker:19.03.1
  services:
    - docker:19.03.1-dind
  stage: test
  variables:
    HEROKU_PREPROD_IMAGE: registry.heroku.com&amp;#x2F;${PREPROD_APP_NAME}&amp;#x2F;web
    HEROKU_PROD_IMAGE: registry.heroku.com&amp;#x2F;${PROD_APP_NAME}&amp;#x2F;web
  script:
    - docker login --username=_ --password=$HEROKU_API_KEY registry.heroku.com
    - docker build -t $CONTAINER_TEST_IMAGE .
    - docker tag $CONTAINER_TEST_IMAGE $HEROKU_PREPROD_IMAGE
    - docker push $HEROKU_PREPROD_IMAGE
    - docker tag $CONTAINER_TEST_IMAGE $HEROKU_PROD_IMAGE
    - docker push $HEROKU_PROD_IMAGE
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The above follows from the example provided in the &lt;a href=&quot;https:&#x2F;&#x2F;docs.gitlab.com&#x2F;ee&#x2F;user&#x2F;packages&#x2F;container_registry&#x2F;#container-registry-examples-with-gitlab-cicd&quot;&gt;Gitlab documentation&lt;&#x2F;a&gt; with
some tweaks to target the Heroku container registry instead of the Gitlab one. In Heroku each
application has its own container registry, since each stage is its own application we need to push
the built image to both registries.&lt;&#x2F;p&gt;
&lt;p&gt;The one new variable here is the &lt;code&gt;HEROKU_API_KEY&lt;&#x2F;code&gt; which I have injected into the pipeline. This is
the API token that is generated by Heroku to allow access to the API, this can be accessed in your
Heroku account settings.&lt;&#x2F;p&gt;
&lt;p&gt;With the image built and pushed to the Heroku container repository we can now move onto the final
stage which is the actual deployment to Heroku.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;yaml&quot; class=&quot;language-yaml &quot;&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;preprod:
  stage: preprod
  script:
    - apt-get update -qy
    - apt-get install -y curl bash
    - curl https:&amp;#x2F;&amp;#x2F;cli-assets.heroku.com&amp;#x2F;install.sh | sh
    - heroku container:release -a ${PREPROD_APP_NAME} web
  only:
    - master
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The only way to perform the deployment is through the Heroku CLI therefore the first step here
(after obtaining dependencies) is to download the CLI. We can then simply perform the
&lt;a href=&quot;https:&#x2F;&#x2F;devcenter.heroku.com&#x2F;articles&#x2F;heroku-cli-commands#heroku-container-release&quot;&gt;container:release&lt;&#x2F;a&gt; operation which will deploy the most recent version of our built application
from the container registry. The same step can be done for the production stage by simply changing
the app name variable.&lt;&#x2F;p&gt;
&lt;p&gt;Using this technique over &lt;code&gt;dpl&lt;&#x2F;code&gt; the deployment time went down from around 5 minutes to around 1.5
minutes for each deployment! Reducing this deployment time is extremely valuable to allow for the
ability to roll forward with continuous deployment pipelines, as well as a great excuse to learn
something new!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;completed-file&quot;&gt;Completed file&lt;&#x2F;h2&gt;
&lt;p&gt;The completed pipeline file looks something like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;yaml&quot; class=&quot;language-yaml &quot;&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;stages:
  - test
  - preprod
  - integration_test
  - prod

before_script:
  - export GRADLE_USER_HOME=`pwd`&amp;#x2F;.gradle

cache:
  paths:
    - .gradle&amp;#x2F;wrapper
    - .gradle&amp;#x2F;caches

variables:
  CONTAINER_IMAGE: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG
  PREPROD_APP_NAME: my-pre-prod-app
  PROD_APP_NAME: my-prod-app

build:
  image: docker:19.03.1
  services:
    - docker:19.03.1-dind
  stage: test
  variables:
    HEROKU_PREPROD_IMAGE: registry.heroku.com&amp;#x2F;${PREPROD_APP_NAME}&amp;#x2F;web
    HEROKU_PROD_IMAGE: registry.heroku.com&amp;#x2F;${PROD_APP_NAME}&amp;#x2F;web
  script:
    - docker login --username=_ --password=$HEROKU_API_KEY registry.heroku.com
    - docker build -t $CONTAINER_TEST_IMAGE .
    - docker tag $CONTAINER_TEST_IMAGE $HEROKU_PREPROD_IMAGE
    - docker push $HEROKU_PREPROD_IMAGE
    - docker tag $CONTAINER_TEST_IMAGE $HEROKU_PROD_IMAGE
    - docker push $HEROKU_PROD_IMAGE

test:
  stage: test
  # Test step...

preprod:
  stage: preprod
  script:
    - apt-get update -qy
    - apt-get install -y curl bash
    - curl https:&amp;#x2F;&amp;#x2F;cli-assets.heroku.com&amp;#x2F;install.sh | sh
    - heroku container:release -a ${PREPROD_APP_NAME} web
  only:
    - master

integration:
  stage: &amp;quot;integration_test&amp;quot;
  # Integration step...

production:
  stage: prod
  script:
    - apt-get update -qy
    - apt-get install -y curl bash
    - curl https:&amp;#x2F;&amp;#x2F;cli-assets.heroku.com&amp;#x2F;install.sh | sh
    - heroku container:release -a ${PROD_APP_NAME} web
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Kotlin class validation in initialization</title>
		<published>2020-03-22T00:00:00+00:00</published>
		<updated>2020-03-22T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/kotlin-constructor-validation/" type="text/html"/>
		<id>https://maccoda.github.io/kotlin-constructor-validation/</id>
		<content type="html">&lt;p&gt;Recently I was working with a bit of code where we had written validation logic in the constructor.
This was simply validating that the input received from an API call matched what we required. We are
currently migrating some of the code across from Java to Kotlin and whilst most of the time this is
a straightforward process this validation one wasn&#x27;t so smooth.&lt;&#x2F;p&gt;
&lt;p&gt;Let&#x27;s say you have a &lt;code&gt;FullName&lt;&#x2F;code&gt; class that requires both a first and last name that cannot be empty.
We might have a class something like the following:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public class FullName {
  private final String firstName;
  private final String lastName;

  public FullName(final String firstName, final String lastName) {
    if (StringUtils.isBlank(firstName) || StringUtils.isBlank(lastName)) {
      throw new InvalidDataException(&amp;quot;Names must not be blank&amp;quot;);
    }
    this.firstName = firstName;
    this.lastName = lastName;
  }
  &amp;#x2F;&amp;#x2F; getters...
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We want to move this across to a new &lt;code&gt;FullName&lt;&#x2F;code&gt; Kotlin class instead, below are some of the options
we managed create. Each have different styles and benefits so it is up to you which you prefer.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;For these examples I am assuming that &lt;code&gt;firstName&lt;&#x2F;code&gt; and &lt;code&gt;lastName&lt;&#x2F;code&gt; didn&#x27;t have to add a &lt;code&gt;null&lt;&#x2F;code&gt; check.
If this is not the case for you simply change the type to a nullable type and perform the check
using &lt;a href=&quot;https:&#x2F;&#x2F;kotlinlang.org&#x2F;docs&#x2F;reference&#x2F;null-safety.html#safe-calls&quot;&gt;safe calls&lt;&#x2F;a&gt; or similar. Do this so that you do not get an exception throw from the standard
library which is essentially a null pointer exception.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;using-an-init-block&quot;&gt;Using an &lt;code&gt;init&lt;&#x2F;code&gt; block&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;class FullName(firstName: String, lastName: String) {
    val firstName: String
    val lastName: String
    init {
        if (firstName.isBlank() || lastName.isBlank()) {
            throw RuntimeException(&amp;quot;Name cannot be blank&amp;quot;)
        }
        this.firstName = firstName
        this.lastName = lastName
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;Try this &lt;a href=&quot;https:&#x2F;&#x2F;pl.kotl.in&#x2F;0dQNj7Fb2&quot;&gt;in the playground&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;pros&quot;&gt;Pros&lt;&#x2F;h4&gt;
&lt;ul&gt;
&lt;li&gt;This has the same interface as the previous Java class so all calling code should fit nicely&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h4 id=&quot;cons&quot;&gt;Cons&lt;&#x2F;h4&gt;
&lt;ul&gt;
&lt;li&gt;We haven&#x27;t been able to convert to a &lt;code&gt;data class&lt;&#x2F;code&gt; where it may have been similar to one in Java.
This is because a &lt;code&gt;data class&lt;&#x2F;code&gt; requires a public field being present in the primary constructor.
This can easily be overcome by using your IDE to generate the &lt;code&gt;equals&#x2F;hashcode&lt;&#x2F;code&gt; and &lt;code&gt;toString&lt;&#x2F;code&gt;
functions you may have wanted.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;use-a-static-constructor&quot;&gt;Use a static constructor&lt;&#x2F;h3&gt;
&lt;p&gt;Using static constructors is a recommended practice as per Effective Java, so one alternative is to
put the validation logic into such a function so the class becomes simple. In our above I believe it
was done in the way above to match the Spring MVC convention.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;data class FullName private constructor(val firstName: String, val lastName: String) {

    companion object {
        fun of(firstName: String, lastName: String): FullName {
            if(firstName.isBlank() || lastName.isBlank()) {
                throw RuntimeException(&amp;quot;Name cannot be blank&amp;quot;)
            }
            return FullName(firstName, lastName)
        }
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;Try this &lt;a href=&quot;https:&#x2F;&#x2F;pl.kotl.in&#x2F;QfFA6uqJt&quot;&gt;in the playground&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;h4 id=&quot;pros-1&quot;&gt;Pros&lt;&#x2F;h4&gt;
&lt;ul&gt;
&lt;li&gt;We are now able to use the &lt;code&gt;data class&lt;&#x2F;code&gt;&lt;&#x2F;li&gt;
&lt;li&gt;The class itself doesn&#x27;t have a &#x27;smart&#x27; constructor&lt;&#x2F;li&gt;
&lt;li&gt;We are able to make all construction through the static method using &lt;code&gt;private constructor&lt;&#x2F;code&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h4 id=&quot;cons-1&quot;&gt;Cons&lt;&#x2F;h4&gt;
&lt;ul&gt;
&lt;li&gt;We have now changed the signature of the class for the callers of the existing class&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;using-invoke-to-get-both&quot;&gt;Using &lt;code&gt;Invoke&lt;&#x2F;code&gt; to get both&lt;&#x2F;h3&gt;
&lt;p&gt;I have not been able to test how this works with Java interoperability but this option will give you
the best of the above two solutions.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;data class FullName private constructor(val firstName: String, val lastName: String) {

    companion object {
        operator fun invoke(firstName: String, lastName: String): FullName {
            if(firstName.isBlank() || lastName.isBlank()) {
                throw RuntimeException(&amp;quot;Name cannot be blank&amp;quot;)
            }
            return FullName(firstName, lastName)
        }
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;Try this &lt;a href=&quot;https:&#x2F;&#x2F;pl.kotl.in&#x2F;GIfzAHuXR&quot;&gt;in the playground&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Exploring how to use the Law of Demeter</title>
		<published>2020-03-21T00:00:00+00:00</published>
		<updated>2020-03-21T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/software_concepts/demeters-law/" type="text/html"/>
		<id>https://maccoda.github.io/software_concepts/demeters-law/</id>
		<content type="html">&lt;p&gt;First and foremost I should define exactly what the &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Law_of_Demeter&quot;&gt;Law of Demeter&lt;&#x2F;a&gt; is. The Law of Demeter is a
design principle of object orientated software, which is also known as the &lt;strong&gt;principle of least
knowledge&lt;&#x2F;strong&gt;. The essence of the principle is that your code should only know about the classes it is
directly dealing with and should not be overreaching into classes that those classes know. As with
all design principles this is quite intellectual and is difficult to translate to the code we write
day to day. Personally I try and find concrete patterns for these that I can use to check if I am
either infringing or obeying the principle. The Law of Demeter has a pretty easy check if you are
disobeying it:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;If you see a chain of calls (several dots) on a single line you are most likely violating the Law of Demeter&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;A concrete example of this is something like&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;boolean isGmailAccount = account.getProfile()
                                .getEmail()
                                .endsWith(&amp;quot;gmail.com&amp;quot;);
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As you can see here our code has access to some &lt;code&gt;Account&lt;&#x2F;code&gt; class but this class also knows the
internals of the &lt;code&gt;Account&lt;&#x2F;code&gt; class that is used to determine if it is a Gmail account. Checking
against our rule you can easily see it violates the rule as there are &lt;strong&gt;3 dots&lt;&#x2F;strong&gt; for chained calls
and 2 of those are accessing different classes.&lt;&#x2F;p&gt;
&lt;p&gt;I want to make a quick note here that as per every rule there are exemptions. The key part of the
above code is the call chain is accessing different underlying classes. This means that our code
goes from only knowing about the &lt;code&gt;Account&lt;&#x2F;code&gt; class to now also knowing about the &lt;code&gt;Profile&lt;&#x2F;code&gt; and &lt;code&gt;Email&lt;&#x2F;code&gt;
class. Said differently it means that our code is now coupled to the &lt;code&gt;Profile&lt;&#x2F;code&gt; and &lt;code&gt;Email&lt;&#x2F;code&gt; class and
even their implementation. An example where there is a call chain but no extended class
access is easily seen when using combinators on &lt;code&gt;Stream&lt;&#x2F;code&gt;s in Java&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;List&amp;lt;MovieTitle&amp;gt; movieTitles = movies.stream()
                                     .filter(Objects::notNull)
                                     .map(Movie::getTitle)
                                     .collect(toList());
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;example&quot;&gt;Example&lt;&#x2F;h2&gt;
&lt;p&gt;I am going to do a quick example where we work for a bank and we want to send an email to a customer
about our new deal if that customer has a checking account with the bank.&lt;&#x2F;p&gt;
&lt;div class=&quot;mermaid&quot;&gt;
classDiagram
  Customer o-- &quot;1..*&quot; Account
  Account -- AccountType
  class AccountType{
    CHECKING
    SAVINGS
  }
&lt;&#x2F;div&gt;
&lt;p&gt;&lt;em&gt;This diagram is intentionally limited to not distract from the key elements.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;These class all seem like we can represent these as plain data objects, they contain some
values and we just create a whole bunch of getters. This was exactly my typical approach as I
thought &amp;quot;I don&#x27;t need my data classes to be very smart&amp;quot;. So then to implement our requirement above
we may need to write some code like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public void sendPromoEmail(Customer customer) {
  boolean shouldSendPromoEmail = customer.getAccounts()
                                         .stream()
                                         .filter(x -&amp;gt; x.getType() == AccountType.CHECKING)
                                         .findFirst()
                                         .isPresent();
  if (shouldSendPromoEmail) {
    &amp;#x2F;&amp;#x2F; Build promo message ...
    emailService.sendEmail(customer.getEmail(), promoMessage);
  }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This definitely does seem to do the job and we meet the requirements but if you look carefully this
function doesn&#x27;t quite satisfy the Law of Demeter. This function only knows about (or is coupled
with) the &lt;code&gt;Customer&lt;&#x2F;code&gt; class. However because we choose to model our data with simple getters we need
our function to know what is inside a &lt;code&gt;Customer&lt;&#x2F;code&gt;. This function is now coupled with how the
&lt;code&gt;Customer&lt;&#x2F;code&gt; models the &lt;code&gt;Account&lt;&#x2F;code&gt;s it has and is also coupled with the representation of the
&lt;code&gt;AccountType&lt;&#x2F;code&gt; of &lt;code&gt;Account&lt;&#x2F;code&gt;. This coupling is quite subtle and will typically go unnoticed, I
am not even needing to import the &lt;code&gt;Account&lt;&#x2F;code&gt; class for this to work!&lt;&#x2F;p&gt;
&lt;p&gt;The root of the problem here is that we chose to use &lt;strong&gt;dumb data classes&lt;&#x2F;strong&gt; that simply store data. I
am not saying these don&#x27;t work in all cases but I would urge you to consider if by doing so you end
up in the same situation we are in here.&lt;&#x2F;p&gt;
&lt;p&gt;To remove this unneeded coupling we will need the data classes to now tell us more about themselves
rather than us ask about it.&lt;&#x2F;p&gt;
&lt;p&gt;First thing we could do is change the &lt;code&gt;Account&lt;&#x2F;code&gt; class to tell us if it is a checking account.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;class Account {
  private final AccountType type;
  &amp;#x2F;&amp;#x2F; ...
  public boolean isCheckingAccount() {
    return type == AccountType.CHECKING;
  }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then our function becomes:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public void sendPromoEmail(Customer customer) {
  boolean shouldSendPromoEmail = customer.getAccounts()
                                         .stream()
                                         .filter(Account::isCheckingAccount)
                                         .findFirst()
                                         .isPresent();
  if (shouldSendPromoEmail) {
    &amp;#x2F;&amp;#x2F; Build promo message ...
    emailService.sendEmail(customer.getEmail(), promoMessage);
  }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Trust me I know this looks odd and what about all the other account types, does that mean we need to
expand the &lt;code&gt;Account&lt;&#x2F;code&gt; interface for all of this? We may, but only if we ever use them of course. This
encapsulation is a trade off as everything is. By creating this method the &lt;code&gt;AccountType&lt;&#x2F;code&gt; can be
encapsulated withing the &lt;code&gt;Account&lt;&#x2F;code&gt; class, which means if we were ever change the representation or
interface it would now only be the &lt;code&gt;Account&lt;&#x2F;code&gt; class we need to update. We don&#x27;t need to go back to
our &lt;code&gt;sendPromoEmail&lt;&#x2F;code&gt; function or any others that may be doing the same!&lt;&#x2F;p&gt;
&lt;p&gt;We have now removed the coupling with the &lt;code&gt;AccountType&lt;&#x2F;code&gt; and the next to remove is the &lt;code&gt;Account&lt;&#x2F;code&gt;. To
do this we will follow the same pattern but one up the chain. We now want the &lt;code&gt;Customer&lt;&#x2F;code&gt; class to
tell us if it has a checking account rather than us ask for its internals.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;class Customer {
  private final List&amp;lt;Account&amp;gt; accounts;
  &amp;#x2F;&amp;#x2F; ...
  public boolean hasCheckingAccount() {
    return accounts.stream()
                   .filter(Account::isCheckingAccount)
                   .findFirst()
                   .isPresent();
  }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then our function becomes:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public void sendPromoEmail(Customer customer) {
  boolean shouldSendPromoEmail = customer.hasCheckingAccount();
  if (shouldSendPromoEmail) {
    &amp;#x2F;&amp;#x2F; Build promo message ...
    emailService.sendEmail(customer.getEmail(), promoMessage);
  }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;There we have it, we have removed the &lt;code&gt;Account&lt;&#x2F;code&gt; coupling in our function and it only knows about the
&lt;code&gt;Customer&lt;&#x2F;code&gt; class and its interface. Now any changes to the &lt;code&gt;Account&lt;&#x2F;code&gt; class never reach this method
and can ideally all be handled in the &lt;code&gt;Customer&lt;&#x2F;code&gt; class.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Don&#x27;t fret over it not being perfect</title>
		<published>2020-03-07T00:00:00+00:00</published>
		<updated>2020-03-07T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/premature-gold-plating/" type="text/html"/>
		<id>https://maccoda.github.io/premature-gold-plating/</id>
		<content type="html">&lt;p&gt;Software is such a young and unique stream of engineering. Almost always we cannot physically see
the product that we produce as opposed to civil engineers for example, who have their buildings and
bridges to see and test. Along with this however comes a much higher cost and risk of their design
requiring to be right the first time round. On top of this many people will be using these final
products and a failure won&#x27;t mean that they can&#x27;t double tap to like some celebrities new fad diet.&lt;&#x2F;p&gt;
&lt;p&gt;Whilst this may sound like it is belittling the work we do as an industry, but the truth is this is
a super power that we have over every other stream of engineering. Once they have built and shipped
a car to the end customer, they cannot simply add a minor improvement to the brake pads and then
update all existing customers and still make a profit. We however can! This iterative development
cycle is one of the key factors of agile development and our ability to adapt to the change in
requirements. This is why we can pull out concepts like Kanban and Scrum, and then single out
the deficiencies of waterfall in our industry, something that works so well in others.&lt;&#x2F;p&gt;
&lt;p&gt;In my opinion one of the core pieces and that which I wanted to share some thoughts on is the
iterative versus upfront design. In particular my experience with this in a team working with Kanban
and how important it is reflect on your working process to avoid eventually grinding to a glacial
speed.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;iterative-vs-upfront-design&quot;&gt;Iterative vs upfront design&lt;&#x2F;h2&gt;
&lt;p&gt;One of the key aspects of Agile is in the name itself, have the agility to change how your product
develops. This is as opposed to the classic approach of completing all the design upfront before we
even build the first tiny piece. In this upfront design we will typically be inundated with
documentation and discussions on all possibilities. Again I emphasize that this has worked well in
numerous other industries but in the software industry I just don&#x27;t believe it is a good fit. Doing
all this design upfront forces us to ask all the questions and have all the answers before we can
even start to test any of our hypotheses.&lt;&#x2F;p&gt;
&lt;p&gt;I have found that we can also use this mindset from the scale of an entire product, on a single
service, or even a single card from the backlog. This single card level is where I want to focus on
for the rest of this post.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;iterative-development-with-kanban-cards&quot;&gt;Iterative development with Kanban cards&lt;&#x2F;h2&gt;
&lt;p&gt;Previously I had worked in a team following the Kanban approach, I won&#x27;t go into details about this
style of working here, but the main point is we had our projects sliced up into smaller tasks which
we would pick up on to work on. It is these tasks or cards that I started to notice we were falling
into a lot of upfront design, gold plating, and what if scenarios. At first I thought this to be
good practice, designing for the worst and hoping for the best. It wasn&#x27;t until after a few months
that I noticed this was starting to decay our work process, card scopes began to increase once work
had started, cards were starting to overlap with other cards making dependencies we didn&#x27;t want, as
well when it came time to hand over we had to define a whole new set of definition of done.&lt;&#x2F;p&gt;
&lt;p&gt;My thoughts as to why this occurred was based on the fact we were prematurely gold plating our
solution, particularly since it was a new project were we were continually discovering new
requirements. My learning from this can be boiled down to the following topics:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Watch the scope creep in cards&lt;&#x2F;li&gt;
&lt;li&gt;Define and stick to acceptance criteria&lt;&#x2F;li&gt;
&lt;li&gt;Utilize user stories to understand what you are achieving&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;watch-the-scope-creep-in-cards&quot;&gt;Watch the scope creep in cards&lt;&#x2F;h3&gt;
&lt;p&gt;In our work process we had groomed all the cards prior to them being ready to be picked up, that
meant there was a pretty scope of what was required from the card, which had input from the
developers. However there will always come a time when you miss a subtle requirement or you find to
do this you need that. At this point it is very tempting to switch gears and take on the new found
task but you should avoid this as it then introduces new scope into your current card. Particularly
in a Kanban style of working where you are focussed on flow of work, increasing the scope of a card
is particularly problematic.&lt;&#x2F;p&gt;
&lt;p&gt;When you do find these new requirements or pre-requisites, don&#x27;t view it as a fault in your process for not
knowing this beforehand but rather see if you can carve up a new card to capture these new
requirements. Doing it this way means that any dependencies on your current work won&#x27;t get blocked
and it may even be able to be picked up by another team member immediately so it can be completed in
parallel.&lt;&#x2F;p&gt;
&lt;p&gt;If this new piece of work is a dependency on your current card it is still possible to split it into
a new card and not block yourself. Consider how you could put in a stub or something of the sort
which will allow you to progress and for that stub to be removed&#x2F;implemented as part of the card you
have just created.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;define-and-stick-to-an-acceptance-criteria&quot;&gt;Define and stick to an acceptance criteria&lt;&#x2F;h3&gt;
&lt;p&gt;One of the great parts of the work process I had in this team was that we had a close working
relationship with QA. When we picked up a new card we defined an acceptance criteria or a definition
of done for that card. This was typically a bullet point list of some use cases QA could test
against and what they were to expect. What I ended up learning was that this was as useful to me as
a developer (if not more) as it was for QA. If I stuck to only implementing this acceptance criteria
then I could easily avoid over complicating the implementation. This meant that it was even more
important that I participate and understand where this acceptance criteria came from and really
focus on breaking down that barrier that we see all too often between developers and QA.&lt;&#x2F;p&gt;
&lt;p&gt;Only focusing on the acceptance criteria can mean that you know that there may be some
implementation detail you believe is missed. Again write this up into a new card because time and
time again I have found that I expected something was required only to find out later it is covered
by something else, requirements change, or I made incorrect assumptions. It more than likely is
better to write a card which captures your thoughts in the moment and reevaluate its importance
later on when you are ready to pick it up.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;utilize-user-stories-to-understand-what-you-are-achieving&quot;&gt;Utilize user stories to understand what you are achieving&lt;&#x2F;h3&gt;
&lt;p&gt;Finally when implementing a new piece of functionality it is always so much more satisfying if you
know the impact you will be having on customers. This is where user stories provide the answer.
Defining at least one user story for the card you are going to pick up feeds into a lot of positive
processes indirectly. Having a user story means that defining acceptance criteria will be simpler as
it is based on this user story. When you are considering the scope of work you need to complete
again this user story provides that basis on which you can check if your expected implementation
will handle that scenario.&lt;&#x2F;p&gt;
&lt;p&gt;Whilst I have mentioned the user story to a particular card sometimes this is difficult and one user
story may span several cards and hence the right place to create such a story is during the grooming
session.&lt;&#x2F;p&gt;
&lt;p&gt;The main aspect of gold plating this user story achieves is it helps us bring our attention to what
actual functionality we want to deliver to our customer and not all the ones that we think we want
to deliver.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Making it Immutable</title>
		<published>2019-07-21T00:00:00+00:00</published>
		<updated>2019-07-21T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/software_concepts/immutability/" type="text/html"/>
		<id>https://maccoda.github.io/software_concepts/immutability/</id>
		<content type="html">&lt;p&gt;Mutability in terms of software usually will describe the ability to change the internal state of an
object once it has been created. Many main design decisions on frameworks and conventions favored
having mutable objects and didn&#x27;t really touch on the concept of immutability. The clearest example
of this is the POJO concept in Java, or more specifically the notion of getters and setters.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-notion-of-getters-and-setters&quot;&gt;The Notion of Getters and Setters&lt;&#x2F;h2&gt;
&lt;p&gt;I will take a short tangent for those not familiar but if you are please skip ahead.&lt;&#x2F;p&gt;
&lt;p&gt;In a typical Java object you will encapsulate fields by making them &lt;code&gt;private&lt;&#x2F;code&gt; and unable to be
directly accessed. The access to these internal fields are usually protected by getters and setters,
which simply get the current value and update the field respectively. A basic example for getting
and setting the name of a person can be seen below.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public class Person {
    private String name;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;why-the-change-of-mind&quot;&gt;Why the Change of Mind?&lt;&#x2F;h2&gt;
&lt;p&gt;So if we made all these decisions in languages and frameworks that are now so popular why should I
even need to know this? Well this may be a little bleak but in software just because something is
popular unfortunately does not mean it is good or right. I would almost argue that it is very hard
to find something good in software because designs can be so subjective and things simply move so
fast that we can suddenly do things that we couldn&#x27;t do when our first decisions were made.&lt;&#x2F;p&gt;
&lt;p&gt;My favorite comparison is comparing older languages to more modern languages. A simple example is
Java vs Kotlin. Whilst these both live in a similar realm of the language space I don&#x27;t believe you
can justly compare them as they both came from different times when we knew different things. Java
is much older than Kotlin, which was a language specifically designed to bake in all the Java best
practices into a language. The fact that we can make an entirely new language with the goal to
simply enforce best practices is a clear sign that as an industry we discover new and better
things arguably daily.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;immutability-is-now-part-of-the-language&quot;&gt;Immutability is now part of the language&lt;&#x2F;h3&gt;
&lt;p&gt;In this example one of the things that Kotlin has added that Java didn&#x27;t have (at least when Kotlin
first came out) was the notion of immutability. In Java (and many other languages of the time) the
notion of immutability is not as evident. It has the &lt;code&gt;final&lt;&#x2F;code&gt; keyword to enforce variables are set
only once but it is an extra keyword always needed to be added and certainly not what you learn in
most beginner courses. Whereas more modern languages have introduced separate keywords for a mutable
and immutable variable. This makes the thought about this variable&#x27;s mutability far more apparent.&lt;&#x2F;p&gt;
&lt;p&gt;Let us take a really basic example of getting a result back from a method invocation. In Java I can
simply make the types line up and we are good to go. I can almost forget about the mutability
question because it isn&#x27;t required at all. In fact this happens a lot for me so I have actions
performed on save to add the &lt;code&gt;final&lt;&#x2F;code&gt; keywords for me.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;String result = myObject.invoke();
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;But if I want it immutable I need to remember my &lt;code&gt;final&lt;&#x2F;code&gt; keyword:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;final String result = myObject.invoke();
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Whereas in Kotlin, thanks to advances in what we can achieve within the compiler the notion of
making the types line up is not as important and the developer&#x27;s responsibility is to choose the
correct keyword to define the mutability of the result.&lt;&#x2F;p&gt;
&lt;p&gt;If the result is to be immutable&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;val result = myObject.invoke()
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If the result is to be mutable&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;var result = myObject.invoke()
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As you can see from this example, the notion of immutability has become more prevalent in the
developers decisions. To the point where the compiler can tell you that the mutable variable you
made could actually be mutable.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;mutability-can-bite&quot;&gt;Mutability can bite&lt;&#x2F;h3&gt;
&lt;p&gt;So we have explored how the notion of mutability is now brought closer to front in terms of our
development, but still have not answered why? The answer is pretty simple, making everything mutable
and not addressing that upfront led to a large cognitive load for developers and with that bugs will
follow. The issue is embedded in the fact that it lead to objects having vast amounts of way of
changing state. The more possible states an object could be in the harder it is to reason with and
that is what happened.&lt;&#x2F;p&gt;
&lt;p&gt;An immutable object is one that is set at construction and has no way in which it is able to change
afterwards. Of course this does come with a few issues you need to keep track of and I will discuss
those later. The main point I want to express here is that mutability can cause difficult to manage
code and we should be aware of our decision to use mutable or immutable objects.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;converting-to-immutable-objects&quot;&gt;Converting to Immutable Objects&lt;&#x2F;h2&gt;
&lt;p&gt;So we have hinted at why you might want to try immutability but how can you do it? Every language
has its own way to manage immutability and the extent to which you can achieve immutability. We will
stick with Java for the time being. Let&#x27;s return to the person example before but make it a little
more interesting. Let&#x27;s say the person has a name and a phone number and we want to make it a basic
immutable object. It would look something like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public final class Person {
    private final String name;
    private final String phoneNumber;

    public Person(String name, String phoneNumber) {
        this.name = name;
        this.phoneNumber = phoneNumber;
    }

    public String getName() {
        return name;
    }

    public String getPhoneNumber() {
        return phoneNumber;
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The key points to note:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Whilst not exactly data immutable, having the &lt;code&gt;final class&lt;&#x2F;code&gt; means that the class is immutable and
cannot be extended&lt;&#x2F;li&gt;
&lt;li&gt;&lt;code&gt;private final&lt;&#x2F;code&gt; variables ensure they are set once and only available within the class scope&lt;&#x2F;li&gt;
&lt;li&gt;There are no setters, only getters&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;not-everything-is-perfectly-immutable&quot;&gt;Not Everything is Perfectly Immutable&lt;&#x2F;h3&gt;
&lt;p&gt;Whilst the above example is the closest we can get to perfect immutable in Java there are some
things to consider with these, since Java as a language chose mutability as the default.&lt;&#x2F;p&gt;
&lt;p&gt;One of the biggest confusions is that following those steps above is all you need for it to be
immutable but let us consider an extension on the example. Let&#x27;s say that this person object now
needs to cater for multiple phone numbers and my naive implementation is to do this by using a list.
Perhaps it could look something like the following:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public final class Person {
    private final String name;
    private final List&amp;lt;String&amp;gt; phoneNumbers;

    public Person(String name, List&amp;lt;String&amp;gt; phoneNumbers) {
        this.name = name;
        this.phoneNumbers = phoneNumbers;
    }

    public String getName() {
        return name;
    }

    public List&amp;lt;String&amp;gt; getPhoneNumbers() {
        return phoneNumbers;
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now this looks pretty good, all our data is only set once and we only have getters. The problem here
is that a &lt;code&gt;List&lt;&#x2F;code&gt; is not an immutable object whereas it just so happened in our earlier example
&lt;code&gt;String&lt;&#x2F;code&gt; was. Let&#x27;s delve a little deeper into how immutability breaks here.&lt;&#x2F;p&gt;
&lt;p&gt;The client code for the above &lt;code&gt;Person&lt;&#x2F;code&gt; class could look something like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;List&amp;lt;String&amp;gt; numbers = person.getPhoneNumbers();
numbers.add(&amp;quot;555444333&amp;quot;);
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Despite the poor choice of example phone number there is also something else concerning here, the
client is modifying the list of phone numbers. Now sure enough because the &lt;code&gt;Person&lt;&#x2F;code&gt; class returns
the reference to their internal field this is going to modify the state of the original &lt;code&gt;person&lt;&#x2F;code&gt;
object.&lt;&#x2F;p&gt;
&lt;p&gt;Let&#x27;s have a look at what I mean by that (the comments on the right show the value printed)&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;Person person = new Person(&amp;quot;Frank&amp;quot;, new ArrayList&amp;lt;&amp;gt;());

System.out.println(person.getPhoneNumbers().size()); &amp;#x2F;&amp;#x2F; 0

List&amp;lt;String&amp;gt; numbers = person.getPhoneNumbers();
numbers.add(&amp;quot;555444333&amp;quot;);

System.out.println(person.getPhoneNumbers().size()); &amp;#x2F;&amp;#x2F; 1
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So even without any setters we can see that we have still actually written an interface that allows
mutability, but we really want this to be an immutable object so how can we do this? Unfortunately
this does involve a little bit of work in Java but certainly does give us the immutability benefits
so if it is what you are working for then definitely the cost is worth it.&lt;&#x2F;p&gt;
&lt;p&gt;The general practice is you need to return the value not the reference. For a list this is by making
a copy of the list and returning that.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Warning&lt;&#x2F;em&gt;: Making a shallow copy may not always be enough, if the contained object is not immutable
then a deep copy is necessary.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;things-to-be-aware-of-with-immutability&quot;&gt;Things to be aware of with Immutability&lt;&#x2F;h2&gt;
&lt;p&gt;Nothing is a silver bullet and immutability certainly has some caveats to be aware of, here are a
few obvious ones:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;If the type returned from the getters is not immutable itself, then your class has just become
mutable. (Refer to above section)&lt;&#x2F;li&gt;
&lt;li&gt;Java does support reflection so people can get fancy with this.&lt;&#x2F;li&gt;
&lt;li&gt;A lot of frameworks have been built based on mutability so can be difficult to integrate&lt;&#x2F;li&gt;
&lt;li&gt;Can create many copies of objects which can be costly&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;The last one is particularly important and one of the main reasons immutability wasn&#x27;t popular
earlier. Having pure immutable objects means that you need different copies for every possible value
which can consume a lot of your memory resources. Obviously we have a lot more memory we can use
nowadays but that does not mean we can disregard this limitation. When making objects immutable
consider this, particularly when needing to perform deep copies as these are certainly not free.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;benefits-of-immutable-objects&quot;&gt;Benefits of Immutable Objects&lt;&#x2F;h2&gt;
&lt;p&gt;Finally, why am I writing about this, why tell people to aim for immutability where possible? Quite
simply it makes me think less. In our profession as counter intuitive as that may sound I find it is
a big influencer because there will always be other difficult things wanting your attention.&lt;&#x2F;p&gt;
&lt;p&gt;If you have immutable objects you do not need to worry about shared state and who is modifying what.
This particularly becomes useful in concurrency. You can share as many immutable objects between
thread as you want and you won&#x27;t have to worry about landing in a corrupt state because you cannot
modify the state of the object but only create a new one.&lt;&#x2F;p&gt;
&lt;p&gt;For the simplicity it has added to my development I would definitely recommend choosing immutable as
your standard and then consciously making the decision to make your classes mutable. This has even
become a standard for programming languages themselves, Rust is an example of such a language.&lt;&#x2F;p&gt;
&lt;p&gt;Regardless of if you agree or not on the value of immutability, I urge you to at least consider the
mutability facet of a class when you are designing and not let it be an after thought because the
language you develop in doesn&#x27;t accentuate it.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Intro to the basics of TDD</title>
		<published>2019-07-21T00:00:00+00:00</published>
		<updated>2019-07-21T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/software_concepts/tdd/" type="text/html"/>
		<id>https://maccoda.github.io/software_concepts/tdd/</id>
		<content type="html">&lt;p&gt;TDD is definitely quite the polarizing topic in my experience, whilst not
everyone may agree with it I believe it is always valuable to understand it and
develop your own opinion on it.&lt;&#x2F;p&gt;
&lt;p&gt;TDD stands for Test Driven Development and was made made popular by Kent Beck.
It is an option of development process that we as software engineers can
consider. A wispy way to describe it that instead of the typical practice of
writing tests after production code your write it up front. I don&#x27;t know about
you but when I was first introduced to this I thought it was pretty crazy. Let&#x27;s
explore it a little further are there is more to it than simply writing your
tests first.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-tdd-cycle&quot;&gt;The TDD Cycle&lt;&#x2F;h2&gt;
&lt;p&gt;A core part of TDD is the TDD cycle. This is a fairly simple cycle and it
dictates the exact development cycle one should take when implementing TDD.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Write test - Write code - Refactor&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The scope of this cycle is to whatever you define your unit of test. In the
object orientated world this will typically match to your class and your unit
tests for said class. Let&#x27;s delve into each of these steps before heading into
an example.&lt;&#x2F;p&gt;
&lt;p&gt;This cycle is also known as the &lt;em&gt;Red-Green-Green&lt;&#x2F;em&gt; cycle representing the state
of the tests at each stage.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;write-test&quot;&gt;Write Test&lt;&#x2F;h3&gt;
&lt;p&gt;First and foremost, you write a test for the behavior that you expect of the
class. Most importantly you expect this to be a &lt;strong&gt;failing&lt;&#x2F;strong&gt; test. Here of course
remember that a compilation error is also a failing test. This test just needs
to describe one piece of functionality and fail so that we can implement it and
make it pass in the next stage of the cycle.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;write-code&quot;&gt;Write Code&lt;&#x2F;h3&gt;
&lt;p&gt;Now that we have a failing test that describes a piece of functionality we
implement that functionality. The interesting part here, and where most people
struggle to adopt TDD is that your implementation should be as minimal as
possible. That is, your implementation should only make your tests pass and
nothing more. The purpose of this is to drive implementation details to be as
simple as possible, attempting to remove as much unintentional complexity as
possible. It is very common at the end of this step to be looking at your code
and not being very impressed, but stick with it because we will get there.&lt;&#x2F;p&gt;
&lt;p&gt;This stage is complete once we have an implementation that makes all existing,
and new tests being written green (or passing).&lt;&#x2F;p&gt;
&lt;h3 id=&quot;refactor&quot;&gt;Refactor&lt;&#x2F;h3&gt;
&lt;p&gt;This is the time where we look at our code and we can make it something that we
are proud of. Apply all the refactoring tools from your toolbox but make sure
after every refactor you run all your tests and they all stay green. There is
not much more to it, there may various different changes to make but it will all
depend on the situation.&lt;&#x2F;p&gt;
&lt;p&gt;Once we have completed this step and all our tests are green now would be a good
time to commit (small and often). Then we start the cycle again by adding in a
new test and continue.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;give-it-a-try&quot;&gt;Give It a Try&lt;&#x2F;h2&gt;
&lt;p&gt;There is whole lot more that we can delve into for TDD practices and reasons as
to why it is good but this post is simply to give an introduction to the topic.
We will try give a better understanding with a basic example of a much loved
Fizz Buzz program.&lt;&#x2F;p&gt;
&lt;p&gt;To give a quick recap of the problem so you don&#x27;t have to search it up, the Fizz
Buzz problem is given a number and returns &lt;em&gt;fizz&lt;&#x2F;em&gt; if it is divisible by 3 and
&lt;em&gt;buzz&lt;&#x2F;em&gt; if it is divisible by 5. If it is both we return &lt;em&gt;fizz buzz&lt;&#x2F;em&gt;, otherwise
return the number.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;The example I will show is written in Kotlin for something a little different
and we will only look on the function level, just for those looking for the
constructor that never was. Also I won&#x27;t be using any fancy test framework just
good old fashioned JUnit.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Let&#x27;s write our first test then, when we give our function 1 we expect it to
return 1.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;@Test
fun `when 1 should return 1`() {
    assertEquals(&amp;quot;1&amp;quot;, fizzBuzz(1)) &amp;#x2F;&amp;#x2F; Compilation error
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;First and foremost this test will have a compilation error which is indeed a
failing test because we do not have the function yet written. Whilst this is not
a good example, the compilation error step is important because it allows us to
consider the API that we want to define. This is because the Fizz Buzz problem
has a clear input and output but you can imagine when you create a new class you
can use this as a chance to consider API options.&lt;&#x2F;p&gt;
&lt;p&gt;Now we move into the write code phase. First thing we do is get it compiling and
passing.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;fun fizzBuzz(num: Int): String {
    return &amp;quot;1&amp;quot;
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is exactly the time when you need to fight the urge to try and over
complicate this as this perfectly matches the requirements of the cycle. The
tests we have written pass and that is that. Since we don&#x27;t have much code here,
there isn&#x27;t much to refactor so let&#x27;s commit and move to our next step.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;@Test
fun `when 2 should return 2`() {
    assertEquals(&amp;quot;2&amp;quot;, fizzBuzz(2))
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Moving back to the implementation stage we see it starts get a bit weird but we
follow the TDD rules of only implementing enough to satisfy the tests to pass.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;fun fizzBuzz(num: Int): String {
    return if (num == 1) &amp;quot;1&amp;quot;
    else &amp;quot;2&amp;quot;
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we can refactor this a little here, keeping the tests green and then commit
again before we start writing our next test.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;fun fizzBuzz(num: Int): String {
    return num.toString()
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we encounter a different case, so let&#x27;s write a test for it.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;@Test
fun `when 3 should return fizz`() {
    assertEquals(&amp;quot;fizz&amp;quot;, fizzBuzz(3))
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Back to the implementation step we go!&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;fun fizzBuzz(num: Int): String {
    return if (num == 3) &amp;quot;fizz&amp;quot;
    else num.toString()
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Again you can clearly say, hey this won&#x27;t consider all other cases! Yet again we
are only considering making the current tests pass. However you may start to see
that this could possibly take a lot longer than the traditional method of
implement followed by test, which is definitely a common argument against TDD
and in this case it definitely shows.&lt;&#x2F;p&gt;
&lt;p&gt;In my opinion that is because the speed of TDD here can be improved by defining
tests based on expected behavior, rather than for this case just incrementing
the input (particularly since not all of our problems will take a simple
integer). So let&#x27;s do exactly that, let&#x27;s consider the case where it is
divisible by 5.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;@Test
fun `when 5 should return buzz`() {
    assertEquals(&amp;quot;buzz&amp;quot;, fizzBuzz(5))
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Hopefully you can see this test will obviously be failing so let&#x27;s make it pass.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;fun fizzBuzz(num: Int): String {
    return if (num == 3) &amp;quot;fizz&amp;quot;
    else if (num == 5) &amp;quot;buzz&amp;quot;
    else num.toString()
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;We are almost there we have a few more behaviors we want to check, these are:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;A number divisible by 3 but not 3&lt;&#x2F;li&gt;
&lt;li&gt;A number divisible by 5 but not 5&lt;&#x2F;li&gt;
&lt;li&gt;A number divisible by both 3 and 5&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;So let&#x27;s quickly iterate through these as hopefully by now you have the basic
idea. For brevity I will collapse all the tests into a single code block but
these would have been added and then implemented one at a time. The
implementation blocks I will separate though to make it clear.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;@Test
fun `when num is divisible by 3 should return fizz`() {
    assertEquals(&amp;quot;fizz&amp;quot;, fizzBuzz(9))
}

@Test
fun `when num is divisible by 5 should return buzz`() {
    assertEquals(&amp;quot;buzz&amp;quot;, fizzBuzz(10))
}

@Test
fun `when num is divisible by 3 and 5 should return fizzbuzz`() {
    assertEquals(&amp;quot;fizzbuzz&amp;quot;, fizzBuzz(15))
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now to the implementation. After testing for divisible by 3.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;fun fizzBuzz(num: Int): String {
    return if (num % 3 == 0) &amp;quot;fizz&amp;quot;
    else if (num == 5) &amp;quot;buzz&amp;quot;
    else num.toString()
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Divisible by 5.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;fun fizzBuzz(num: Int): String {
    return if (num % 3 == 0) &amp;quot;fizz&amp;quot;
    else if (num % 5 == 0) &amp;quot;buzz&amp;quot;
    else num.toString()
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Divisible by both 3 and 5.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;kotlin&quot; class=&quot;language-kotlin &quot;&gt;&lt;code class=&quot;language-kotlin&quot; data-lang=&quot;kotlin&quot;&gt;fun fizzBuzz(num: Int): String {
    return if (num % 3  == 0 &amp;amp;&amp;amp; num % 5 == 0) &amp;quot;fizzbuzz&amp;quot;
    else if (num % 3 == 0) &amp;quot;fizz&amp;quot;
    else if (num % 5 == 0) &amp;quot;buzz&amp;quot;
    else num.toString()
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now of course you can then refactor this however best suits your needs (I would
prefer braces here, maybe consider using a &lt;code&gt;when&lt;&#x2F;code&gt; statement, etc). Then there
you have it, we have just implemented fizz buzz by TDD.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;isn-t-this-a-bit-much&quot;&gt;Isn&#x27;t this a bit much?&lt;&#x2F;h2&gt;
&lt;p&gt;As I mentioned before one of the biggest deterrents I have heard around is that
this procedure can be so strict and slow down development cycle. Honestly this
is definitely true at first but of course you are learning something entirely
new, you don&#x27;t expect to be incredibly effective in a brand new programming
language when you first start, so why expect much different when learning a new
process?&lt;&#x2F;p&gt;
&lt;p&gt;TDD is a new mindset as well as process so it definitely does take time. To top
it off it does some with some very strict rules making you think just joined the
military! This is exactly why for me personally I haven&#x27;t been able to integrate
the explicit procedure in my working process, however I still believe there is a
lot of value to TDD.&lt;&#x2F;p&gt;
&lt;p&gt;For me personally I really like the aspect of having to think of the behavior
upfront rather than implementation, which is always a great thing to be focusing
on in testing. However sometimes I need to play around with API ideas and test
out some possible implementations which may or may not work. This is where I
have found TDD a bit harder to utilize.&lt;&#x2F;p&gt;
&lt;p&gt;Overall there are some great takeaways from TDD and it is up to you how much or
little you buy into it and use it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;wrapping-it-up&quot;&gt;Wrapping it up&lt;&#x2F;h2&gt;
&lt;p&gt;Something I hope you take away from this introduction of TDD is that it is a
process with more to it than just writing some tests upfront. There is a nice
little cycle (Test-Implement-Refactor) to guide you through the whole process
which has some great goals. It allows you to think about the behavior of your
system rather than its implementation, making it easier to test and maintain. By
only implementing enough to get it to pass it provides a framework to reduce
incidental complexity. As well as always providing you a chance to look and
consider any refactoring once each cycle, which is much better than having to
perform it at a larger scale.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Making your own test doubles and mocks</title>
		<published>2019-06-19T00:00:00+00:00</published>
		<updated>2019-06-19T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/software_concepts/test-doubles-and-stubs/" type="text/html"/>
		<id>https://maccoda.github.io/software_concepts/test-doubles-and-stubs/</id>
		<content type="html">&lt;p&gt;This is another topic I was wanting to cover whilst I explored some topics that usually are missed
in schooling. Test doubles or mocks and stubs. The first thing I want to note is that I don&#x27;t intend
on using any frameworks as I am aiming to try explain the concepts so hopefully it becomes apparent
as to why the frameworks came in place. The next is how we will look into this, to start I want to
clarify my understanding for the difference between the stubs and doubles and what both of these
enable. Then I want to consolidate these with some examples, so let&#x27;s get into it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-exactly-is-the-difference&quot;&gt;What exactly is the difference?&lt;&#x2F;h2&gt;
&lt;p&gt;Now when I was first introduced to mocking as it is called I wasn&#x27;t told of the difference and the
value, instead it was &amp;quot;Here is a cool framework that does it all for us&amp;quot;. Don&#x27;t ask how it works or
what it does, it gets our tests to pass so we move on. What I came to learn later is that the
framework was blocking me from understanding what exactly was going on. What was worse, the
framework obfuscated bad design choices because it made it simple to test my classes even when they
shouldn&#x27;t have been. That was when I was told of &lt;em&gt;test doubles&lt;&#x2F;em&gt; and &lt;em&gt;test stubs&lt;&#x2F;em&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;These two concepts are rarely seen too far from each other. They form a very valuable part of being
able to write good unit tests that are able to refine your system under test, where for the examples
below that will be a single class but in different scenarios this could vary. It essentially boils
down to your system under test needing to interact with some other system, who we will call its
collaborators, and we want to test these interactions.&lt;&#x2F;p&gt;
&lt;p&gt;When your service interacts with another service it can be broken down into 2 key parts. The request
and the response. When unit testing this we want to ensure that what we request of our collaborators
is correct and when receiving a response we correctly manage that. Therefore this can lead to two
separate tests for each interaction so to keep a single assertion per test. When we test the
&lt;strong&gt;request&lt;&#x2F;strong&gt; we will use a &lt;strong&gt;test double&lt;&#x2F;strong&gt; to assert that we request the correct behavior from the
collaborator. Then on the return with the &lt;strong&gt;response&lt;&#x2F;strong&gt; we will use a &lt;strong&gt;test stub&lt;&#x2F;strong&gt; to provide some
dummy data that our service can process.&lt;&#x2F;p&gt;
&lt;!--

TODO: A picture would be pretty handy here

Example will be database interaction where we need to ask a certain query based on parameters and
process the output to either return a list of a sub set of results or the number.
--&gt;
&lt;p&gt;Let&#x27;s try and put this into action with an example. Let&#x27;s say you have a little application that
manages your books and one of your services looks up those books by author and returns the list of
book titles. However our book model is pretty complex so we want the service to map this to a simple
model of title and author when it has retrieved the results.&lt;&#x2F;p&gt;
&lt;p&gt;Our database entity may look something like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public class BookEntity {
    &amp;#x2F;&amp;#x2F; Note: this is bad practice to give these primitive types but will suffice for this example
    private String title;
    private String author;
    &amp;#x2F;&amp;#x2F; ...some more fields

    public String title() {
        return title;
    }

    public String author() {
        return author;
    }

    &amp;#x2F;&amp;#x2F; ... some more methods
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;With our output model like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public class BookModel {
    private String title;
    private String author;

    public BookModel(String title, String author) {
        this.title = title;
        this.author = author;
    }

    public String title() {
        return title;
    }

    public String author() {
        return author;
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then our service may look a little like:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public class BookLookupService {
    private BookRepository repository;

    &amp;#x2F;&amp;#x2F; ...

    public List&amp;lt;BookModel&amp;gt; findByAuthor(String author) {
        List&amp;lt;BookEntity&amp;gt; bookEntities = repository.findBooksByAuthor(author);
        return bookEntities.stream().map(x -&amp;gt; new BookModel(x.title(), x.author())).collect(Collectors::toList);
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now let&#x27;s get onto writing these tests!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;testing-with-a-double&quot;&gt;Testing with a double&lt;&#x2F;h2&gt;
&lt;p&gt;As I said before we can split the interaction up into 2 whilst writing our unit tests for the
&lt;code&gt;BookLookupService&lt;&#x2F;code&gt;. We will use a test double to ensure that it communicates with its
&lt;code&gt;BookRepository&lt;&#x2F;code&gt; collaborator correctly. For this to work &lt;code&gt;BookRepository&lt;&#x2F;code&gt; should be an interface
that we can implement for our test, as all &lt;code&gt;BookLookupService&lt;&#x2F;code&gt; needs is a &lt;code&gt;findBookByAuthor&lt;&#x2F;code&gt; method.&lt;&#x2F;p&gt;
&lt;p&gt;This is perhaps what a possible double could look like.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public class BookRepositoryDouble implements BookRepository {
    int callCount = 0;
    String authorArgument;
    &amp;#x2F;&amp;#x2F; ... implements other methods of the interface

    @Override
    public List&amp;lt;BookModel&amp;gt; findBooksByAuthor(String author) {
        callCount++;
        authorArgument = author;
        return new List&amp;lt;&amp;gt;(books); &amp;#x2F;&amp;#x2F; Return some books we set earlier
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As you can see we are interested in how our &lt;code&gt;BookRepositoryDouble&lt;&#x2F;code&gt; is being called. Hence we track
the parameters given and times called so that we could make some assertions on those values. On this
side of the collaboration we want to see that &lt;code&gt;findBooksByAuthor&lt;&#x2F;code&gt; is called with the correct
parameters. Arguably in this example the test doesn&#x27;t provide us much but the concept extends to all
cases.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@Before
public void setUp() {
    service = new BookLookupService(mockRepository);
}
@Test
public void checkCorrectCall() {
    service.findByAuthor(&amp;quot;Author Name&amp;quot;);
    assertEquals(&amp;quot;Author Name&amp;quot;, mockRepository.authorArgument);
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;testing-with-a-stub&quot;&gt;Testing with a stub&lt;&#x2F;h2&gt;
&lt;p&gt;On the other side we want to ensure that our service interprets the received data correctly. For
this case we create a stub where we don&#x27;t track what is given but return something of value we can
test. For example we would want to test the nominal path where there are a few books but we would
also want to check how our service works when there is only one book or no books. As you can see the
test scenarios with the stub are quite different than that of the double.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public class BookRepositoryStub implements BookRepository {
    &amp;#x2F;&amp;#x2F; ... implements other methods of the interface

    @Override
    public List&amp;lt;BookModel&amp;gt; findBooksByAuthor(String author) {
        return new List&amp;lt;&amp;gt;();
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Again we want to split our tests up as best we can to only have one assertion per test so there can
only be one cause of failure.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;@Test
public void checkWithTwoBooks() {
    service = new BookLookupService(twoBookRepository); &amp;#x2F;&amp;#x2F; Instantiate with stub returning 2 books
    List&amp;lt;BookModel&amp;gt; result = service.findByAuthor(&amp;quot;Author Name&amp;quot;);
    assertEquals(2, result.size());
}

@Test
public void checkWithZeroBooks() {
    service = new BookLookupService(noBookRepository); &amp;#x2F;&amp;#x2F; Instantiate with stub returning 0 books
    service.findByAuthor(&amp;quot;Author Name&amp;quot;);
    assertEquals(0, result.size());
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;frameworks&quot;&gt;Frameworks&lt;&#x2F;h2&gt;
&lt;p&gt;I just wanted to finish up this piece discussing the elephant in the room. Why are you not just
using a framework to do all this? Honestly as I was writing these code examples I was thinking much
the same. There is a lot of boiler plate and repetition, surely we could do better. However the
problem with jumping straight into using frameworks is you don&#x27;t get the chance to understand why
they exist and instead only learn their usage at surface level. Hopefully after going through these
examples when you next grab a mocking or testing framework you can appreciate and understand what it
is doing for you rather than just blindly following examples because it sure does make a lot less
code to write!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Why would I even use dependency injection?</title>
		<published>2019-06-15T00:00:00+00:00</published>
		<updated>2019-06-15T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/software_concepts/dependency-injection/" type="text/html"/>
		<id>https://maccoda.github.io/software_concepts/dependency-injection/</id>
		<content type="html">&lt;p&gt;I was inspired to write this post and hopefully a little series on some of these key concepts of
software as I was asked &amp;quot;Why would I need to use dependency injection?&amp;quot;. This brought me back to
when I was first learning these industry staples that you never get taught learning computer
science. Due to this I was hoping to write a little series around my learning experiences and
understanding of these concepts because I have always found the more perspectives you get the easier
it is to form your own understanding. This is the first one for the series so let&#x27;s see how far we
can go.&lt;&#x2F;p&gt;
&lt;p&gt;If anyone does read this, firstly thank you and I hope it helps! Secondly if there is something you
would be interested in hearing thinking raise an
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;maccoda&#x2F;maccoda.github.io&#x2F;issues&quot;&gt;issue&lt;&#x2F;a&gt; for lack of a better means for the time
being and I will hopefully get around to it sooner rather than later!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-dependency-injection&quot;&gt;What is Dependency Injection?&lt;&#x2F;h2&gt;
&lt;p&gt;Alright now that the little preamble is over with lets start out like any good problem solver and
define the &lt;em&gt;What&lt;&#x2F;em&gt; of the problem. According to our good friends at Wikipedia we define dependency
injection as:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;In software engineering, dependency injection is a technique whereby one object supplies the
dependencies of another object.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Dependency_injection&quot;&gt;Wikipedia&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;So this is pretty good and correct, assuming you understand the concept to begin with. So let&#x27;s try
break it down a bit.&lt;&#x2F;p&gt;
&lt;p&gt;I first learnt this with Java, so one simple trick to think of dependency injection is moving all of
the &lt;code&gt;new&lt;&#x2F;code&gt; keywords out of your classes. Now this is a pretty dumb thing to say because something
obviously has to instantiate your classes and that is entirely correct but the point of dependency
injection is to create that separation between where your classes and their dependencies are
instantiated and where you write the fun problem solving logic. So the concept of dependency
injection is being able to &lt;strong&gt;give&lt;&#x2F;strong&gt; your classes their dependencies rather than you class
instantiating its own dependencies. A term you will hear a lot around this topic is Inversion of
Control (IOC). You are now giving control of what your classes dependencies are to a class higher up
the chain.&lt;&#x2F;p&gt;
&lt;p&gt;Don&#x27;t worry there is a lot of writing here and my description is arguably confusing in itself but I
will clarify this with some examples soon! So stick with me!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-do-i-use-dependency-injection&quot;&gt;How do I use Dependency Injection?&lt;&#x2F;h2&gt;
&lt;p&gt;There are a lot of fancy frameworks that you can use for dependency injection, no matter what
language you develop in. However I have no intention of showing how to use those frameworks because
if you want to learn you should practice it on the bare metal. I always enjoy getting my hands dirty
with this (as much as they can typing on a keyboard) because I find that to be the best way to
understand, making the mistakes and finding the answers.&lt;&#x2F;p&gt;
&lt;p&gt;Saying that let&#x27;s get onto our example. Since I am not feeling incredibly creative today I am going
to take the classic shopping cart example. Our task is to make a shopping cart class that will allow
our customers to buy some items. The code below is one possible way of doing this (although please
don&#x27;t use this to implement an actual shopping cart).&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public class ShoppingCart {
    private CreditCard creditCard;
    private LineItems items;

    public ShoppingCart(long creditCardNumber, List&amp;lt;Product&amp;gt; products) {
        creditCard = new CreditCard(creditCardNumber);
        items = new LineItems(products);
    }

    public void placeOrder() {
        creditCard.charge(items.total());
    }
}

&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So as you can see this shopping cart implementation needs to have a &lt;code&gt;CreditCard&lt;&#x2F;code&gt; to charge and some
&lt;code&gt;LineItems&lt;&#x2F;code&gt; to define how much to charge. Therefore it is pretty easy to see that the dependencies of
&lt;code&gt;ShoppingCart&lt;&#x2F;code&gt; are &lt;code&gt;CreditCard&lt;&#x2F;code&gt; and &lt;code&gt;LineItems&lt;&#x2F;code&gt;. A pretty easy way to see this in Java is they will
be fields of the class, you really only define a field if you need to use it perform some tasks.&lt;&#x2F;p&gt;
&lt;p&gt;However there are &lt;code&gt;new&lt;&#x2F;code&gt; keywords here so you can see the dependencies are not injected into
&lt;code&gt;ShoppingCart&lt;&#x2F;code&gt;, rather &lt;code&gt;ShoppingCart&lt;&#x2F;code&gt; knows exactly how to create its dependencies. It knows it
needs a &lt;strong&gt;credit card number&lt;&#x2F;strong&gt; and a &lt;strong&gt;list of products&lt;&#x2F;strong&gt;. In fact this is exactly why dependency
injection is important because it means your class does not need to know how to create its
dependencies but only how to &lt;strong&gt;use&lt;&#x2F;strong&gt; its dependencies. Instead of providing the parameters to
construct the dependencies we should have instead provided the dependencies themselves and
constructed those elsewhere, perhaps like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public class ShoppingCart {
    private CreditCard creditCard;
    private LineItems items;

    public ShoppingCart(CreditCard creditCard, LineItems items) {
        this.creditCard = creditCard;
        this.items = items;
    }

    public void placeOrder() {
        creditCard.charge(items.total());
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So we can now create it elsewhere&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;java&quot; class=&quot;language-java &quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public class Factory {
    public ShoppingCart shoppingCart(long creditCardNumber, List&amp;lt;Product&amp;gt; products) {
        return new ShoppingCart(new CreditCard(creditCardNumber), new LineItems(products));
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we have separated our creation code from our domain logic code. In doing this it has provided us
dependency injection as you can see our &lt;code&gt;ShoppingCart&lt;&#x2F;code&gt; no longer has any &lt;code&gt;new&lt;&#x2F;code&gt; keywords!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-dependency-injection&quot;&gt;Why Dependency Injection?&lt;&#x2F;h2&gt;
&lt;p&gt;The most obvious question now is, &amp;quot;Why would I do that? That looks like more code!&amp;quot;. This is indeed
correct we do have more code but the number of lines you have written is never a sole indicator of
the quality of the code. Instead what you should be looking at is &amp;quot;Has this made it easier for me to
change the code as requirements change?&amp;quot; or &amp;quot;Is this code easily testable?&amp;quot;. Making our code use
dependency injection has allowed us to say yes on both of those fronts.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;changing-with-requirements-or-design&quot;&gt;Changing with Requirements or Design&lt;&#x2F;h3&gt;
&lt;p&gt;The biggest achievement we have made is we are now able to develop to an interface. That is,
&lt;code&gt;ShoppingCart&lt;&#x2F;code&gt; doesn&#x27;t need to know anything about how &lt;code&gt;CreditCard&lt;&#x2F;code&gt; or &lt;code&gt;LineItems&lt;&#x2F;code&gt; work under the
hood, or if they are even concrete classes. All it needs to know is that it can call &lt;code&gt;charge&lt;&#x2F;code&gt; and
&lt;code&gt;total&lt;&#x2F;code&gt; on them respectively. Therefore if we only supported one type of credit card and we needed
to add another one, so long as it implements &lt;code&gt;charge&lt;&#x2F;code&gt; for the &lt;code&gt;CreditCard&lt;&#x2F;code&gt; interface our
&lt;code&gt;ShoppingCart&lt;&#x2F;code&gt; need not change.&lt;&#x2F;p&gt;
&lt;p&gt;In a different direction, if the design of &lt;code&gt;LineItems&lt;&#x2F;code&gt; were to change and it needed something
different to construct itself, our &lt;code&gt;ShoppingCart&lt;&#x2F;code&gt; is now unaffected. The only place it needs to
change is where we create it.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;testability&quot;&gt;Testability&lt;&#x2F;h3&gt;
&lt;p&gt;Something else that dependency injection has aided with is making tests easier to write. If we had
of kept it the old way, testing &lt;code&gt;ShoppingCart&lt;&#x2F;code&gt; would be near impossible without needing to charge an
actual credit card. To avoid this we would need to use reflection to inject a mock and capture all
the interactions, doable but more complicated than it need be. Now we can simply make a test double
that looks like a &lt;code&gt;CreditCard&lt;&#x2F;code&gt; and then capture the interactions on that.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;finishing-up&quot;&gt;Finishing Up&lt;&#x2F;h2&gt;
&lt;p&gt;Hopefully through this very basic example you can see how you can use dependency injection in your
current work as well as how it is helpful. As with a lot of these practices it is hard to see the
benefit in the small scale but once your system grows and the number of moving parts increases its
value becomes apparent.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Deploying Micronaut Application to Heroku</title>
		<published>2019-03-11T00:00:00+00:00</published>
		<updated>2019-03-11T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/deploying-micronaut-heroku/" type="text/html"/>
		<id>https://maccoda.github.io/deploying-micronaut-heroku/</id>
		<content type="html">&lt;p&gt;&lt;a href=&quot;http:&#x2F;&#x2F;micronaut.io&#x2F;&quot;&gt;Micronaut&lt;&#x2F;a&gt; is a great JVM framework I was recently introduced to. It has been
designed with the intention to fit into the modern day micro-service and
serverless architecture with its big selling point being compile time dependency
injection. If you have ever used something like Spring Boot you will know what a
difference this will make to start up times. However this post is about
deploying these apps to Heroku. Once I have had some more experience in the
framework I will write another post about making an application with it.
In lieu of that, I would really recommend giving it a try and reach out if you
have any blockers.&lt;&#x2F;p&gt;
&lt;p&gt;For this post I am assuming you are familiar with &lt;a href=&quot;https:&#x2F;&#x2F;www.heroku.com&#x2F;&quot;&gt;Heroku&lt;&#x2F;a&gt; as I won&#x27;t go in
depth about setting it up. However that is the beauty of this service is they
make it really simple to get started which is great for hobby projects.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;creating-the-application&quot;&gt;Creating the Application&lt;&#x2F;h2&gt;
&lt;p&gt;Creating the app is very simple as with many frameworks. Micronaut provide a CLI
tool and a &lt;a href=&quot;https:&#x2F;&#x2F;guides.micronaut.io&#x2F;index.html&quot;&gt;guide&lt;&#x2F;a&gt; for creating your first application using this. Again I won&#x27;t
go more in depth into this but it is very important to follow this &lt;a href=&quot;https:&#x2F;&#x2F;guides.micronaut.io&#x2F;index.html&quot;&gt;guide&lt;&#x2F;a&gt;
otherwise your experience may differ and likely be more difficult.&lt;&#x2F;p&gt;
&lt;p&gt;The important part of using the CLI tool is that is generates the base project
and along with that is provides the &lt;code&gt;Dockerfile&lt;&#x2F;code&gt; that can be used to build a
deployed image. It is a very simple &lt;code&gt;Dockerfile&lt;&#x2F;code&gt; but just highlights the
focus on simplicity in the modern environments provided by Micronaut.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;first-attempt-to-deploy-to-heroku&quot;&gt;First Attempt to deploy to Heroku&lt;&#x2F;h2&gt;
&lt;p&gt;My first attempt as the naming of this sections forbodes was not all that
successful and led to a few weird issues. Let&#x27;s start at the beginning.&lt;&#x2F;p&gt;
&lt;p&gt;Choosing Heroku as the service to manage my deployments was primarily driven by
simplicity. To deploy my first app was as simple as &lt;code&gt;git push heroku master&lt;&#x2F;code&gt;
(after some minimal set up of course). This application should be no different I
thought, it is a Gradle application and Heroku natively supports with this a
Gradle build pack. Unfortunately not quite so, they know how to support Spring
applications but if none is detected you are in charge of telling the build pack
how to build your application. Which is a good choice and again is made simple
by enforcing a convention.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;If Heroku does not how to build your application you define a &lt;code&gt;stage&lt;&#x2F;code&gt; Gradle
task&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Of course I am not the first person to deploy a non-Spring application to Heroku
so there is a simple guide. For a Micronaut application the only required part
however is defining the &lt;code&gt;stage&lt;&#x2F;code&gt; task and its dependencies.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;groovy&quot; class=&quot;language-groovy &quot;&gt;&lt;code class=&quot;language-groovy&quot; data-lang=&quot;groovy&quot;&gt;task stage(dependsOn: [&amp;#x27;build&amp;#x27;, &amp;#x27;clean&amp;#x27;])
build.mustRunAfter clean
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;That was pretty simple!&lt;&#x2F;p&gt;
&lt;p&gt;Now if you were anything like me and just want to get your application out there
you would try to deploy this shortly after. In doing this I started to find
where most of my issues lay. After the deployment I attempted to check the
health endpoint and was receiving a fat nothing, my first thoughts were, &#x27;Does
it know how to run my application?&#x27;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;defining-the-procfile&quot;&gt;Defining the Procfile&lt;&#x2F;h3&gt;
&lt;p&gt;For those unfamiliar with Heroku, they have a notion of a &lt;code&gt;Procfile&lt;&#x2F;code&gt; which
defines which commands to run to start your application(s). Akin to that you
would write for a build pipeline.&lt;&#x2F;p&gt;
&lt;p&gt;First thing I thought here is I know I was able to run my application through
Gradle using the &lt;code&gt;run&lt;&#x2F;code&gt; command so let&#x27;s first try that.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;yaml&quot; class=&quot;language-yaml &quot;&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;web: .&amp;#x2F;gradlew run
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Immediately I deployed again and tested the health endpoint. Same result...&lt;&#x2F;p&gt;
&lt;h3 id=&quot;finding-the-error&quot;&gt;Finding the Error&lt;&#x2F;h3&gt;
&lt;p&gt;It turned out the error was staring me in the face the whole time in the
deployment logs that I clearly do not pay the required attention to. When you
perform the git deployment you don&#x27;t actually get all the logs of the container
you will need to use &lt;code&gt;heroku logs --tail&lt;&#x2F;code&gt; to get these, and they are incredibly
useful!&lt;&#x2F;p&gt;
&lt;p&gt;Littered throughout the logs I had occurrences of &lt;code&gt;Error R14 (Memory quota exceeded)&lt;&#x2F;code&gt;. Not only that, it did not only appear during the execution of the
application but actually when trying to build the application!&lt;&#x2F;p&gt;
&lt;p&gt;Now of course I could purchase the plan providing me with more memory but this
was a hobby project. Further that is almost always the cheat&#x27;s way out as there
is probably something better you can do before just upping allocated resources.&lt;&#x2F;p&gt;
&lt;p&gt;The reason for this issue I can only assume is because of the manner in which
Micronaut builds your application. A lot of the heavy lifting is done during
compile time giving you super fast start up times. However I was now pushing all
this load onto the Heroku containers for which I had limited resources for.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;getting-the-application-deployed&quot;&gt;Getting the Application Deployed&lt;&#x2F;h2&gt;
&lt;p&gt;After realising I would need to perform the staging on my local machine I
started looking at different methods of deploying to Heroku. As it turns out
they provide you access to a container registry for which you can push images
and then release them for your application.&lt;&#x2F;p&gt;
&lt;p&gt;The process to deploy a container is as follows:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Define your deployable image&lt;&#x2F;li&gt;
&lt;li&gt;Build the artifacts needed for the image and consequently build the
deployable image&lt;&#x2F;li&gt;
&lt;li&gt;Push the deployable image to the registry&lt;&#x2F;li&gt;
&lt;li&gt;Release the image to the deployed environment&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;This process is made extremely simple by Micronaut and Heroku! I was able to
script it in 3 lines!&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;.&amp;#x2F;gradlew stage
heroku container:push web
heroku container:release web
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;These define the last 3 steps of the process above but where is our image
definition? It is the &lt;code&gt;Dockerfile&lt;&#x2F;code&gt; that Micronaut generated for us on the first
build!&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;Dockerfile&quot; class=&quot;language-Dockerfile &quot;&gt;&lt;code class=&quot;language-Dockerfile&quot; data-lang=&quot;Dockerfile&quot;&gt;FROM openjdk:8u171-alpine3.7
RUN apk --no-cache add curl
COPY build&amp;#x2F;libs&amp;#x2F;*-all.jar myapp-kt.jar
CMD java ${JAVA_OPTS} -jar myapp-kt.jar
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;All this &lt;code&gt;Dockerfile&lt;&#x2F;code&gt; does is simply copy the built artifact from the &lt;code&gt;stage&lt;&#x2F;code&gt;
task (which is combined into a single JAR ending in &lt;code&gt;-all&lt;&#x2F;code&gt;).&lt;&#x2F;p&gt;
&lt;p&gt;Finally we just need to update the &lt;code&gt;Procfile&lt;&#x2F;code&gt; as we do not need to build
anything anymore, but rather just need to simply execute the JAR. Of course be
aware there is a version appended.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;yaml&quot; class=&quot;language-yaml &quot;&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;web: java -jar build&amp;#x2F;libs&amp;#x2F;myapp-kt-0.1-all.jar
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Once you have updated the &lt;code&gt;Procfile&lt;&#x2F;code&gt;, deploy to Heroku again and you should find
your application up and running!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h2&gt;
&lt;p&gt;To recap what we managed to achieve. We built our Micronaut application
following the provided guide. Then utilizing what was provided from the template
built a deployable Docker image which could then deploy to Heroku!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Managing Local Heroku Deployments</title>
		<published>2019-03-11T00:00:00+00:00</published>
		<updated>2019-03-11T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/managing-local-deployments/" type="text/html"/>
		<id>https://maccoda.github.io/managing-local-deployments/</id>
		<content type="html">&lt;p&gt;Recently I have using &lt;a href=&quot;https:&#x2F;&#x2F;www.heroku.com&#x2F;&quot;&gt;Heroku&lt;&#x2F;a&gt; a fair bit on a hobby project I am working on and
having a hard time getting comfortable with local deployments. As my project is
starting to get a little more complex and actually useful I am wanting to make
sure what I have deployed is something that works. Further to it I have a back end
deployed separately from the front end application so I want to make sure they
are in sync.&lt;&#x2F;p&gt;
&lt;p&gt;All of this lands me at a point where I would love to build in a proper CI&#x2F;CD
pipeline for these projects, however I struggle to bring myself to it as I am
lazy and couldn&#x27;t find a short solution in the first 3.5 seconds
:stuck_out_tongue_closed_eyes:. So I went for the next best thing, an
over-engineered script that gives me some certainty in what I am releasing. This
is what I wanted to share so hopefully someone who gets into the same position
as myself has something pre-made for them.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;#!&amp;#x2F;usr&amp;#x2F;bin&amp;#x2F;env bash
set -e

echo &amp;quot;Last release:&amp;quot;
cat .last-release
echo
stats=$(git status --porcelain)
if [[ -z $stats ]]; then
    echo &amp;quot;Hit enter to continue with the release&amp;quot;
    read
else
    echo &amp;quot;Workspace is dirty, stash or commit before release!&amp;quot;
    exit 1
fi

.&amp;#x2F;ci.sh
git push heroku master

git log -n 1 &amp;gt; .last-release
git commit -a -m &amp;quot;$(heroku releases -n 1)&amp;quot;
git push
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It isn&#x27;t by any means a replacement for a proper pipeline but it helped me feel
better about my releases.&lt;&#x2F;p&gt;
&lt;p&gt;Essentially all it is doing is ensuring that:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;You only release with a clean workspace. All changes you are running locally
are deployed&lt;&#x2F;li&gt;
&lt;li&gt;You can see what was last released by tracking the file&lt;&#x2F;li&gt;
&lt;li&gt;A commit is only deployed if it passes the &lt;code&gt;ci.sh&lt;&#x2F;code&gt; script which for me usually
contains running tests and linter&lt;&#x2F;li&gt;
&lt;li&gt;A commit is also made containing the Heroku version that has been deployed&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Hope you may find this useful. Any ideas or improvements let me know!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>How was I so wrong about CI and what I learnt about CD</title>
		<published>2018-07-16T00:00:00+00:00</published>
		<updated>2018-07-16T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/ci-cd/" type="text/html"/>
		<id>https://maccoda.github.io/ci-cd/</id>
		<content type="html">&lt;p&gt;My knowledge of Continuous Integration (CI) and Continuous Delivery (CD) had so
far only been developed from discussions with colleges and my own assumptions on
the topic. Only recently had I decided that I should actually put this knowledge
to the test and started doing some reading. To my surprise I was well off...&lt;&#x2F;p&gt;
&lt;h2 id=&quot;continuous-integration&quot;&gt;Continuous Integration&lt;&#x2F;h2&gt;
&lt;p&gt;First off I started looking into CI, you know the build machines and stuff yeah?
Nope. Continuous Integration is exactly as its name describes, continuously
integrating your code. For some unknown reason to me I had understood CI as the
build pipeline getting kicked off every time someone makes a commit to the
repository. In a way this isn&#x27;t ridiculously off as this pipeline provides the
means for CI but is not it itself. After watching a &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=aoMfbgF2D_4&quot;&gt;talk&lt;&#x2F;a&gt; by Martin Fowler he
described CI in such a raw, upfront manner that it has really stuck with me. I
paraphrase but he states something along the lines of;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;If you can answer yes to the following 3 questions, then indeed you &lt;strong&gt;are&lt;&#x2F;strong&gt;
practicing continuous integration:&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;Are all engineers pushing to trunk&#x2F;master on a daily basis?&lt;&#x2F;em&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;em&gt;Does every commit run a solid suite of tests giving confidence the commit works?&lt;&#x2F;em&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;em&gt;When the build is broken, is it typically fixed in under 10 minutes?&lt;&#x2F;em&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;This is pretty far from a build pipeline tool right?&lt;&#x2F;p&gt;
&lt;p&gt;So what we are saying here is that CI is the practice of continually integrating
developer&#x27;s code in the repository, &lt;strong&gt;daily&lt;&#x2F;strong&gt;. That is, there is no never ending
feature branches and no &#x27;sub-master&#x27; branch that we all merge into before we go
to our actual master, nope. Everything needs to be integrated and on the master
branch. Period. I have definitely witnessed teams not practicing CI and seeing
how things can gradually diverge over time and then when finally ready, bringing
them all back together becomes feature work in of itself!&lt;&#x2F;p&gt;
&lt;p&gt;Next up, we are saying, cool you are all integrating but does the software still
do what it is meant to? The easiest way to get peace of mind for this is a solid
suite of tests. Now we are all well familiar with unit tests but through my
readings I was introduced to so many different types of tests, all of which play
a different role in building our confidence in our software. If you are
interested in looking further into it have a read of &lt;a href=&quot;https:&#x2F;&#x2F;www.atlassian.com&#x2F;continuous-delivery&#x2F;different-types-of-software-testing&quot;&gt;this article&lt;&#x2F;a&gt; by
Atlassian. So what we really want here is a suite of tests, not only unit tests,
that is kicked off every time some one delivers and definitely every time some
on commits to the master branch.&lt;&#x2F;p&gt;
&lt;p&gt;The final question is directed more at the culture developed, than the actual
practice. I feel that it is depicting the importance of the master branch. The
notion of, if it fails, you drop everything and get that baby back to green! To
achieve this there has to be a culture shift, as well as confidence in your
build pipeline. The last thing you want is developers not thinking twice about a
failed build because &#x27;everyone knows this test is flaky&#x27;. If it is flaky and you
can do something about it, fix that up, regain some confidence in your pipeline
and get that pipeline to a strong green.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;continuous-delivery-vs-continuous-deployment&quot;&gt;Continuous Delivery vs Continuous Deployment&lt;&#x2F;h2&gt;
&lt;p&gt;The two CD&#x27;s were a lot newer to my vocabulary than the wrongly understood CI,
so I approached these with less of a tainted mind. Again Martin Fowler covered
these topics in his &lt;a href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=aoMfbgF2D_4&quot;&gt;talk&lt;&#x2F;a&gt;. There is so much to talk about regarding these
topics and it is really fascinating if you get the chance to read further into
them but here I just wanted to look at &lt;em&gt;what exactly is the difference?&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Firstly I want to say that I am by no means an expert in regards to these but
just want to share what I thought was a really simple explanation on
differentiating the two. Both of these notions revolve around very similar
concepts and both have similar end goals. They are looking at being able to
get quality software out the door in an automated, reproducible manner, and of
course, quickly. One of the biggest pre-requisites is to have an automated
pipeline, script where you can, define your pipeline in source code, get
everything moving with as little human interaction as possible! Once this is
done we can look into getting the software into environments of closer parity to
the production environment than our local development machine, again ideally in
an automated manner. This is all so we can gain confidence that the release will
work as well as be certain that it is done in the same manner every time.&lt;&#x2F;p&gt;
&lt;p&gt;So at this point we haven&#x27;t really said much about what is the actual difference
between delivery and deployment. Well that is because up until now there kind of
isn&#x27;t much of a difference. However when we get to the final stage delivering
the software into production that is where it differs. &lt;strong&gt;Continuous Delivery&lt;&#x2F;strong&gt;
is having the ability to deliver the current master at any given moment,
&lt;strong&gt;Continuous Deployment&lt;&#x2F;strong&gt; is actually doing just that for every commit. You can
see how the two can be easily confused, further how continuous delivery is sort
of a requirement for continuous deployment.&lt;&#x2F;p&gt;
&lt;p&gt;Actually implementing these practices can have some unexpected side effects as I
have seen. Applying only continuous delivery, teams had no problem practicing
continuous integration as they had their master branch raring and ready, but
only deployed when it was required. Whereas those practicing continuous
deployment actually gravitated away from the continuous integration definition
given earlier as they started having these sub-master branches so that they
could be confident in their software before it was delivered to production.
However I am sure this all depends on the scenario and what your team has in
place, I am certainly not saying continuous deployment is bad as I am sure the
big tech companies have definitely made this work well for them. Give it a go
and see what works best for your team.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Making microservices in Rust</title>
		<published>2018-05-01T00:00:00+00:00</published>
		<updated>2018-05-01T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/rust-web-frameworks/" type="text/html"/>
		<id>https://maccoda.github.io/rust-web-frameworks/</id>
		<content type="html">&lt;p&gt;This is a small idea that I have been wanting to put together for quite some
time now and finally have managed to get the time and most importantly
experience in Rust to finally try something a little more than just small
projects. One area that I think Rust is really making a decent headway in in the
web domain, which I am assuming is likely due to its origin from Firefox. So I
wanted to see if I could put together a really basic CRUD micro-service doing
the ever so original TODO functionality.&lt;&#x2F;p&gt;
&lt;p&gt;My main goal from this project was to be able to try some larger scale crates
available in the Rust ecosystem and perform some more typical enterprise
activities of working with databases and HTTP requests in Rust, something I have
usually been steering clear of. Further to this, I was really hoping that I
could help some of these frameworks grow with some more examples of how to put
them all together so hopefully can make it easier to pick up for new comers.&lt;&#x2F;p&gt;
&lt;p&gt;If you aren&#x27;t up for the read and would just like the code go check out the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;maccoda&#x2F;micro-rs&quot;&gt;repository&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;So what were the frameworks that I wanted to explore?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;diesel&quot;&gt;Diesel&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;diesel.rs&#x2F;&quot;&gt;Diesel&lt;&#x2F;a&gt; is one of the more popular &lt;a href=&quot;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Object-relational_mapping&quot;&gt;ORM&lt;&#x2F;a&gt; in the Rust community. It has some
great documentation to get set up and to understand how to use it. It also comes
with a very handy CLI tool to assist in the setting up of a project and managing
database migrations, which is great for keeping everything nice and uniform and
automated. A great combination indeed!&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;http:&#x2F;&#x2F;diesel.rs&#x2F;guides&#x2F;getting-started&#x2F;&quot;&gt;getting started guide&lt;&#x2F;a&gt; for Diesel
provides a solid foundation on how to put it all together so I won&#x27;t try rewrite
that, rather provide a light overview of the steps to be able to reproduce.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;setting-up-the-migrations&quot;&gt;Setting up the migrations&lt;&#x2F;h3&gt;
&lt;p&gt;Following the guide the CLI tool will create an &lt;code&gt;up.sql&lt;&#x2F;code&gt; and &lt;code&gt;down.sql&lt;&#x2F;code&gt; in the
&lt;code&gt;migrations&lt;&#x2F;code&gt; directory to handle our initial database migration.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;shell&quot; class=&quot;language-shell &quot;&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;$ diesel migration generate tasks
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This will generate the files and place them into a time stamped directory,
appended with the name of the migration we gave, which was &lt;code&gt;tasks&lt;&#x2F;code&gt;. In here we
want to put the SQL query to create our table and the opposing query to undo the
change.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;up.sql&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;sql&quot; class=&quot;language-sql &quot;&gt;&lt;code class=&quot;language-sql&quot; data-lang=&quot;sql&quot;&gt;CREATE TABLE tasks (
  id SERIAL PRIMARY KEY,
  task VARCHAR NOT NULL,
  completed BOOLEAN NOT NULL DEFAULT &amp;#x27;f&amp;#x27;
)
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;code&gt;down.sql&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;sql&quot; class=&quot;language-sql &quot;&gt;&lt;code class=&quot;language-sql&quot; data-lang=&quot;sql&quot;&gt;DROP TABLE tasks
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;adding-the-models&quot;&gt;Adding the Models&lt;&#x2F;h3&gt;
&lt;p&gt;Following the remainder of the guide we get to develop the model of our Tasks
which then allows us to use the CLI tool to generate our schema.&lt;&#x2F;p&gt;
&lt;p&gt;We want to follow the recommended guide of having one type to represent the
structure we want to query from the database and one type to represent the
structure to insert into the database. These will be &lt;code&gt;Task&lt;&#x2F;code&gt; and &lt;code&gt;NewTask&lt;&#x2F;code&gt;
respectively and will be put in the &lt;code&gt;model&lt;&#x2F;code&gt; module.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;#[derive(Queryable)]
pub struct Task {
    id: i32,
    task: String,
    completed: bool,
}

#[derive(Insertable)]
#[table_name = &amp;quot;tasks&amp;quot;]
pub struct NewTask {
    task: String,
    completed: bool,
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;generating-the-schema&quot;&gt;Generating the Schema&lt;&#x2F;h3&gt;
&lt;p&gt;Once we have set up the models we can then go back again to the Diesel CLI to
generate the schema for us which will provide the DSL that we will interact
with.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;shell&quot; class=&quot;language-shell &quot;&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;$ diesel print-schema &amp;gt; src&amp;#x2F;schema.rs
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This will look at our source code and locate the &lt;code&gt;struct&lt;&#x2F;code&gt;s that are &lt;code&gt;Queryable&lt;&#x2F;code&gt;
to determine the shape of our data. The resulting &lt;code&gt;schema.rs&lt;&#x2F;code&gt; should look like
the following:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;table! {
    tasks (id) {
        id -&amp;gt; Integer,
        task -&amp;gt; Varchar,
        completed -&amp;gt; Bool,
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;adding-the-functionality&quot;&gt;Adding the Functionality&lt;&#x2F;h3&gt;
&lt;p&gt;The final part to the database aspect of our micro-service is to provide some
functionality on interacting with the database with the CRUD operations. My
implementation is a very basic one to allow me to associate these interactions
with the model type.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;impl Task {
    pub fn all(conn: &amp;amp;PgConnection) -&amp;gt; Vec&amp;lt;Task&amp;gt; {
        use schema::tasks::dsl::*;
        tasks.load::&amp;lt;Task&amp;gt;(conn).expect(&amp;quot;Could not load tasks&amp;quot;)
    }

    pub fn create(conn: &amp;amp;PgConnection, task: NewTask) {
        use schema::tasks;
        diesel::insert_into(tasks::table)
            .values(&amp;amp;task)
            .execute(conn)
            .expect(&amp;quot;Unable to insert&amp;quot;);
    }

    pub fn update(conn: &amp;amp;PgConnection, task_id: i32, task_update: Task) -&amp;gt; i32 {
        use schema::tasks::dsl::*;
        diesel::update(tasks.find(task_id))
            .set((
                task.eq(task_update.task),
                completed.eq(task_update.completed),
            ))
            .execute(conn)
            .expect(&amp;quot;Failed to update&amp;quot;);
        task_update.id
    }

    pub fn delete(conn: &amp;amp;PgConnection, task_id: i32) {
        use schema::tasks::dsl::*;
        diesel::delete(tasks.find(task_id))
            .execute(conn)
            .expect(&amp;quot;Failed to delete&amp;quot;);
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The above code shows a few different ways in which we can use the generated DSL
to work with our data, or in the case of the &lt;code&gt;create&lt;&#x2F;code&gt; function, how we can use
it without the DSL.&lt;&#x2F;p&gt;
&lt;p&gt;Note that it is important that the DSL is only imported on the function scope
and that when doing this ensure that the function parameters don&#x27;t match any
column in the schema to avoid any unexpected shadowing.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;rocket&quot;&gt;Rocket&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;rocket.rs&#x2F;&quot;&gt;Rocket&lt;&#x2F;a&gt; is quite a popular web framework, for several reasons but one
of course is the well polished website! It is pretty easy to get started with
and handles a lot of the boiler plate through its powerful use of macros. This
part of the project I cannot claim I developed a lot for as it does have a great
&lt;a href=&quot;https:&#x2F;&#x2F;rocket.rs&#x2F;guide&#x2F;state&#x2F;#databases&quot;&gt;tutorial&lt;&#x2F;a&gt; on the website for how to use Rocket with Diesel. So
I will just provide some basic changes to this that I ended up applying.&lt;&#x2F;p&gt;
&lt;p&gt;The first thing being that I wanted to use PostgreSQL which wasn&#x27;t covered in
the tutorial. This was a very minor deviation from the tutorial however because
it was mainly handled in the Diesel section of the code which was already
described previously. The biggest change here was changing the features that
Diesel was compiled with:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;Cargo.toml&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;diesel = { version = &amp;quot;1.0.0&amp;quot;, features = [&amp;quot;postgres&amp;quot;] }
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The only other chunk related to this was the database connection pool that we used
which was simply changed to a &lt;code&gt;PgConnection&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;type Pool = r2d2::Pool&amp;lt;ConnectionManager&amp;lt;PgConnection&amp;gt;&amp;gt;;
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;managing-the-database-connection&quot;&gt;Managing the Database Connection&lt;&#x2F;h3&gt;
&lt;p&gt;From there I was able to follow the tutorial fairly closely. We start by
ensuring that Rocket manages our database connection pool. This is as simple as
adding it to &lt;code&gt;ignite&lt;&#x2F;code&gt; function.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;type Pool = r2d2::Pool&amp;lt;ConnectionManager&amp;lt;PgConnection&amp;gt;&amp;gt;;
fn init_pool() -&amp;gt; Pool {
    dotenv::dotenv().ok();
    let database_url = env::var(&amp;quot;DATABASE_URL&amp;quot;).expect(&amp;quot;DATABASE_URL must be set&amp;quot;);
    let manager = ConnectionManager::&amp;lt;PgConnection&amp;gt;::new(database_url);
    r2d2::Pool::new(manager).expect(&amp;quot;db pool&amp;quot;)
}

pub fn start() {
    rocket::ignite()
        .manage(init_pool())
        .launch();
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now that Rocket is managing our state we want to be able to grab that from our
requests. To do this in Rocket we need to implement the &lt;code&gt;FromRequest&lt;&#x2F;code&gt; trait for
our database connection.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;impl&amp;lt;&amp;#x27;a, &amp;#x27;r&amp;gt; FromRequest&amp;lt;&amp;#x27;a, &amp;#x27;r&amp;gt; for DbConn {
    type Error = ();

    fn from_request(request: &amp;amp;&amp;#x27;a Request&amp;lt;&amp;#x27;r&amp;gt;) -&amp;gt; request::Outcome&amp;lt;DbConn, ()&amp;gt; {
        let pool = request.guard::&amp;lt;State&amp;lt;Pool&amp;gt;&amp;gt;()?;
        match pool.get() {
            Ok(conn) =&amp;gt; Outcome::Success(DbConn(conn)),
            Err(_) =&amp;gt; Outcome::Failure((Status::ServiceUnavailable, ())),
        }
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;adding-the-request-handlers&quot;&gt;Adding the Request Handlers&lt;&#x2F;h3&gt;
&lt;p&gt;Essentially the final part of this is to add in the request handlers. Thanks to
Rocket&#x27;s code generation this is quite easy to write. For example to add the
request to return all the tasks the request would look like:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;#[get(&amp;quot;&amp;#x2F;&amp;quot;)]
fn get_all_tasks(conn: DbConn) -&amp;gt; Json&amp;lt;Vec&amp;lt;Task&amp;gt;&amp;gt; {
    Json(Task::all(&amp;amp;conn))
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then we would update the &lt;code&gt;start&lt;&#x2F;code&gt; function to mount this route:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;pub fn start() {
    rocket::ignite()
        .mount(&amp;quot;&amp;#x2F;tasks&amp;quot;, routes![get_all_tasks])
        .manage(init_pool())
        .launch();
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;returning-some-data&quot;&gt;Returning Some Data&lt;&#x2F;h4&gt;
&lt;p&gt;However we have this new &lt;code&gt;Json&lt;&#x2F;code&gt; type that we are returning from our request so
at the moment this won&#x27;t compile. Let&#x27;s go ahead and add that type and make our
&lt;code&gt;Task&lt;&#x2F;code&gt; model serializable.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Just as side note I wouldn&#x27;t recommend in practice you have you database
representation the same the model type returned from your request but for the
sake of brevity for this walk through I will keep it this way&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;To obtain the &lt;code&gt;Json&lt;&#x2F;code&gt; type we will add a dependency from Rocket,
&lt;code&gt;rocket-contrib&lt;&#x2F;code&gt;, adding to our &lt;code&gt;Cargo.toml&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;[dependencies.rocket_contrib]
version = &amp;quot;0.3.6&amp;quot;
default-features = false
features = [&amp;quot;json&amp;quot;]
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then we need to make our &lt;code&gt;Task&lt;&#x2F;code&gt; serializable, and our &lt;code&gt;NewTask&lt;&#x2F;code&gt; whilst we are at
it. To do this we will use &lt;code&gt;serde&lt;&#x2F;code&gt; which is the standard serialization and
de-serialization crate used in Rust. With a small tweak of our &lt;code&gt;Cargo.toml&lt;&#x2F;code&gt; and
some added &lt;code&gt;derive&lt;&#x2F;code&gt;s to our type we are done.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;Cargo.toml&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;serde = &amp;quot;1.0&amp;quot;
serde_json = &amp;quot;1.0&amp;quot;
serde_derive = &amp;quot;1.0&amp;quot;
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;code&gt;model.rs&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;#[derive(Deserialize, Serialize, Queryable)]
pub struct Task {
    id: i32,
    task: String,
    completed: bool,
}

#[derive(Deserialize, Serialize, Insertable)]
#[table_name = &amp;quot;tasks&amp;quot;]
pub struct NewTask {
    task: String,
    completed: bool,
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;adding-the-rest-of-the-requests&quot;&gt;Adding the Rest of the Requests&lt;&#x2F;h4&gt;
&lt;p&gt;Following the initial request we can add the remaining operations to create,
update, and delete tasks.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;#[post(&amp;quot;&amp;#x2F;&amp;quot;, data = &amp;quot;&amp;lt;task&amp;gt;&amp;quot;)]
fn create_task(task: Json&amp;lt;NewTask&amp;gt;, conn: DbConn) -&amp;gt; Json&amp;lt;String&amp;gt; {
    Task::create(&amp;amp;conn, task.into_inner());
    Json(&amp;quot;Task added&amp;quot;.to_owned())
}

#[put(&amp;quot;&amp;#x2F;&amp;lt;id&amp;gt;&amp;quot;, data = &amp;quot;&amp;lt;task&amp;gt;&amp;quot;)]
fn update_task(id: u32, task: Json&amp;lt;Task&amp;gt;, conn: DbConn) -&amp;gt; Json&amp;lt;i32&amp;gt; {
    let id = Task::update(&amp;amp;conn, id as i32, task.into_inner());
    Json(id)
}

#[delete(&amp;quot;&amp;#x2F;&amp;lt;id&amp;gt;&amp;quot;)]
fn delete_task(id: u32, conn: DbConn) -&amp;gt; Json&amp;lt;Value&amp;gt; {
    Task::delete(&amp;amp;conn, id as i32);
    Json(json!({&amp;quot;status&amp;quot;: &amp;quot;ok&amp;quot;}))
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then finally don&#x27;t forget to mount these routes when you start &lt;code&gt;rocket&lt;&#x2F;code&gt; and we
have ignition!.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;gotham&quot;&gt;Gotham&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;gotham.rs&#x2F;&quot;&gt;Gotham&lt;&#x2F;a&gt; is a web framework a bit newer on the scene. With one of the
key differences between it and Rocket is that it targets &lt;strong&gt;only&lt;&#x2F;strong&gt; stable Rust.
Whereas to get those really fancy macros with Rocket it is currently only able
to run on nightly Rust, which may be a deal breaker for some. This is not to say
this is the only differing aspect but a notable one.&lt;&#x2F;p&gt;
&lt;p&gt;Being a bit newer, Gotham is still changing it&#x27;s shape and structure as when
writing this it was only &lt;strong&gt;v0.2&lt;&#x2F;strong&gt;. However they do provide numerous examples of
how to use the framework in the several ways in which it was designed. Due to
the youth of this framework some of the examples on the website are out of date
as the framework changes but the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;gotham-rs&#x2F;gotham&#x2F;tree&#x2F;master&#x2F;examples&quot;&gt;GitHub&lt;&#x2F;a&gt; does provide up to date
examples. This is what I used to piece this one together.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;finding-common-ground&quot;&gt;Finding Common Ground&lt;&#x2F;h3&gt;
&lt;p&gt;The way I approached this little project was to try the different web frameworks
whilst keeping the same database interactions. Therefore it seemed sensible to
extract the common database work and share that between the two frameworks.
Therefore we will start with the current &lt;code&gt;model.rs&lt;&#x2F;code&gt; and keep it as similar as
possible.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;getting-it-started&quot;&gt;Getting it started&lt;&#x2F;h3&gt;
&lt;p&gt;As I was less familiar with this framework and the examples weren&#x27;t yet as
documented I thought I would try some nice and simple routing and basic
responses for those endpoints but they didn&#x27;t need to return anything.&lt;&#x2F;p&gt;
&lt;p&gt;The first part was simply starting the framework, this looked a bit different
but still pretty simple:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;pub fn start() {
    let addr = &amp;quot;127.0.0.1:8000&amp;quot;;
    println!(&amp;quot;Listening for requests at http:&amp;#x2F;&amp;#x2F;{}&amp;quot;, addr);
    gotham::start(addr, router())
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You will note there is a &lt;code&gt;router()&lt;&#x2F;code&gt; function which I have made no mention of,
never fear I will explain it here! Rather than the dispersed approach for the
routing that was used in Rocket where each route gets to be defined at the
function that is to be executed, in Gotham we define the routes in a single
function producing a &lt;code&gt;Router&lt;&#x2F;code&gt;. Whilst it looks different we are essentially
doing the same thing as we had to mount all the routes in Rocket when starting
it.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;use gotham::router::Router;
use gotham::router::builder::*;

fn router -&amp;gt; Router {
    build_simple_router(|route|{
        route.get(&amp;quot;&amp;#x2F;tasks&amp;quot;).to(get_all_tasks);
    })
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;So now we have a simple route to the &lt;code&gt;get_all_tasks&lt;&#x2F;code&gt; request handler so we
better define that on but first when we look into the documentation for Gotham
it has a very clear definition of what a &lt;code&gt;Handler&lt;&#x2F;code&gt; must look like. It takes a
&lt;code&gt;State&lt;&#x2F;code&gt; and returns a tuple of &lt;code&gt;(State, Response)&lt;&#x2F;code&gt;. Now we want to return a list
of &lt;code&gt;Task&lt;&#x2F;code&gt;s, so thankfully this is made very simple by using the &lt;code&gt;IntoResponse&lt;&#x2F;code&gt;
trait provided from Gotham. With a small tweak of our &lt;code&gt;model.rs&lt;&#x2F;code&gt; we can have our
response type now be a &lt;code&gt;TaskList&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;code&gt;model.rs&lt;&#x2F;code&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&amp;#x2F;&amp;#x2F; ...

#[derive(Deserialize, Serialize)]
pub struct TaskList {
    pub list: Vec&amp;lt;Task&amp;gt;,
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Gotham uses &lt;code&gt;hyper&lt;&#x2F;code&gt; and &lt;code&gt;mime&lt;&#x2F;code&gt; crates to define its response structure so we
will need to grab those.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;extern crate hyper;
extern crate mime;
extern crate serde_json;

use gotham::state::State;
use gotham::http::response::create_response;
use hyper::{Response, StatusCode};

impl IntoResponse for TaskList {
    fn into_response(self, state: &amp;amp;State) -&amp;gt; Response {
        create_response(
            &amp;amp;state,
            StatusCode::Ok,
            Some((
                serde_json::to_string(&amp;amp;self.list)
                    .expect(&amp;quot;serialized product&amp;quot;)
                    .into_bytes(),
                mime::APPLICATION_JSON,
            )),
        )
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we are ready to write our &lt;code&gt;Handler&lt;&#x2F;code&gt; to retrieve all the tasks.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;fn get_all_tasks(state: State) -&amp;gt; (State, TaskList) {
    let tasks = vec![
        Task {
            id: 1,
            task: &amp;quot;Do homework&amp;quot;.to_owned(),
            completed: false,
        },
    ];
    (state, tasks)
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;manage-the-database-connection&quot;&gt;Manage the Database Connection&lt;&#x2F;h3&gt;
&lt;p&gt;Now we want to connect this up so it actually reads from the database. Here I
followed a similar approach to what I had seen from working with Rocket, which I
am sure is probably not the best or intended method with Gotham but it has
seemed to do the job.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;After putting this together I did actually see that Gotham does have some work
in their GitHub repository about getting Diesel to connect with it.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;The way Gotham manages state is though its definition of a &lt;code&gt;Handler&lt;&#x2F;code&gt; as we have
already seen. Every &lt;code&gt;Handler&lt;&#x2F;code&gt; is given the state, what we need to do is tell
Gotham that we would like to add our database connection to part of that state
for it to manage. After some playing around I found the simplest way to do this
is through middleware.&lt;&#x2F;p&gt;
&lt;p&gt;In Gotham I have understood the concept of &lt;code&gt;middleware&lt;&#x2F;code&gt; as a construct to allow
the management of the requests. They are called before the request is sent to
the &lt;code&gt;Handler&lt;&#x2F;code&gt; and if desired can actually manage the response of the &lt;code&gt;Handler&lt;&#x2F;code&gt;.
The Gotham framework manages the calling of these we simple have to implement
the &lt;code&gt;Middleware&lt;&#x2F;code&gt; trait and add it to our &lt;code&gt;Router&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;First of all we want our database connection pool to be able to be managed. To
do so we add &lt;code&gt;gotham-derive&lt;&#x2F;code&gt; to our dependencies and create the following
struct:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;#[derive(StateData)]
struct PoolState(Pool);
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now we are able to add &lt;code&gt;PoolState&lt;&#x2F;code&gt; to the Gotham &lt;code&gt;State&lt;&#x2F;code&gt;. Next we create our
middleware and implement it. The connection pool is created in the exact same
manner as it was when using Rocket.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;use gotham::middleware::Middleware;

#[derive(Clone, NewMiddleware)]
struct DbConnMiddleware;

impl Middleware for DbConnMiddleware {
    fn call&amp;lt;Chain&amp;gt;(self, mut state: State, chain: Chain) -&amp;gt; Box&amp;lt;HandlerFuture&amp;gt;
    where
        Chain: FnOnce(State) -&amp;gt; Box&amp;lt;HandlerFuture&amp;gt;,
    {
        if !state.has::&amp;lt;PoolState&amp;gt;() {
            &amp;#x2F;&amp;#x2F; Initialize it
            state.put(PoolState(init_pool()));
        }
        chain(state)
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Finally we modify our &lt;code&gt;Router&lt;&#x2F;code&gt; to use this middleware:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;use gotham::pipeline::single::single_pipeline;

fn router() -&amp;gt; Router {
    let (chain, pipelines) = single_pipeline(new_pipeline().add(DbConnMiddleware).build());
    build_router(chain, pipelines, |route| {
        route.get_or_head(&amp;quot;&amp;#x2F;&amp;quot;).to(index);
        route.get(&amp;quot;&amp;#x2F;tasks&amp;quot;).to(get_all_tasks);
    })
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;adding-the-read-all-functionality&quot;&gt;Adding the Read All Functionality&lt;&#x2F;h3&gt;
&lt;p&gt;Now that we have access to the database through the &lt;code&gt;State&lt;&#x2F;code&gt; it is actually very
simple to implement the CRUD functionality. First we create a simple helper
method to extract the database connection from the state.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;fn db_conn(state: &amp;amp;State) -&amp;gt; Option&amp;lt;DbConn&amp;gt; {
    state.borrow::&amp;lt;PoolState&amp;gt;().get().ok().map(|x| DbConn(x))
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then we can complete our read all functionality:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;fn get_all_tasks(state: State) -&amp;gt; (State, TaskList) {
    let conn = db_conn(&amp;amp;state).expect(&amp;quot;Failed with DB connection&amp;quot;);
    let tasks = TaskList {
        list: Task::all(&amp;amp;conn),
    };
    (state, tasks)
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;using-path-variables&quot;&gt;Using Path Variables&lt;&#x2F;h3&gt;
&lt;p&gt;The finally piece of the puzzle is implementing the update and delete where we
specify the ID of the task we want to use. This is provided in the URL path.
This is very easy to implement and reuse for both of these by creating a struct
that Gotham will populate from the path.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;#[derive(Deserialize, StateData, StaticResponseExtender)]
struct PathId {
    id: u32,
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Followed by changing the &lt;code&gt;Router&lt;&#x2F;code&gt; definition to expect there to be a path
variable&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&amp;#x2F;&amp;#x2F; ... previous router definition
route
    .put(&amp;quot;&amp;#x2F;task&amp;#x2F;:id&amp;quot;)
    .with_path_extractor::&amp;lt;PathId&amp;gt;()
    .to(update_task);
route
    .delete(&amp;quot;&amp;#x2F;task&amp;#x2F;:id&amp;quot;)
    .with_path_extractor::&amp;lt;PathId&amp;gt;()
    .to(delete_task);
&amp;#x2F;&amp;#x2F; ... rest of definition
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then we can define our delete to look like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;fn delete_task(mut state: State) -&amp;gt; (State, Response) {
    let PathId { id } = PathId::take_from(&amp;amp;mut state);
    let conn = db_conn(&amp;amp;state).expect(&amp;quot;Failed with DB connection&amp;quot;);
    Task::delete(&amp;amp;conn, id as i32);
    let resp = create_response(&amp;amp;state, StatusCode::Ok, None);
    (state, resp)
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;using-the-request-body&quot;&gt;Using the Request Body&lt;&#x2F;h3&gt;
&lt;p&gt;You may have noticed the update and create have yet to be addressed and this is
because these needed to extract the &lt;code&gt;Task&lt;&#x2F;code&gt; to create or update from the body of
the request. This was a little bit more clunky than simply adding annotations
but once I got around it, it wasn&#x27;t too bad at all.&lt;&#x2F;p&gt;
&lt;p&gt;Firstly you must know that Gotham actually stores the &lt;code&gt;Body&lt;&#x2F;code&gt; as part of the
&lt;code&gt;State&lt;&#x2F;code&gt; provided to the handler so that is simply how we would extract it.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;use hyper::Body;

let body = Body::take_from(&amp;amp;mut state)
        .concat2()
        .then(&amp;#x2F;&amp;#x2F; Do something with the body);
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Now there is a fair bit of boiler plate to get this &lt;code&gt;Body&lt;&#x2F;code&gt; out of the state as
the action is asynchronous. So I thought it would be nice if I could just
provide a closure of what I want to do with the body once it is ready and not
have to write this boiler plate out each time (I know twice in this case but I
was determined). So after some fighting with the borrow checker with lifetimes
this was the resulting create and update functions I got:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;fn body_handler&amp;lt;F&amp;gt;(mut state: State, f: F) -&amp;gt; Box&amp;lt;HandlerFuture&amp;gt;
where
    F: &amp;#x27;static + Fn(String, &amp;amp;State) -&amp;gt; Response,
{
    let body = Body::take_from(&amp;amp;mut state)
        .concat2()
        .then(move |full_body| match full_body {
            Ok(valid_body) =&amp;gt; {
                let body_content = String::from_utf8(valid_body.to_vec()).unwrap();
                let res = f(body_content, &amp;amp;mut state);
                future::ok((state, res))
            }
            Err(e) =&amp;gt; return future::err((state, e.into_handler_error())),
        });
    Box::new(body)
}

fn create_task(state: State) -&amp;gt; Box&amp;lt;HandlerFuture&amp;gt; {
    body_handler(state, |s, state| {
        let task = serde_json::from_str(&amp;amp;s).expect(&amp;quot;Failed to deserialize&amp;quot;);
        let conn = db_conn(state).expect(&amp;quot;Failed with DB connection&amp;quot;);
        Task::create(&amp;amp;conn, task);
        create_response(state, StatusCode::Ok, None)
    })
}

fn update_task(mut state: State) -&amp;gt; Box&amp;lt;HandlerFuture&amp;gt; {
    let PathId { id } = PathId::take_from(&amp;amp;mut state);
    body_handler(state, move |s, state| {
        let task = serde_json::from_str(&amp;amp;s).expect(&amp;quot;Failed to deserialize&amp;quot;);
        let conn = db_conn(&amp;amp;state).expect(&amp;quot;Failed with DB connection&amp;quot;);
        Task::update(&amp;amp;conn, id as i32, task);
        create_response(state, StatusCode::Ok, None)
    })
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;All in all I hope I could give some really basic use cases for working with
these frameworks and I hope to keep adding to this and improving the code as I
go so keep an eye on the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;maccoda&#x2F;micro-rs&quot;&gt;repository&lt;&#x2F;a&gt; if you are interested.&lt;&#x2F;p&gt;
&lt;p&gt;The key thing I wanted to try with this exercise was usability of the
frameworks, not really comparing in terms of performance. I think in this small
example Diesel was extremely easy to work with, mainly due to its helpful
documentation and examples.&lt;&#x2F;p&gt;
&lt;p&gt;In terms of the web frameworks you could definitely feel that Rocket was the
more mature in particular with its documentation which really assisted in
getting everything started. Further having those macros made everything very
simple to get it together, so if speed to get a product is your thing I would
definitely recommend. Also the variety of functionality Rocket currently
supports is great, I have barely scratched the surface with this basic example.&lt;&#x2F;p&gt;
&lt;p&gt;Gotham definitely has a lot going for it and it has very clear goals of what it
wants to achieve. It does have a bit more boiler plate lying around but
personally I don&#x27;t mind that because I feel like I can understand a bit better
how things are working. This is definitely a promising framework and look
forward to seeing what is to come.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Note Taking in Visual Studio Code</title>
		<published>2018-04-04T00:00:00+00:00</published>
		<updated>2018-04-04T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/note-taking/" type="text/html"/>
		<id>https://maccoda.github.io/note-taking/</id>
		<content type="html">&lt;p&gt;tl;dr Installed some extensions and made some snippets to make a really nice
note taking experience. Exact changes needed are &lt;a href=&quot;https:&#x2F;&#x2F;maccoda.github.io&#x2F;note-taking&#x2F;#setting-it-all-up&quot;&gt;below&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;visual-studio-code&quot;&gt;Visual Studio Code&lt;&#x2F;h2&gt;
&lt;p&gt;First and foremost I would like to introduce &lt;a href=&quot;https:&#x2F;&#x2F;code.visualstudio.com&quot;&gt;Visual Studio Code&lt;&#x2F;a&gt; if you haven&#x27;t
heard of it yet. It is my editor of choice and is very flexible and extendable.
For more information on it check out their site, I definitely recommend having a
look!&lt;&#x2F;p&gt;
&lt;p&gt;Now that you have VSCode I want to share the set of extensions, snippets, etc.
that I put together to create what I believe to be a very useful setup to allow
you to use VSCode for note taking. In particular I prefer to take my notes in
Markdown, if this isn&#x27;t your preferred I hope I can still assist in some way.&lt;&#x2F;p&gt;
&lt;p&gt;One thing I have noticed is that my laptop consistently starts getting filled up
with more and more applications during my work with software. An IDE (usually a
few even), an editor, database visualizer, email client, internet browsers
(multiple), etc. The last thing I want to do is add another application where I
could use an existing one in its place, this is what triggered me to look into
what alternatives were out there. Considering I am pretty mainstream with my
Markdown note taking it wasn&#x27;t too much of a difficult task. I already used
VSCode for many of my projects and plenty for editing READMEs and the like, so I
knew that it had quite an expansive set of functionality baked in to provide a
great experience when writing Markdown.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;dedicated-note-taking-applications&quot;&gt;Dedicated Note Taking Applications&lt;&#x2F;h2&gt;
&lt;p&gt;Before I started this I definitely had a look at existing applications because,
hey who doesn&#x27;t want to just take something off the shelf and it just works.
Again I specifically looked at the areas around Markdown based note taking and I
noted a few things that I found to be the most useful.&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Instant preview - a lot of these was in a side by side view&lt;&#x2F;li&gt;
&lt;li&gt;Tags - This is a great feature and easy way of searching and grouping notes&lt;&#x2F;li&gt;
&lt;li&gt;&#x27;Notebooks&#x27; - Being able to separate the notes into &#x27;notebooks&#x27; is a very
logical thing to be able to group notes together for easy reference.&lt;&#x2F;li&gt;
&lt;li&gt;Direct access - not so much a functionality of the application itself but I
enjoy being able to have direct access to my notes and be able to treat them
as their own separate entity.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;After some tinkering and searching I was very excited to find that I could
create a very similar experience in my already existing VSCode.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;setting-it-all-up&quot;&gt;Setting it all up&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;vsnotes&quot;&gt;VSNotes&lt;&#x2F;h3&gt;
&lt;p&gt;Extensions are the name given to plugins for VSCode. They are easily installed
from the extension manager in the sidebar, or even through the command palette
directly!&lt;&#x2F;p&gt;
&lt;p&gt;The first extension you will want is &lt;a href=&quot;https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=patricklee.vsnotes&quot;&gt;VSNotes&lt;&#x2F;a&gt;. This provides the majority of
the functionality. It provides:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Direct access to your notes through the &lt;em&gt;Explorer&lt;&#x2F;em&gt; side bar or &lt;em&gt;Command
Palette&lt;&#x2F;em&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Tags using the Markdown front matter of your notes&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h4 id=&quot;settings&quot;&gt;Settings&lt;&#x2F;h4&gt;
&lt;p&gt;All that you need to do to make the most of this change the setting for the home
directory of your notes:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;json&quot; class=&quot;language-json &quot;&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&amp;quot;vsnotes.defaultNotePath&amp;quot;: &amp;quot;&amp;#x2F;path&amp;#x2F;to&amp;#x2F;notes&amp;quot;
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h4 id=&quot;snippets&quot;&gt;Snippets&lt;&#x2F;h4&gt;
&lt;p&gt;Then create the following snippet for Markdown files. This snippet can be
created by accessing the &lt;em&gt;Command Palette&lt;&#x2F;em&gt; then selecting &lt;code&gt;Preferences: Configure User Snippets&lt;&#x2F;code&gt; &amp;gt; &lt;code&gt;markdown&lt;&#x2F;code&gt;. This will allow you to create language
specific snippets for Markdown.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;json&quot; class=&quot;language-json &quot;&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&amp;quot;Front Matter Tags&amp;quot;: {
		&amp;quot;prefix&amp;quot;: &amp;quot;tags&amp;quot;,
		&amp;quot;body&amp;quot;: [
			&amp;quot;---&amp;quot;,
			&amp;quot;tags:&amp;quot;,
			&amp;quot;    - $1&amp;quot;,
			&amp;quot;---&amp;quot;
		]
	}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;auto-preview&quot;&gt;Auto Preview&lt;&#x2F;h3&gt;
&lt;p&gt;The final extension was &lt;a href=&quot;https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=hnw.vscode-auto-open-markdown-preview&quot;&gt;Auto-Open Markdown Preview&lt;&#x2F;a&gt; which simply
does exactly as the name suggests. When a Markdown file is opened it
automatically opens the side preview of the Markdown file (which I usually can
open from &lt;code&gt;ctrl + shift + m&lt;&#x2F;code&gt;).&lt;&#x2F;p&gt;
&lt;h3 id=&quot;notebooks&quot;&gt;Notebooks&lt;&#x2F;h3&gt;
&lt;p&gt;The last part is the least inventive of how to address the final point of
notebooks. I am simply using directory structure to solve this problem. However
I am finding that this is sufficient thanks to the structure preview provided by
&lt;strong&gt;VSNotes&lt;&#x2F;strong&gt;. I know I am sorry a not so exciting note to end on but a simple
one.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;All in all I am finding this to be a suitable solution for my note taking
problem and hope this helps someone. I am also keen to hear if anyone else has a
better way of doing this or the like. Probably best way to discuss is to raise
an issue on the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;maccoda&#x2F;maccoda.github.io&#x2F;issues&quot;&gt;repo&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Writing Rust Documentation</title>
		<published>2017-09-15T00:00:00+00:00</published>
		<updated>2017-09-15T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/documentation/" type="text/html"/>
		<id>https://maccoda.github.io/documentation/</id>
		<content type="html">&lt;p&gt;Personally I have found Rust documentation to be great and very easy to follow.
Further I really enjoy that I can easily access the source code from the
documentation.&lt;&#x2F;p&gt;
&lt;p&gt;Recently I have tried to contribute back through writing some documentation on
the standard library and thought I would try construct a reference for
guidelines and principles the docs team seem to be following.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;formatting&quot;&gt;Formatting&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Wrap lines to 80 characters&lt;&#x2F;li&gt;
&lt;li&gt;Leave room for headings to breathe, empty line above and below.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;templates&quot;&gt;Templates&lt;&#x2F;h2&gt;
&lt;p&gt;Standardization is always good in the standard library so to address these the
documentation team developed some templates for common documentation which makes
the feel of the documentation very consistent and easy to write.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;iterator-template&quot;&gt;Iterator Template&lt;&#x2F;h3&gt;
&lt;p&gt;When describing a struct that implements &lt;code&gt;Iterator&lt;&#x2F;code&gt; the following template
should be used:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;An iterator that {what it does}&lt;&#x2F;p&gt;
&lt;p&gt;This struct is create by the {foo} method[ on {trait}]. See its documentation
for more.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h2 id=&quot;linking&quot;&gt;Linking&lt;&#x2F;h2&gt;
&lt;p&gt;This was the part I continue to struggle with as it is a bit confusing without a
reference nearby.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;modules&quot;&gt;Modules&lt;&#x2F;h3&gt;
&lt;p&gt;Each module is located in its own sub-directory. That is if my crate is called
&lt;code&gt;foo&lt;&#x2F;code&gt; with a public module &lt;code&gt;bar&lt;&#x2F;code&gt;. Then to reference something in that module my
comment link would need to be something like:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&amp;#x2F;&amp;#x2F;&amp;#x2F; [bar::MyStruct`]: bar&amp;#x2F;struct.MyStruct.html
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;lexical-elements&quot;&gt;Lexical Elements&lt;&#x2F;h3&gt;
&lt;h4 id=&quot;structs&quot;&gt;Structs&lt;&#x2F;h4&gt;
&lt;p&gt;All structs will be prepended with &lt;code&gt;struct&lt;&#x2F;code&gt; such as &lt;code&gt;struct.MyStruct.html&lt;&#x2F;code&gt; and
will be located on their own HTML page.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;enums&quot;&gt;Enums&lt;&#x2F;h4&gt;
&lt;p&gt;All enums will be prepended with &lt;code&gt;enum&lt;&#x2F;code&gt; such as &lt;code&gt;enum.MyEnum.html&lt;&#x2F;code&gt; and will be
located on their own HTML page.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;traits&quot;&gt;Traits&lt;&#x2F;h4&gt;
&lt;p&gt;All traits will be prepended with &lt;code&gt;trait&lt;&#x2F;code&gt; such as &lt;code&gt;trait.MyTrait.html&lt;&#x2F;code&gt; and will
be located on their own HTML page.&lt;&#x2F;p&gt;
&lt;h4 id=&quot;functions&quot;&gt;Functions&lt;&#x2F;h4&gt;
&lt;p&gt;Functions will always be related to some struct, trait or enum, hence will not
have their own HTML page and need to be referenced by ID. So let&#x27;s say I have a
function called &lt;code&gt;my_func&lt;&#x2F;code&gt; for a struct called &lt;code&gt;MyStruct&lt;&#x2F;code&gt; (I know pretty original
over here), then to reference this would be:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&amp;#x2F;&amp;#x2F;&amp;#x2F; [`my_func`]: MyStruct.html#method.my_func
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;However if you were wishing to reference a function on a trait it would be
slightly different.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&amp;#x2F;&amp;#x2F;&amp;#x2F; [`my_func`]: MyTrait.html#tymethod.my_func
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Binding Raspberry Pi Libraries</title>
		<published>2017-06-03T00:00:00+00:00</published>
		<updated>2017-06-03T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/rust-raspberrypi/" type="text/html"/>
		<id>https://maccoda.github.io/rust-raspberrypi/</id>
		<content type="html">&lt;p&gt;My background with software stemmed from my interest in electronics and embedded
software and when I saw that Rust was starting to get some traction in this area
I knew that I had to give it a go and see how far I could get.&lt;&#x2F;p&gt;
&lt;p&gt;To see the actual source referred to in this post you can find it on &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;maccoda&#x2F;wiringpi-rs&quot;&gt;Github&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;TL;DR Got the LED blinking. Boo yeah!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-project&quot;&gt;The project&lt;&#x2F;h2&gt;
&lt;p&gt;The goal of the project was create Rust bindings for the &lt;a href=&quot;http:&#x2F;&#x2F;wiringpi.com&quot;&gt;wiringPi library&lt;&#x2F;a&gt;,
this is a Arduino like library for using the GPIO on the Raspberry Pi. Starting
off this was just an experiment to looking into the usage of the &lt;code&gt;bindgen&lt;&#x2F;code&gt; crate
now that they have a very useful &lt;a href=&quot;https:&#x2F;&#x2F;servo.github.io&#x2F;rust-bindgen&#x2F;&quot;&gt;guide&lt;&#x2F;a&gt; for how to utilize &lt;code&gt;bindgen&lt;&#x2F;code&gt; in
generating FFI bindings to C and C++ libraries. Of course as I should have
realized, this also would then lead to cross compilation again but now with the
target being an embedded device and hopefully opening the way for more of these
ports and making Rust a common language for ARM devices.&lt;&#x2F;p&gt;
&lt;p&gt;Also it would be extremely rude of me not to mention that this work has already
been done my Ogeon in the crate &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Ogeon&#x2F;rust-wiringpi&quot;&gt;rust-wiringpi&lt;&#x2F;a&gt;, so this was more of an exercise
for myself, but I was very lucky someone had done the hard yards as this
repository greatly assisted me in the cross compilation aspect of this project.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;bindings&quot;&gt;Bindings&lt;&#x2F;h2&gt;
&lt;p&gt;Writing the bindings was rather painless thanks to the guide and &lt;code&gt;bindgen&lt;&#x2F;code&gt;, I
won&#x27;t explain the process here as the &lt;a href=&quot;https:&#x2F;&#x2F;servo.github.io&#x2F;rust-bindgen&#x2F;&quot;&gt;guide&lt;&#x2F;a&gt; does a great job of that. In
generating these bindings there was very few manual components in getting the
bindings created. However the bindings created aren&#x27;t very Rust-ic, they are
just a one to one mapping of the functions and constants defined within a
header. It was really lacking a lot of the strong typing that I have come to
love in Rust, so I thought surely there is a better way to make these bindings,
and more importantly surely I am not the first to have this idea.&lt;&#x2F;p&gt;
&lt;p&gt;Sure enough I wasn&#x27;t after doing some searching I found some interesting takes
on how to make the bindings to existing C&#x2F;C++ libraries. The one I chose was to
add the library as a &lt;a href=&quot;https:&#x2F;&#x2F;git-scm.com&#x2F;book&#x2F;en&#x2F;v2&#x2F;Git-Tools-Submodules&quot;&gt;git submodule&lt;&#x2F;a&gt; within my repository so that I was able to
build it from source, this would prove to be vital for the cross compilation
aspect of this. Then on top of this I had the one simple project that would
generate the bindings using &lt;code&gt;bindgen&lt;&#x2F;code&gt; then finally the main project which would
be using these bindings but expose an API of my choice rather than that of the
wiringPi library (not saying its API is poor, just wanted to make it more
idiomatic for Rust).&lt;&#x2F;p&gt;
&lt;p&gt;This meant that my structure would look something like the following:&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;wiringpi-rs
-src
-wiringPi-bindings
| -src
| -build.rs
|  Cargo.toml
-WiringPi
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The most important aspect of wrapping these bindings also means that users of
the library aren&#x27;t having to wrap every library call in an &lt;code&gt;unsafe&lt;&#x2F;code&gt; block as our
wrappings can handle this and only expose the aspects we want. Further it really
improved the notion of constants, all the &lt;code&gt;#def&lt;&#x2F;code&gt; within C library can now be
represented using enums and hence better express their purpose and context for
usage.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;mapping-constants&quot;&gt;Mapping Constants&lt;&#x2F;h3&gt;
&lt;p&gt;The typical way to represent constants within C would be like the following:&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;#def LOW 0
#def HIGH 1
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is very common for a language like C but we can do a lot better in Rust to make it far simpler to separate concepts. The issue that constants like these raise is that we end up with functions that accept integers for which we just pass some value in that was included from some distant header file.&lt;&#x2F;p&gt;
&lt;p&gt;What would be far clearer is representing this as an enumeration . The Rust representation for enumerations is very powerful but it doesn&#x27;t have the concept of ordinals, so I found the simplest way was to have a trait that exposed this, with the eventual hope to make a macro of it.&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;enum DigitalValue {
    Low = 0,
    High = 1,
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Which allows us to be explicit in the types we can give to functions using these constants:&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;fn digital_write(value: DigitalValue)
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And access them as:&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;bindings::digitalWrite(value as i32);
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;cross-compilation-for-raspberry-pi&quot;&gt;Cross compilation for Raspberry Pi&lt;&#x2F;h2&gt;
&lt;p&gt;The general idea of cross compilation I have already covered in a &lt;a href=&quot;cross_compilation.html&quot;&gt;previous
post&lt;&#x2F;a&gt; so I won&#x27;t go into that here but just the specifics required for this
project.&lt;&#x2F;p&gt;
&lt;p&gt;This part of the project I managed to get most of my answers from the Rust
community from an &lt;a href=&quot;https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;29917513&#x2F;how-can-i-compile-rust-code-to-run-on-a-raspberry-pi-2&quot;&gt;SO answer&lt;&#x2F;a&gt; to the original &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Ogeon&#x2F;rust-wiringpi&quot;&gt;rust-wiringpi&lt;&#x2F;a&gt;. The former in
what was the correct target for the Raspberry Pi and the latter for how to build
the WiringPi library as part of the bindings build, hence ensuring the build
library would have the correct architecture. Put simply if you follow the general instructions I provided in the &lt;a href=&quot;cross_compilation.html&quot;&gt;Cross Compilation&lt;&#x2F;a&gt; post the target you are wanting is: &lt;strong&gt;arm-unknown-linux-gnueabihf&lt;&#x2F;strong&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;The two aspects go hand in hand as essentially what we are doing is ensuring we
have the linker for the correct target and configuring first Cargo to do this
correctly for us, then secondly we use the build tools of the library we are
binding to, to ensure that the linker used there is that same as the target we
are going for. In order to get the WiringPi library built for the target I followed off what was done in the original bindings which was to add a Makefile for which we set the &lt;code&gt;CC&lt;&#x2F;code&gt; variable to the linker that we were requiring for the Raspberry Pi.&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;CC=arm-linux-gnueabihf-gcc
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;After adding this I was able to overcome all of the build issues and then with a simple &lt;code&gt;scp&lt;&#x2F;code&gt; moved the built binary which you can find in &lt;code&gt;target&#x2F;arm-unknown-linux-gnueabihf&#x2F;debug&#x2F;&lt;&#x2F;code&gt; or &lt;code&gt;target&#x2F;arm-unknown-linux-gnueabihf&#x2F;release&lt;&#x2F;code&gt; the LED was blinking from the Raspberry Pi!&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Cross Compilation for Rust (Windows on Linux)</title>
		<published>2017-05-13T00:00:00+00:00</published>
		<updated>2017-05-13T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/cross-compilation/" type="text/html"/>
		<id>https://maccoda.github.io/cross-compilation/</id>
		<content type="html">&lt;p&gt;Cross compilation always has an aura about it, being able to develop on one
machine and be able to produce executables for all devices. I mean that was
Java&#x27;s selling point &amp;quot;Write it once, run it everywhere&amp;quot; (I probably got that one
wrong but you get the point). This was one hurdle for me with Rust as I use a
Linux desktop at work but I was to be able to make things that I can give family
and friends so that they may benefit from it also. In particular a lot of
corporate positions use Windows (myself included) meaning it is difficult to get
my executables to work. However after a bit of reading and in particular the
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;japaric&#x2F;rust-cross&quot;&gt;Cross Repository&lt;&#x2F;a&gt; I have managed to get cross compilation for Linux
(Ubuntu) to Windows working and thought I would send this one out :).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;building-with-cargo&quot;&gt;Building with Cargo&lt;&#x2F;h2&gt;
&lt;p&gt;For those not so familiar with Rust, Cargo is the build tool actually shipped
with Rust. I must say I find this to be a very well planned and built build
tool. It handle a lot of the common issues with the build process and makes it
extremely simple to get applications built and running quickly. Essentially it
add a lot more brain power to the &lt;code&gt;rustc&lt;&#x2F;code&gt; compiler, particularly in the
department of dependency management and tasks (build, test, etc.).&lt;&#x2F;p&gt;
&lt;p&gt;Where it comes in even more useful here is that when I want to build for a
different target there is not much more work than a few commands and then simply
add the &lt;code&gt;--target=&amp;lt;target&amp;gt;&lt;&#x2F;code&gt; argument and viola I have my cross compilation!&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-a-target&quot;&gt;What is a Target?&lt;&#x2F;h2&gt;
&lt;p&gt;Put simply the target is the target architecture that your executable is going to be running on. It is fairly common knowledge that my executable on a Linux machine can&#x27;t run exactly on a Windows, and only sometimes on a Mac (Don&#x27;t quote me on that last one). Again this is very well detailed in the &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;japaric&#x2F;rust-cross&quot;&gt;Cross Repository&lt;&#x2F;a&gt; what Rust defines as targets but will have a quick summary here.&lt;&#x2F;p&gt;
&lt;p&gt;Essentially it boils down to a few things. First and foremost the
&lt;strong&gt;architecture&lt;&#x2F;strong&gt;. This is the architecture of the actual processor that is
running your software. Is it a 32-bit or 64-bit machine? Or is it perhaps for an
embedded platform and running on an ARM processor? Excitingly, all of these are
possible targets for Rust!&lt;&#x2F;p&gt;
&lt;p&gt;The other main aspect is the &lt;strong&gt;system&lt;&#x2F;strong&gt;, in here we separate Linux from Mac from Windows. Of course there are may others than just these ones but these are your main players. From these and some other characteristics we create a &lt;strong&gt;triple&lt;&#x2F;strong&gt; that explicitly defines a target.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;cross-compiling&quot;&gt;Cross-Compiling&lt;&#x2F;h2&gt;
&lt;p&gt;Alight enough background, let&#x27;s get into what needs to be done to cross compile.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;em&gt;Now little disclaimer, I have only done this for my machine compiling for Windows on my Linux machine. I have not tried to the converse or any other combination.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;
&lt;p&gt;First off we need to add the target to your machine, in particular this adds the standard library for the intended target. Again thanks to the incredible tooling from the Rust community this is simple using &lt;code&gt;rustup&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;$ rustup target add x86_64-pc-windows-gnu
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Next we need to get the &lt;code&gt;gcc&lt;&#x2F;code&gt; compiler for that target. If you are interested I found it fascinating the amount of targets gcc itself has as I looked through which was the correct package to get. Using a Debian system:&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt-get install gcc-mingw-w64
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You should then find in &lt;code&gt;&#x2F;usr&#x2F;lib&#x2F;gcc&lt;&#x2F;code&gt; all your &lt;code&gt;gcc&lt;&#x2F;code&gt; targets.&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;[dmaccora:&amp;#x2F;usr&amp;#x2F;lib&amp;#x2F;gcc] $ ls
i686-w64-mingw32  x86_64-linux-gnu  x86_64-w64-mingw32
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Next we need to change the Cargo configuration so that it uses the newly
installed &lt;code&gt;gcc&lt;&#x2F;code&gt; linker instead of the system one. Of course we only want to use
this for a particular target but of course Cargo has got this covered for us
with its &lt;a href=&quot;http:&#x2F;&#x2F;doc.crates.io&#x2F;config.html&quot;&gt;configuration options&lt;&#x2F;a&gt;. So it applies for all projects
we place the configuration in &lt;code&gt;~&#x2F;.cargo&#x2F;config&lt;&#x2F;code&gt;. Don&#x27;t worry if this file
doesn&#x27;t exist just create it new, Cargo has a default configuration it will be
using unless otherwise specified (which is what we will do now). All that is needed to add the following two lines:&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;[target.x86_64-pc-windows-gnu]
linker = &amp;quot;x86_64-w64-mingw32-gcc&amp;quot;
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You will note that the linker matches the &lt;code&gt;gcc&lt;&#x2F;code&gt; target we found earlier (hopefully this is the general rule as that is how I managed to get it all working).&lt;&#x2F;p&gt;
&lt;p&gt;Then finally we can build our crate for another target!&lt;&#x2F;p&gt;
&lt;pre&gt;&lt;code&gt;$ cargo build --target=x86_64-pc-windows-gnu
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Simple GUI in Relm</title>
		<published>2017-05-12T00:00:00+00:00</published>
		<updated>2017-05-12T00:00:00+00:00</updated>
		<link href="https://maccoda.github.io/relm-gui/" type="text/html"/>
		<id>https://maccoda.github.io/relm-gui/</id>
		<content type="html">&lt;p&gt;This work stemmed from the article written on &lt;a href=&quot;https:&#x2F;&#x2F;www.vandenoever.info&#x2F;blog&#x2F;2017&#x2F;02&#x2F;17&#x2F;a-simple-rust-gui-with-qml.html&quot;&gt;A Simple Rust GUI with
QML&lt;&#x2F;a&gt; and reused a bit of the back end there.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-is-relm&quot;&gt;What is Relm&lt;&#x2F;h2&gt;
&lt;p&gt;Recently the GUI library &lt;a href=&quot;http:&#x2F;&#x2F;relm.ml&#x2F;relm-intro&quot;&gt;Relm&lt;&#x2F;a&gt; came onto the scene with the goal to develop asynchronous GUI applications in Rust. The link provides a great description as to it benefits that it brings so I won&#x27;t bore you with the details a second time around.
In short what really sold me initially (as someone quite unfamiliar with GUI work) was:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;The ability to have a declarative nature in which you could define your view&lt;&#x2F;li&gt;
&lt;li&gt;The simplicity with dealing with a model&lt;&#x2F;li&gt;
&lt;li&gt;The simplicity of defining the events or messages received&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Of this the biggest winner for me was the abstraction of the model manipulation
as I wanted to try a few different frameworks so I could have a go to when
writing GUI programs and the difficultly was handling the mutability of your
model. This is notion is put in the limelight with Rust due to its borrow
checker. However I do want to point out that this is by no means a shortcoming
of Rust but rather highlights one of the more common issues in UI and all
development is a mutable state which is able to altered from several locations. Anyway Rust fanfare aside, Relm has done a great job in wrapping this complexity to make a very simple library to work with I believe.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;getting-our-hands-dirty&quot;&gt;Getting our hands dirty&lt;&#x2F;h2&gt;
&lt;p&gt;Relm is quite well documented and has several examples that were easy to follow so again I won&#x27;t repeat these but it was very easy to get a basic example of a button that is able to report when it is clicked an increment a counter.&lt;&#x2F;p&gt;
&lt;p&gt;One thing I do want to add before we go deeper is that Relm is strongly related to GTK concepts, in particular the widget elements used are GTK widgets. So I would really recommend having at least a reference to it open when working through it if you aren&#x27;t familiar with the nomenclature of the widgets.&lt;&#x2F;p&gt;
&lt;p&gt;So my test was to see how simple it would be to get the basic file explorer example shown in &lt;a href=&quot;https:&#x2F;&#x2F;www.vandenoever.info&#x2F;blog&#x2F;2017&#x2F;02&#x2F;17&#x2F;a-simple-rust-gui-with-qml.html&quot;&gt;the QML article&lt;&#x2F;a&gt; using Relm. To my surprise I managed to get it done in under 200 line (199 to be exact XD). If all you want is to have a look at the code and play around with it (be warned I wouldn&#x27;t say it is beautiful just yet) I have made a &lt;a href=&quot;https:&#x2F;&#x2F;gist.github.com&#x2F;maccoda&#x2F;a93fb2a0ef1f283bc63a4be9e5f8fe9c&quot;&gt;gist&lt;&#x2F;a&gt;, otherwise if you&#x27;d like to stick around we can build it up bit by bit.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;model&quot;&gt;Model&lt;&#x2F;h2&gt;
&lt;p&gt;First things first, we want to define our model of our little application. For those note so familiar with this concept the model is data that will adequately explain the state of your application. Since it is just a very simple file browser all we need is the current directory. So it will look a little something like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;#[derive(Clone)]
pub struct Directory {
    current_dir: PathBuf,
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Note that you will need your model to implement the &lt;code&gt;Clone&lt;&#x2F;code&gt; trait to used as part of Relm.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;message&quot;&gt;Message&lt;&#x2F;h2&gt;
&lt;p&gt;Now we don&#x27;t just a static window that doesn&#x27;t respond to much so we need a way of sending events&#x2F;messages to update the state of our application. The beauty of Relm is just how simple it makes it to handle several events and even more so you are able to categorize the events logically in terms of your application as opposed to the underlying framework. That is, if you have several different UI events that from the perspective of your application are indifferent then you are able to send the same message for both with a more descriptive name.&lt;&#x2F;p&gt;
&lt;p&gt;Now this example doesn&#x27;t really delve into that but it isn&#x27;t too much of a stretch to see how it could be great. For our little application we only care when the user selects an item in the list of files we present to them and of course when they want to quit.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;#[derive(Msg)]
enum Msg {
    ItemSelect,
    Quit,
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Here we use the one of the biggest time savers in Rust, the &lt;code&gt;derive&lt;&#x2F;code&gt; attribute to derive the &lt;code&gt;Msg&lt;&#x2F;code&gt; trait from Relm.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;creating-the-main-widget&quot;&gt;Creating the Main Widget&lt;&#x2F;h2&gt;
&lt;p&gt;The final step now is to create our widget. As seen in the &lt;a href=&quot;http:&#x2F;&#x2F;relm.ml&#x2F;relm-intro&quot;&gt;intro to Relm&lt;&#x2F;a&gt; there are two methods to this using the &lt;code&gt;#[widget]&lt;&#x2F;code&gt; attribute or implementing the &lt;code&gt;Widget&lt;&#x2F;code&gt; trait. WIth the structure of this widget I had a bit of difficulty getting the &lt;code&gt;#[widget]&lt;&#x2F;code&gt; attribute to entirely agree with me so I implemented the trait which I did not mind at all as I always feel that the amazing macro system in Rust can add a layer of complexity when it comes to solving errors.&lt;&#x2F;p&gt;
&lt;p&gt;Below is the full implementation for which we will look at individually.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&amp;#x2F;&amp;#x2F; Top level structure
#[derive(Clone)]
struct Win {
    window: gtk::Window,
    tree_view: gtk::TreeView,
}

impl Widget for Win {
    type Model = Directory;
    type Msg = Msg;
    type Root = gtk::Window;

    fn model() -&amp;gt; Directory {
        let working_directory = fs::canonicalize(&amp;quot;.&amp;quot;).expect(&amp;quot;Failed to open directory&amp;quot;);

        Directory { current_dir: working_directory }
    }

    fn root(&amp;amp;self) -&amp;gt; &amp;amp;Self::Root {
        &amp;amp;self.window
    }

    fn update(&amp;amp;mut self, event: Msg, model: &amp;amp;mut Self::Model) {
        match event {
            Msg::ItemSelect =&amp;gt; {
                let selection = self.tree_view.get_selection();
                if let Some((list_model, iter)) = selection.get_selected() {
                    let is_dir: bool = list_model
                        .get_value(&amp;amp;iter, IS_DIR_COL)
                        .get::&amp;lt;bool&amp;gt;()
                        .unwrap();

                    if is_dir {
                        let dir_name = list_model
                            .get_value(&amp;amp;iter, VALUE_COL)
                            .get::&amp;lt;String&amp;gt;()
                            .unwrap();
                        println!(&amp;quot;{:?} selected&amp;quot;, dir_name);
                        let new_dir = if dir_name == &amp;quot;..&amp;quot; {
                            &amp;#x2F;&amp;#x2F; Go up parent directory if it exists
                            model
                                .current_dir
                                .parent()
                                .unwrap_or(&amp;amp;model.current_dir)
                                .to_owned()
                        } else {
                            model.current_dir.join(dir_name)
                        };

                        model.current_dir = new_dir;
                        let new_model = create_and_fill_model(&amp;amp;model.current_dir).unwrap();

                        self.tree_view.set_model(Some(&amp;amp;new_model));
                    }
                }
            }
            Msg::Quit =&amp;gt; gtk::main_quit(),
        }
    }

    fn view(relm: RemoteRelm&amp;lt;Msg&amp;gt;, _model: &amp;amp;Self::Model) -&amp;gt; Win {
        let window = create_window(&amp;quot;Treeview&amp;quot;);

        let scroll = gtk::ScrolledWindow::new(None, None);
        let tree = gtk::TreeView::new();


        let column = gtk::TreeViewColumn::new();
        let cell = gtk::CellRendererText::new();

        column.pack_start(&amp;amp;cell, true);
        &amp;#x2F;&amp;#x2F; Association of the view&amp;#x27;s column with the model&amp;#x27;s &amp;#x27;id&amp;#x27; column.
        let id = 0;
        column.add_attribute(&amp;amp;cell, &amp;quot;text&amp;quot;, id);
        tree.append_column(&amp;amp;column);


        let model = create_and_fill_model(&amp;amp;_model.current_dir).unwrap();

        tree.set_model(Some(&amp;amp;model));

        &amp;#x2F;&amp;#x2F; tree.connect_cursor_changed(change_dir);
        connect!(relm, tree, connect_cursor_changed(_), Msg::ItemSelect);
        connect!(relm, window, connect_delete_event(_, _) (Some(Msg::Quit), Inhibit(false)));

        scroll.add(&amp;amp;tree);
        window.add(&amp;amp;scroll);

        window.show_all();

        Win {
            window: window,
            tree_view: tree,
        }
    }
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;top-level-widget&quot;&gt;Top Level Widget&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;struct Win {
    window: gtk::Window,
    tree_view: gtk::TreeView,
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Of course we have to have a root or top level widget, the one that will contain all other widgets. This is exactly what the &lt;code&gt;Win&lt;&#x2F;code&gt; struct is, it is our window (mind the pun) into the GTK widgets. Here we have the encasing &lt;code&gt;gtk::window&lt;&#x2F;code&gt; for our root widget and we wanted to open access to the &lt;code&gt;gtk::TreeView&lt;&#x2F;code&gt; which will contain the file listing.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;widget-type-declarations&quot;&gt;Widget Type Declarations&lt;&#x2F;h3&gt;
&lt;p&gt;When implementing the &lt;code&gt;Widget&lt;&#x2F;code&gt; trait we need to declare&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;the &lt;code&gt;Model&lt;&#x2F;code&gt; of our application already discussed in the &lt;a href=&quot;https:&#x2F;&#x2F;maccoda.github.io&#x2F;relm-gui&#x2F;#model&quot;&gt;model&lt;&#x2F;a&gt; section,&lt;&#x2F;li&gt;
&lt;li&gt;the &lt;code&gt;Msg&lt;&#x2F;code&gt; being the events to communicate changes already discussed in the &lt;a href=&quot;https:&#x2F;&#x2F;maccoda.github.io&#x2F;relm-gui&#x2F;#message&quot;&gt;message&lt;&#x2F;a&gt; section,&lt;&#x2F;li&gt;
&lt;li&gt;the &lt;code&gt;Root&lt;&#x2F;code&gt; element of the application, this is the GTK element that will house the other widgets. For us this is the &lt;code&gt;gtk::Window&lt;&#x2F;code&gt;.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;For the notions of &lt;code&gt;Model&lt;&#x2F;code&gt; and &lt;code&gt;Root&lt;&#x2F;code&gt;, Relm&#x27;s &lt;code&gt;Widget&lt;&#x2F;code&gt; provides a function to construct&#x2F;access these through the &lt;code&gt;model()&lt;&#x2F;code&gt; function to initialize the model, and &lt;code&gt;root()&lt;&#x2F;code&gt; to provide access to the root element.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;view&quot;&gt;View&lt;&#x2F;h3&gt;
&lt;p&gt;Now we finally have to build our view to describe how it should look. This is where Relm made the delightful &lt;code&gt;view!&lt;&#x2F;code&gt; macro to allow for a view to be built in a declarative fashion. However I found that it was a bit easier to do away with this and just simply implement the trait function in the usual fashion. This was partly due to the fact that I had already played around with this idea with GTK and had some code at hand.&lt;&#x2F;p&gt;
&lt;p&gt;The goal of the &lt;code&gt;view()&lt;&#x2F;code&gt; function is to construct the view exactly as desired and return our &lt;a href=&quot;https:&#x2F;&#x2F;maccoda.github.io&#x2F;relm-gui&#x2F;#top-level-widget&quot;&gt;top level widget&lt;&#x2F;a&gt;. In here also we add all of event listeners using the simple &lt;code&gt;connect!&lt;&#x2F;code&gt; macro.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;connect!(relm, tree, connect_cursor_changed(_), Msg::ItemSelect);
        connect!(relm, window, connect_delete_event(_, _) (Some(Msg::Quit), Inhibit(false)));
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Don&#x27;t forget to make it visible also!&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;window.show_all();
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;updating-from-events&quot;&gt;Updating From Events&lt;&#x2F;h3&gt;
&lt;p&gt;The final part of this trait to implement is the &lt;code&gt;update()&lt;&#x2F;code&gt; function. This is where our events will be handled depending on our &lt;a href=&quot;https:&#x2F;&#x2F;maccoda.github.io&#x2F;relm-gui&#x2F;#message&quot;&gt;message&lt;&#x2F;a&gt; received. Since there isn&#x27;t a lot going on here I haven&#x27;t gone for the asynchronous version of this and the function signature is the following:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;fn update(&amp;amp;mut self, event: Msg, model: &amp;amp;mut Self::Model)
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As you can see from this function we have:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;amp;mut self&lt;&#x2F;code&gt; so we are able to manipulate the main widget, which in our case will be with the intention to update the &lt;code&gt;gtk::TreeView&lt;&#x2F;code&gt; when a new directory is selected.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;code&gt;event: Msg&lt;&#x2F;code&gt; so that we can perform a simple &lt;code&gt;match&lt;&#x2F;code&gt; on the event received and have clear separation of our event handling code.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;code&gt;&amp;amp;mut Self::Model&lt;&#x2F;code&gt; which will provide mutable access to the model, allowing us to update it if required from the event.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;but-what-about-the-other-code&quot;&gt;But what about the other code?&lt;&#x2F;h3&gt;
&lt;p&gt;As you may notice in the gist there is a whole bunch of other code that I had there more related to the construction of the GTK elements. This is heavily based on example code from &lt;code&gt;gtk-rs&lt;&#x2F;code&gt; which now has even more documentation so thought could just leave that for the reader to understand XD.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;actually-running-it&quot;&gt;Actually Running It&lt;&#x2F;h2&gt;
&lt;p&gt;Of course what good is all this if we cannot run it! Just make sure your main looks like the following and it all can get happening!&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;fn main() {
    relm::run::&amp;lt;Win&amp;gt;().unwrap();
}
&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h1&gt;
&lt;p&gt;Overall I found Relm as a great addition to the Rust GUI libraries and very simple to use especially when UI is not your strong suit. It abstracts away several repeated details that we required to make the borrow checker smile allowing the user to put something together quite quickly.&lt;&#x2F;p&gt;
&lt;p&gt;That&#x27;s all for the first post. Hope this has helped!&lt;&#x2F;p&gt;
</content>
	</entry>
</feed>
